# FedMem: åŸºäºLLMçš„è”é‚¦æ¨èç³»ç»Ÿï¼ˆå¸¦æœ¬åœ°åŠ¨æ€å¤šæ¨¡æ€è®°å¿†ï¼‰

> æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„è”é‚¦å­¦ä¹ æ¨èç³»ç»Ÿï¼Œç»“åˆäº†æœ¬åœ°åŠ¨æ€è®°å¿†æœºåˆ¶å’Œå¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ ã€‚

## æ¶æ„æ¦‚è§ˆ

FedMemæ˜¯æ ‡å‡†è”é‚¦æ¨èç³»ç»Ÿçš„å‡çº§ç‰ˆæœ¬ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

### 1. **æœ¬åœ°åŠ¨æ€è®°å¿† (Local Dynamic Memory)**
   - **Surpriseæœºåˆ¶**ï¼šå®¢æˆ·ç«¯ç»´æŠ¤æœ¬åœ°è®°å¿†ç¼“å†²åŒºï¼ŒåŸºäº"æƒŠå–œ"ï¼ˆé¢„æµ‹è¯¯å·®ï¼‰æœºåˆ¶åŠ¨æ€æ›´æ–°
   - **å¤šæ¨¡æ€æ”¯æŒ**ï¼šæ”¯æŒæ–‡æœ¬/å›¾åƒ/IDä¸‰ç§æ¨¡æ€çš„åµŒå…¥è¡¨ç¤º
   - **æ•ˆç”¨é©±åŠ¨è¿‡æœŸ**ï¼šåŸºäº `utility = Î± * recency + Î² * frequency` çš„æ™ºèƒ½è¿‡æœŸæœºåˆ¶
   - **éšç§ä¿æŠ¤**ï¼šè®°å¿†å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¸ç›´æ¥ä¸Šä¼ åŸå§‹æ•°æ®

### 2. **å¤šæ¨¡æ€MoE (Multimodal Mixture-of-Experts)**
   - **åœºæ™¯æ„ŸçŸ¥è·¯ç”±å™¨**ï¼šæ ¹æ®ç›®æ ‡ç‰©å“ç±»åˆ«/åµŒå…¥åŠ¨æ€åˆ†é…ä¸“å®¶æƒé‡
   - **ä¸‰ä¸ªä¸“å®¶æ¨¡å—**ï¼š
     - **è§†è§‰ä¸“å®¶**ï¼šå¤„ç†å›¾åƒç‰¹å¾ï¼ˆCLIPåµŒå…¥ï¼‰
     - **æ–‡æœ¬ä¸“å®¶**ï¼šå¤„ç†LLMç”Ÿæˆçš„æ–‡æœ¬åå¥½
     - **åºåˆ—ä¸“å®¶**ï¼šå¤„ç†IDåºåˆ—æ¨¡å¼ï¼ˆSASRecï¼‰
   - **è‡ªé€‚åº”èåˆ**ï¼šåŠ¨æ€æƒé‡åˆ†é…ï¼Œé€‚åº”ä¸åŒåœºæ™¯

### 3. **åŸå‹èšåˆ (Prototype Aggregation)**
   - **K-Meansèšç±»**ï¼šå°†å®¢æˆ·ç«¯è®°å¿†èšç±»ä¸ºKä¸ªåŸå‹ä¸­å¿ƒç‚¹
   - **å…¨å±€æŠ½è±¡è®°å¿†**ï¼šæœåŠ¡å™¨èšåˆåŸå‹æ„å»ºå…¨å±€çŸ¥è¯†
   - **çŸ¥è¯†è’¸é¦**ï¼šä¸‹å‘ç»™å®¢æˆ·ç«¯è¾…åŠ©æœ¬åœ°æ¨è
   - **éšç§å‹å¥½**ï¼šä»…ä¼ è¾“èšç±»ä¸­å¿ƒï¼Œä¸æ³„éœ²åŸå§‹äº¤äº’æ•°æ®

## æ ¸å¿ƒç»„ä»¶

### 1. LocalDynamicMemory (`UR4Rec/models/local_dynamic_memory.py`)

**åŠŸèƒ½**ï¼š
- å­˜å‚¨é‡è¦äº¤äº’è®°å¿†
- Surpriseæœºåˆ¶ï¼š`loss > threshold` â†’ åŠ å…¥è®°å¿†
- Expireæœºåˆ¶ï¼š`utility = Î± * recency + Î² * frequency`
- K-Meansèšç±»æå–åŸå‹

**å…³é”®æ–¹æ³•**ï¼š
```python
# æŸ¥è¯¢è®°å¿†
memory.query(target_item, k=5)

# æ›´æ–°è®°å¿†ï¼ˆåŸºäºSurpriseï¼‰
memory.update(
    item_id=item_id,
    loss_val=loss_val,  # SurpriseæŒ‡æ ‡
    text_emb=text_emb,
    img_emb=img_emb,
    id_emb=id_emb
)

# æå–åŸå‹
prototypes = memory.get_memory_prototypes(k=5)
```

### 2. FedMemClient (`UR4Rec/models/fedmem_client.py`)

**åŠŸèƒ½**ï¼š
- æœ¬åœ°è®­ç»ƒé›†æˆè®°å¿†æŸ¥è¯¢
- Surprise-basedè®°å¿†æ›´æ–°
- å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆå¯¹é½ç”¨æˆ·åå¥½ä¸ç‰©å“ï¼‰
- ä¸Šä¼ æ¨¡å‹å‚æ•° + è®°å¿†åŸå‹

**è®­ç»ƒæµç¨‹**ï¼š
```python
# 1. å‰å‘ä¼ æ’­
retrieved_memory = query_memory_batch(target_items)
scores = model(user_ids, input_seq, target_items, retrieved_memory)

# 2. è®¡ç®—æŸå¤±
rec_loss = BPR_loss(pos_scores, neg_scores)
contrastive_loss = align_user_preference_with_item(user_ids, target_items)
total_loss = rec_loss + Î» * contrastive_loss

# 3. åå‘ä¼ æ’­
optimizer.step()

# 4. Surprise-basedè®°å¿†æ›´æ–°
for each sample:
    if sample_loss > threshold:
        memory.update(item_id, sample_loss, embeddings)
```

**å…³é”®æ–¹æ³•**ï¼š
```python
# è®­ç»ƒ
metrics = client.train_local_model(verbose=True)
# è¿”å›: {'loss', 'rec_loss', 'contrastive_loss', 'memory_size', 'memory_updates'}

# æå–åŸå‹
prototypes = client.get_memory_prototypes()  # [K, emb_dim]

# æ¥æ”¶å…¨å±€è®°å¿†
client.set_global_abstract_memory(global_prototypes)
```

### 3. FedMemServer (å¾…å®Œæ•´å®ç°)

**åŠŸèƒ½**ï¼š
- èšåˆæ¨¡å‹å‚æ•°ï¼ˆFedAvgï¼‰
- èšåˆè®°å¿†åŸå‹ï¼ˆå¹³å‡ï¼‰
- ä¸‹å‘å…¨å±€æ¨¡å‹ + å…¨å±€æŠ½è±¡è®°å¿†

**Prototypeèšåˆé€»è¾‘**ï¼š
```python
def aggregate_prototypes(client_prototypes: List[torch.Tensor]):
    """
    èšåˆå®¢æˆ·ç«¯åŸå‹ â†’ å…¨å±€æŠ½è±¡è®°å¿†

    Args:
        client_prototypes: List of [K, emb_dim] tensors

    Returns:
        global_prototypes: [K, emb_dim]
    """
    # ç®€å•å¹³å‡
    global_prototypes = torch.stack(client_prototypes).mean(dim=0)
    return global_prototypes
```

## è®­ç»ƒæµç¨‹

### FedMemè”é‚¦å­¦ä¹ å®Œæ•´æµç¨‹

```
åˆå§‹åŒ–ï¼š
- æœåŠ¡å™¨åˆ›å»ºå…¨å±€UR4RecV2MoEæ¨¡å‹
- ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºFedMemClientï¼ˆå«æœ¬åœ°è®°å¿†ï¼‰

æ¯è½®è®­ç»ƒï¼ˆRound rï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æœåŠ¡å™¨é€‰æ‹©å®¢æˆ·ç«¯ï¼ˆclient_fraction = 10%ï¼‰          â”‚
â”‚ 2. ä¸‹å‘å…¨å±€æ¨¡å‹å‚æ•° + å…¨å±€æŠ½è±¡è®°å¿†                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼š                                     â”‚
â”‚    For each batch:                                     â”‚
â”‚      - æŸ¥è¯¢æœ¬åœ°è®°å¿†                                     â”‚
â”‚      - å‰å‘ä¼ æ’­ï¼ˆæ³¨å…¥è®°å¿†ï¼‰                             â”‚
â”‚      - è®¡ç®—rec_loss + contrastive_loss                 â”‚
â”‚      - åå‘ä¼ æ’­ï¼Œæ›´æ–°æ¨¡å‹                               â”‚
â”‚      - åŸºäºSurpriseæ›´æ–°æœ¬åœ°è®°å¿†                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. å®¢æˆ·ç«¯æå–ï¼š                                         â”‚
â”‚    - æ¨¡å‹å‚æ•°ï¼ˆstate_dictï¼‰                            â”‚
â”‚    - è®°å¿†åŸå‹ï¼ˆK-Meansä¸­å¿ƒç‚¹ï¼‰                          â”‚
â”‚ 5. ä¸Šä¼ åˆ°æœåŠ¡å™¨                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. æœåŠ¡å™¨èšåˆï¼š                                         â”‚
â”‚    - FedAvgèšåˆæ¨¡å‹å‚æ•°                                â”‚
â”‚    - å¹³å‡èšåˆè®°å¿†åŸå‹ â†’ å…¨å±€æŠ½è±¡è®°å¿†                    â”‚
â”‚ 7. æ›´æ–°å…¨å±€æ¨¡å‹                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 8. éªŒè¯é›†è¯„ä¼°                                           â”‚
â”‚ 9. Early stoppingåˆ¤æ–­                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æœ€ç»ˆæµ‹è¯•ï¼š
- åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å…¨å±€æ¨¡å‹
- è¾“å‡ºï¼šHR@K, NDCG@K, MRR
```

## å…³é”®å‚æ•°é…ç½®

```yaml
# FedMemé…ç½®ç¤ºä¾‹
fedmem:
  # è”é‚¦å­¦ä¹ å‚æ•°
  num_rounds: 50
  client_fraction: 0.1
  local_epochs: 1
  federated_lr: 0.001

  # è®°å¿†å‚æ•°
  memory_capacity: 50              # è®°å¿†å®¹é‡
  surprise_threshold: 0.5          # æƒŠå–œé˜ˆå€¼
  recency_weight: 0.6              # è¿‘æœŸæ€§æƒé‡
  frequency_weight: 0.4            # é¢‘ç‡æƒé‡

  # MoEå‚æ•°
  num_memory_prototypes: 5         # åŸå‹æ•°é‡
  contrastive_lambda: 0.1          # å¯¹æ¯”å­¦ä¹ æƒé‡

  # æ¨¡å‹å‚æ•°
  sasrec_hidden_dim: 512
  retriever_output_dim: 512
  moe_num_heads: 8
  fusion_method: 'weighted'
```

## å®éªŒæŒ‡æ ‡

### å¯¹æ¯”å®éªŒ

1. **é›†ä¸­å¼SASRecï¼ˆBaselineï¼‰**
   - HR@10: 0.40-0.41
   - NDCG@10: ~0.25

2. **è”é‚¦SASRecï¼ˆæ— è®°å¿†ï¼‰**
   - HR@10: ç›®æ ‡â‰¥0.35

3. **FedMemï¼ˆå®Œæ•´ç³»ç»Ÿï¼‰**
   - HR@10: ç›®æ ‡â‰¥0.40
   - NDCG@10: ç›®æ ‡â‰¥0.25
   - è®°å¿†æ•ˆç”¨æŒ‡æ ‡ï¼š
     - å¹³å‡è®°å¿†å¤§å°
     - è®°å¿†æ›´æ–°é¢‘ç‡
     - åŸå‹è¦†ç›–åº¦

### å…³é”®åˆ›æ–°ç‚¹

1. **Surpriseæœºåˆ¶**ï¼š
   - è‡ªé€‚åº”è®°å¿†æ›´æ–°
   - åªè®°å¿†éš¾ä»¥é¢„æµ‹çš„item
   - æé«˜è®°å¿†æ•ˆç‡

2. **Prototypeèšåˆ**ï¼š
   - éšç§ä¿æŠ¤ï¼ˆä¸ä¼ è¾“åŸå§‹æ•°æ®ï¼‰
   - çŸ¥è¯†è’¸é¦ï¼ˆå…¨å±€æŠ½è±¡è®°å¿†ï¼‰
   - è¾…åŠ©ä¸ªæ€§åŒ–æ¨è

3. **å¤šæ¨¡æ€èåˆ**ï¼š
   - æ–‡æœ¬ï¼ˆLLMç”Ÿæˆï¼‰
   - å›¾åƒï¼ˆCLIPç‰¹å¾ï¼‰
   - åºåˆ—ï¼ˆIDåµŒå…¥ï¼‰

## ä»£ç ç»“æ„

```
UR4Rec/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ local_dynamic_memory.py        # âœ… æœ¬åœ°åŠ¨æ€è®°å¿†
â”‚   â”œâ”€â”€ fedmem_client.py               # âœ… FedMemå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ fedmem_server.py               # âœ… FedMemæœåŠ¡å™¨
â”‚   â”œâ”€â”€ ur4rec_v2_moe.py               # âœ… UR4Rec MoEæ¨¡å‹ï¼ˆå·²å¢å¼ºï¼‰
â”‚   â”œâ”€â”€ federated_aggregator.py        # è”é‚¦èšåˆå™¨
â”‚   â”œâ”€â”€ sasrec.py                      # SASRecåºåˆ—æ¨¡å‹
â”‚   â””â”€â”€ text_preference_retriever_moe.py  # æ–‡æœ¬åå¥½æ£€ç´¢å™¨
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_fedmem.py                # âœ… FedMemè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_federated_ur4rec_moe.py  # æ ‡å‡†è”é‚¦UR4Recè®­ç»ƒ
â”‚   â””â”€â”€ train_sasrec_centralized.py    # é›†ä¸­å¼SASRecåŸºçº¿
â””â”€â”€ utils/
    â”œâ”€â”€ data_loader.py                 # æ•°æ®åŠ è½½å·¥å…·
    â””â”€â”€ metrics.py                     # è¯„ä¼°æŒ‡æ ‡
```

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
cd UR4Rec
pip install -r requirements.txt
```

### å‡†å¤‡æ•°æ®

```bash
# ä¸‹è½½MovieLens-1Mæ•°æ®é›†
wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
unzip ml-1m.zip -d data/

# é¢„å¤„ç†æ•°æ®
python scripts/preprocess_movielens.py --input data/ml-1m/ratings.dat --output data/ml-1m/
```

### è®­ç»ƒFedMemæ¨¡å‹

```bash
# åŸºç¡€è®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
python scripts/train_fedmem.py \
    --data_dir data/ml-1m \
    --data_file ratings.dat \
    --save_dir checkpoints/fedmem \
    --enable_prototype_aggregation \
    --verbose

# å®Œæ•´é…ç½®è®­ç»ƒ
python scripts/train_fedmem.py \
    --data_dir data/ml-1m \
    --data_file ratings.dat \
    --save_dir checkpoints/fedmem_full \
    --num_rounds 50 \
    --client_fraction 0.1 \
    --local_epochs 1 \
    --memory_capacity 50 \
    --surprise_threshold 0.5 \
    --contrastive_lambda 0.1 \
    --num_memory_prototypes 5 \
    --enable_prototype_aggregation \
    --learning_rate 0.001 \
    --batch_size 32 \
    --device cuda \
    --verbose
```

### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--num_rounds` | 50 | è”é‚¦å­¦ä¹ è½®æ•° |
| `--client_fraction` | 0.1 | æ¯è½®å‚ä¸çš„å®¢æˆ·ç«¯æ¯”ä¾‹ |
| `--memory_capacity` | 50 | æœ¬åœ°è®°å¿†å®¹é‡ |
| `--surprise_threshold` | 0.5 | Surpriseé˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤å€¼æ‰åŠ å…¥è®°å¿†ï¼‰ |
| `--contrastive_lambda` | 0.1 | å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡ |
| `--num_memory_prototypes` | 5 | è®°å¿†åŸå‹æ•°é‡ï¼ˆK-Meansèšç±»ä¸­å¿ƒæ•°ï¼‰ |
| `--enable_prototype_aggregation` | False | æ˜¯å¦å¯ç”¨åŸå‹èšåˆ |

## å¼€å‘å®ŒæˆçŠ¶æ€

### âœ… å·²å®Œæˆï¼š

1. **LocalDynamicMemory** (`local_dynamic_memory.py`) âœ…
   - [x] Surprise-basedè®°å¿†æ›´æ–°æœºåˆ¶
   - [x] æ•ˆç”¨é©±åŠ¨çš„è¿‡æœŸæœºåˆ¶
   - [x] K-MeansåŸå‹æå–
   - [x] å¤šæ¨¡æ€åµŒå…¥æ”¯æŒ

2. **FedMemClient** (`fedmem_client.py`) âœ…
   - [x] é›†æˆLocalDynamicMemory
   - [x] Surprise-basedè®°å¿†æ›´æ–°é€»è¾‘
   - [x] å¯¹æ¯”å­¦ä¹ æŸå¤±è®¡ç®—
   - [x] åŸå‹æå–ä¸ä¸Šä¼ 

3. **FedMemServer** (`fedmem_server.py`) âœ…
   - [x] åŸå‹èšåˆï¼ˆaggregate_prototypesï¼‰
   - [x] å…¨å±€æŠ½è±¡è®°å¿†åˆ†å‘ï¼ˆdistribute_global_abstract_memoryï¼‰
   - [x] FedAvgå‚æ•°èšåˆ
   - [x] è®­ç»ƒå¾ªç¯ä¸è¯„ä¼°

4. **UR4RecV2MoEå¢å¼º** (`ur4rec_v2_moe.py`) âœ…
   - [x] retrieved_memoryå‚æ•°æ”¯æŒ
   - [x] compute_contrastive_lossæ–¹æ³•
   - [x] get_item_embeddingsæ–¹æ³•

5. **è®­ç»ƒè„šæœ¬** (`train_fedmem.py`) âœ…
   - [x] å®Œæ•´çš„æ•°æ®åŠ è½½æµç¨‹
   - [x] å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨åˆ›å»º
   - [x] è®­ç»ƒå¾ªç¯
   - [x] ç»“æœä¿å­˜ä¸å¯è§†åŒ–

### ğŸ“‹ å¯é€‰å¢å¼ºï¼š

1. **æ•°æ®å¢å¼º**
   - [ ] å¤šæ•°æ®é›†æ”¯æŒï¼ˆAmazon, Yelpç­‰ï¼‰
   - [ ] æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼ˆIID vs Non-IIDï¼‰

2. **æ¨¡å‹ä¼˜åŒ–**
   - [ ] åœºæ™¯æ„ŸçŸ¥è·¯ç”±å™¨ï¼ˆæ ¹æ®ç‰©å“ç±»åˆ«åŠ¨æ€è·¯ç”±ï¼‰
   - [ ] æ›´å¤æ‚çš„è®°å¿†æ£€ç´¢æœºåˆ¶
   - [ ] è§†è§‰ç‰¹å¾é›†æˆï¼ˆCLIPå›¾åƒåµŒå…¥ï¼‰

3. **å®éªŒåˆ†æ**
   - [ ] å¯¹æ¯”å®éªŒè„šæœ¬ï¼ˆBaseline vs FedMemï¼‰
   - [ ] æ¶ˆèå®éªŒï¼ˆè®°å¿†/åŸå‹/å¯¹æ¯”å­¦ä¹ ç‹¬ç«‹æµ‹è¯•ï¼‰
   - [ ] å¯è§†åŒ–å·¥å…·ï¼ˆè®°å¿†æ¼”åŒ–ã€åŸå‹åˆ†å¸ƒç­‰ï¼‰

## ä½¿ç”¨ç¤ºä¾‹

```python
from UR4Rec.models.fedmem_client import FedMemClient
from UR4Rec.models.local_dynamic_memory import LocalDynamicMemory
from UR4Rec.models.ur4rec_v2_moe import UR4RecV2MoE

# åˆ›å»ºå…¨å±€æ¨¡å‹
global_model = UR4RecV2MoE(...)

# åˆ›å»ºFedMemå®¢æˆ·ç«¯
client = FedMemClient(
    client_id=user_id,
    model=global_model,
    user_sequence=[1, 2, 3, 4, 5],
    memory_capacity=50,
    surprise_threshold=0.5
)

# æœ¬åœ°è®­ç»ƒ
metrics = client.train_local_model(verbose=True)
print(f"Loss: {metrics['loss']:.4f}, Memory: {metrics['memory_size']}")

# æå–åŸå‹
prototypes = client.get_memory_prototypes()  # [K, emb_dim]

# è¯„ä¼°
eval_metrics = client.evaluate(split='test')
print(f"HR@10: {eval_metrics['HR@10']:.4f}")
```

## å‚è€ƒæ–‡çŒ®

æœ¬å®ç°åŸºäºä»¥ä¸‹ç ”ç©¶æ€è·¯ï¼š

1. **Federated Learning**: McMahan et al. "Communication-Efficient Learning of Deep Networks from Decentralized Data"
2. **Dynamic Memory Networks**: Kumar et al. "Ask Me Anything: Dynamic Memory Networks for NLP"
3. **Surprise-based Learning**: Achille et al. "Information Dropout: Learning Optimal Representations Through Noisy Computation"
4. **Prototype Learning**: Snell et al. "Prototypical Networks for Few-shot Learning"

## License

æœ¬é¡¹ç›®éµå¾ªMIT Licenseã€‚

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤Issueæˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚
