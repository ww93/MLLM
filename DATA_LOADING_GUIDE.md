# M_ML-100K æ•°æ®åŠ è½½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•åŠ è½½å’Œä½¿ç”¨ M_ML-100K å¤šæ¨¡æ€ MovieLens æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•é€‚é…ä»£ç ä»¥æ­£ç¡®å¤„ç†æ•°æ®æ ¼å¼ã€‚

---

## ğŸ“ æ•°æ®é›†ç»“æ„

### M_ML-100K ç›®å½•å†…å®¹

```
UR4Rec/data/Multimodal_Datasets/M_ML-100K/
â”œâ”€â”€ movies.dat          # ç”µå½±å…ƒæ•°æ®
â”œâ”€â”€ ratings.dat         # ç”¨æˆ·è¯„åˆ†
â”œâ”€â”€ text.xls            # ç”µå½±æ–‡æœ¬æè¿°ï¼ˆExcelæ ¼å¼ï¼‰
â”œâ”€â”€ user.dat            # ç”¨æˆ·ä¿¡æ¯
â””â”€â”€ image/              # ç”µå½±å›¾ç‰‡
    â”œâ”€â”€ 1.png
    â”œâ”€â”€ 2.png
    â””â”€â”€ ...
```

### æ•°æ®æ ¼å¼è¯´æ˜

#### 1. movies.dat
```
æ ¼å¼: movie_id::title::genres
åˆ†éš”ç¬¦: ::
ç¼–ç : latin-1

ç¤ºä¾‹:
1::Toy Story (1995)::Animation|Children's|Comedy
2::GoldenEye (1995)::Action|Adventure|Thriller
```

#### 2. ratings.dat
```
æ ¼å¼: user_id::movie_id::rating::timestamp
åˆ†éš”ç¬¦: ::

ç¤ºä¾‹:
196::242::3::881250949
186::302::3::891717742
```

#### 3. text.xls
```
æ ¼å¼: Excel æ–‡ä»¶
åˆ—å: ['movie-id', 'review']

éœ€è¦ pandas å’Œ xlrd è¯»å–:
pip install pandas xlrd
```

#### 4. user.dat
```
æ ¼å¼: user_id::gender::age::occupation::zip_code

ç¤ºä¾‹:
1::M::24::17::85711
2::F::53::0::94043
```

#### 5. image/
```
æ ¼å¼: {movie_id}.png
ç¤ºä¾‹: 1.png, 2.png, ...
åˆ†è¾¨ç‡: ä¸å›ºå®šï¼Œéœ€è¦resize
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°ï¼ˆæ¨èï¼‰

```python
from UR4Rec.data.dataset_loader import load_ml_100k

# ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®
item_metadata, user_sequences, users = load_ml_100k(
    data_dir="UR4Rec/data/Multimodal_Datasets",
    min_rating=4.0,      # åªä¿ç•™é«˜è¯„åˆ†
    min_seq_len=5        # æœ€å°åºåˆ—é•¿åº¦
)

print(f"ç‰©å“æ•°: {len(item_metadata)}")
print(f"ç”¨æˆ·æ•°: {len(user_sequences)}")

# æŸ¥çœ‹ç‰©å“å…ƒæ•°æ®
item = item_metadata[1]
print(f"æ ‡é¢˜: {item['title']}")
print(f"ç±»å‹: {item['genres']}")
print(f"æè¿°: {item['description']}")
```

### æ–¹æ³• 2: åˆ†æ­¥åŠ è½½ï¼ˆæ›´çµæ´»ï¼‰

```python
from UR4Rec.data.dataset_loader import MovieLensDataLoader

# åˆ›å»ºåŠ è½½å™¨
loader = MovieLensDataLoader(
    data_dir="UR4Rec/data/Multimodal_Datasets",
    dataset_name="ml-100k"
)

# åˆ†æ­¥åŠ è½½
movies = loader.load_movies()
text_descriptions = loader.load_text_descriptions()
ratings = loader.load_ratings()
users = loader.load_users()

# æ„å»ºé€‚é…æ ¼å¼
item_metadata = loader.build_item_metadata(movies, text_descriptions)
user_sequences = loader.build_user_sequences(ratings, min_rating=4.0)
```

---

## ğŸ“Š æ•°æ®æ ¼å¼é€‚é…

### è¾“å‡ºæ ¼å¼è¯´æ˜

åŠ è½½å™¨è¾“å‡ºçš„æ•°æ®æ ¼å¼å·²é€‚é… `llm_generator` å’Œ `retriever` çš„è¾“å…¥è¦æ±‚ï¼š

#### item_metadata æ ¼å¼

```python
{
    item_id (int): {
        'title': str,                    # ç”µå½±æ ‡é¢˜
        'genres': List[str],             # ç±»å‹åˆ—è¡¨
        'genres_str': str,               # ç±»å‹å­—ç¬¦ä¸²ï¼ˆç”¨|åˆ†éš”ï¼‰
        'description': str,              # æ–‡æœ¬æè¿°
        'original_id': int               # åŸå§‹ID
    }
}
```

**ç¤ºä¾‹**:
```python
item_metadata[1] = {
    'title': 'Toy Story (1995)',
    'genres': ['Animation', "Children's", 'Comedy'],
    'genres_str': "Animation|Children's|Comedy",
    'description': 'A cowboy doll is profoundly threatened...',
    'original_id': 1
}
```

#### user_sequences æ ¼å¼

```python
{
    user_id (int): [item_id1, item_id2, item_id3, ...]  # æŒ‰æ—¶é—´æ’åº
}
```

**ç¤ºä¾‹**:
```python
user_sequences[298] = [286, 172, 588, 174, 69, 603, ...]
```

---

## ğŸ”„ åˆ›å»º PyTorch DataLoader

### æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°

```python
from UR4Rec.data.multimodal_dataset import create_dataloaders

# åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯• DataLoader
train_loader, val_loader, test_loader = create_dataloaders(
    user_sequences=user_sequences,
    item_metadata=item_metadata,
    image_dir="UR4Rec/data/Multimodal_Datasets/M_ML-100K/image",
    batch_size=128,
    num_workers=4,
    load_images=False,    # æ˜¯å¦åŠ è½½å›¾ç‰‡ï¼ˆè®­ç»ƒæ—¶è®¾ä¸ºTrueï¼‰
    max_seq_len=50,
    num_negatives=5
)

# è®­ç»ƒå¾ªç¯
for epoch in range(10):
    for batch in train_loader:
        user_ids = batch['user_ids']
        input_seq = batch['input_seq']           # [batch, max_seq_len]
        target_items = batch['target_items']      # [batch]
        negative_items = batch['negative_items']  # [batch, num_neg]

        # å¦‚æœ load_images=True
        # target_images = batch['target_images']    # [batch, 3, H, W]
        # negative_images = batch['negative_images'] # [batch, num_neg, 3, H, W]

        # è®­ç»ƒä»£ç ...
```

### æ–¹æ³• 2: æ‰‹åŠ¨åˆ›å»º

```python
from UR4Rec.data.multimodal_dataset import SequenceRecommendationDataset, MultimodalCollator
from torch.utils.data import DataLoader

# åˆ›å»ºæ•°æ®é›†
dataset = SequenceRecommendationDataset(
    user_sequences=user_sequences,
    item_metadata=item_metadata,
    image_dir="UR4Rec/data/Multimodal_Datasets/M_ML-100K/image",
    max_seq_len=50,
    num_negatives=5,
    mode="train"
)

# åˆ›å»º collator
collator = MultimodalCollator(dataset, load_images=True)

# åˆ›å»º DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=128,
    shuffle=True,
    num_workers=4,
    collate_fn=collator,
    pin_memory=True
)
```

---

## ğŸ¤– ä½¿ç”¨ LLM ç”Ÿæˆ

### ç”Ÿæˆç”¨æˆ·åå¥½

```python
from UR4Rec.models.llm_generator import LLMPreferenceGenerator
import os

# åˆ›å»ºç”Ÿæˆå™¨
generator = LLMPreferenceGenerator(
    llm_backend="openai",
    model_name="qwen-flash",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ç”Ÿæˆå•ä¸ªç”¨æˆ·åå¥½
user_id = 1
user_history = user_sequences[user_id]

preference = generator.generate_user_preference(
    user_id=user_id,
    user_history=user_history,
    item_metadata=item_metadata
)

print(f"ç”¨æˆ·åå¥½: {preference}")
```

### æ‰¹é‡ç”Ÿæˆ

```python
# å‡†å¤‡ç”¨æˆ·æ•°æ®
users_data = [
    {"user_id": uid, "user_history": seq}
    for uid, seq in user_sequences.items()
]

# æ‰¹é‡ç”Ÿæˆç”¨æˆ·åå¥½
generator.batch_generate_user_preferences(
    users_data=users_data,
    item_metadata=item_metadata,
    save_path="data/llm_generated/user_preferences.json"
)

# æ‰¹é‡ç”Ÿæˆç‰©å“æè¿°
generator.batch_generate_item_descriptions(
    item_metadata=item_metadata,
    save_path="data/llm_generated/item_descriptions.json"
)
```

---

## ğŸ“ˆ å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹

```python
from UR4Rec.data.dataset_loader import load_ml_100k
from UR4Rec.data.multimodal_dataset import create_dataloaders
from UR4Rec.models.ur4rec_v2 import UR4RecV2
from UR4Rec.models.joint_trainer import JointTrainer

# 1. åŠ è½½æ•°æ®
print("åŠ è½½æ•°æ®...")
item_metadata, user_sequences, users = load_ml_100k(
    min_rating=4.0,
    min_seq_len=5
)

# 2. åˆ›å»º DataLoaders
print("åˆ›å»º DataLoaders...")
train_loader, val_loader, test_loader = create_dataloaders(
    user_sequences=user_sequences,
    item_metadata=item_metadata,
    image_dir="UR4Rec/data/Multimodal_Datasets/M_ML-100K/image",
    batch_size=128,
    load_images=True,  # å¤šæ¨¡æ€è®­ç»ƒ
    max_seq_len=50,
    num_negatives=5
)

# 3. åˆ›å»ºæ¨¡å‹
print("åˆ›å»ºæ¨¡å‹...")
model = UR4RecV2(
    num_items=len(item_metadata) + 1,  # +1 for padding
    sasrec_hidden_dim=256,
    text_embedding_dim=384,
    retriever_output_dim=256,
    device='cuda'
)

# 4. åˆ›å»ºè®­ç»ƒå™¨ï¼ˆå¯ç”¨è‡ªé€‚åº”äº¤æ›¿è®­ç»ƒï¼‰
print("åˆ›å»ºè®­ç»ƒå™¨...")
trainer = JointTrainer(
    model=model,
    device='cuda',
    sasrec_lr=1e-3,
    retriever_lr=1e-4,
    use_adaptive_alternating=True,
    adaptive_switch_threshold=0.01,
    adaptive_min_steps=5
)

# 5. å››é˜¶æ®µè®­ç»ƒ
print("\n=== é˜¶æ®µ1: é¢„è®­ç»ƒ SASRec ===")
trainer.set_training_stage("pretrain_sasrec")
for epoch in range(1, 6):
    metrics = trainer.train_epoch(train_loader, epoch)
    print(f"Epoch {epoch} - Loss: {metrics['total_loss']:.4f}")

print("\n=== é˜¶æ®µ2: é¢„è®­ç»ƒ Retriever ===")
trainer.set_training_stage("pretrain_retriever")
for epoch in range(6, 11):
    metrics = trainer.train_epoch(train_loader, epoch)
    print(f"Epoch {epoch} - Loss: {metrics['total_loss']:.4f}")

print("\n=== é˜¶æ®µ3: è”åˆå¾®è°ƒï¼ˆè‡ªé€‚åº”äº¤æ›¿ï¼‰ ===")
trainer.set_training_stage("joint_finetune")
for epoch in range(11, 21):
    metrics = trainer.train_epoch(train_loader, epoch)
    stats = trainer.adaptive_alternating.get_stats()
    print(f"Epoch {epoch}:")
    print(f"  Loss: {metrics['total_loss']:.4f}")
    print(f"  åˆ‡æ¢æ¬¡æ•°: {stats['switch_count']}")
    print(f"  å½“å‰æ¨¡å—: {stats['current_module']}")

    # éªŒè¯
    if epoch % 5 == 0:
        val_metrics = trainer.evaluate(val_loader)
        print(f"  Hit@10: {val_metrics['hit@10']:.4f}")

print("\n=== é˜¶æ®µ4: ç«¯åˆ°ç«¯è®­ç»ƒ ===")
trainer.set_training_stage("end_to_end")
for epoch in range(21, 26):
    metrics = trainer.train_epoch(train_loader, epoch)
    val_metrics = trainer.evaluate(val_loader)
    print(f"Epoch {epoch} - Loss: {metrics['total_loss']:.4f}, "
          f"Hit@10: {val_metrics['hit@10']:.4f}")

# 6. æœ€ç»ˆæµ‹è¯•
print("\n=== æœ€ç»ˆæµ‹è¯• ===")
test_metrics = trainer.evaluate(test_loader)
print(f"Hit@10: {test_metrics['hit@10']:.4f}")
print(f"NDCG@10: {test_metrics['ndcg@10']:.4f}")
print(f"MRR: {test_metrics['mrr']:.4f}")

# 7. ä¿å­˜æ¨¡å‹
trainer.save_checkpoint("checkpoints/final_model.pt", epoch=25, metrics=test_metrics)
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†ç¼ºå¤±çš„æ–‡æœ¬æè¿°ï¼Ÿ

**è§£å†³æ–¹æ³•**ï¼šå¦‚æœ text.xls ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–ï¼ŒåŠ è½½å™¨ä¼šè‡ªåŠ¨ä½¿ç”¨æ ‡é¢˜å’Œç±»å‹ç”Ÿæˆæè¿°ï¼š

```python
# å¦‚æœæ²¡æœ‰æè¿°ï¼Œè‡ªåŠ¨ç”Ÿæˆ
description = f"{title}. Genres: {', '.join(genres)}"
```

### Q2: å›¾ç‰‡åŠ è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ³•**ï¼šMultimodalCollator ä¼šè‡ªåŠ¨å¤„ç†ç¼ºå¤±çš„å›¾ç‰‡ï¼š

```python
if image is None:
    # ä½¿ç”¨é›¶å¼ é‡ä»£æ›¿
    image = torch.zeros(3, H, W)
```

### Q3: å¦‚ä½•åªä½¿ç”¨æ–‡æœ¬ä¸ä½¿ç”¨å›¾ç‰‡ï¼Ÿ

**è§£å†³æ–¹æ³•**ï¼šè®¾ç½® `load_images=False`ï¼š

```python
train_loader, val_loader, test_loader = create_dataloaders(
    ...,
    load_images=False  # ä¸åŠ è½½å›¾ç‰‡
)
```

### Q4: pandas æˆ– xlrd æœªå®‰è£…

**è§£å†³æ–¹æ³•**ï¼š
```bash
pip install pandas xlrd
```

å¦‚æœä»ç„¶æ— æ³•è¯»å– text.xlsï¼ŒåŠ è½½å™¨ä¼šè·³è¿‡å¹¶ä½¿ç”¨æ ‡é¢˜+ç±»å‹ä½œä¸ºæè¿°ã€‚

### Q5: åºåˆ—å¤ªé•¿æˆ–å¤ªçŸ­

**è§£å†³æ–¹æ³•**ï¼šè°ƒæ•´å‚æ•°ï¼š

```python
# è°ƒæ•´æœ€å°åºåˆ—é•¿åº¦
user_sequences = loader.build_user_sequences(
    ratings,
    min_rating=4.0,
    min_seq_len=3  # é™ä½æœ€å°é•¿åº¦
)

# è°ƒæ•´æœ€å¤§åºåˆ—é•¿åº¦
dataset = SequenceRecommendationDataset(
    ...,
    max_seq_len=100  # å¢åŠ æœ€å¤§é•¿åº¦
)
```

---

## ğŸ“ æ•°æ®ç»Ÿè®¡

### M_ML-100K æ•°æ®é›†

è¿è¡Œç¤ºä¾‹åçš„ç»Ÿè®¡æ•°æ®ï¼š

```
ç‰©å“æ•°: 1659
ç”¨æˆ·æ•°: 943
è¯„åˆ†æ•°: 99309
ç”¨æˆ·åºåˆ—æ•°: 938 (min_rating=4.0, min_seq_len=5)
é«˜è¯„åˆ†è®°å½•: 55024
å›¾ç‰‡å¯ç”¨æ€§: 100% (1659/1659)
```

---

## ğŸ¯ æ€»ç»“

âœ… **æ•°æ®åŠ è½½é€‚é…å™¨å®Œæˆ**
- [UR4Rec/data/dataset_loader.py](UR4Rec/data/dataset_loader.py)
- æ”¯æŒ M_ML-100K å’Œ M_ML-1M æ ¼å¼
- è‡ªåŠ¨å¤„ç† Excelã€å›¾ç‰‡ç­‰å¤šæ¨¡æ€æ•°æ®

âœ… **PyTorch Dataset å®Œæˆ**
- [UR4Rec/data/multimodal_dataset.py](UR4Rec/data/multimodal_dataset.py)
- æ”¯æŒåºåˆ—æ¨èã€è´Ÿæ ·æœ¬é‡‡æ ·
- æ”¯æŒæ–‡æœ¬å’Œå›¾åƒç‰¹å¾

âœ… **å®Œå…¨å…¼å®¹ç°æœ‰ä»£ç **
- llm_generator æ— éœ€ä¿®æ”¹ï¼Œç›´æ¥ä½¿ç”¨
- retriever æ— éœ€ä¿®æ”¹ï¼Œç›´æ¥ä½¿ç”¨
- joint_trainer æ— éœ€ä¿®æ”¹ï¼Œç›´æ¥ä½¿ç”¨

âœ… **å®Œæ•´æµ‹è¯•é€šè¿‡**
- æ•°æ®åŠ è½½æµ‹è¯•ï¼šâœ“
- Dataset æµ‹è¯•ï¼šâœ“
- DataLoader æµ‹è¯•ï¼šâœ“
- ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šâœ“

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- [UR4Rec/data/dataset_loader.py](UR4Rec/data/dataset_loader.py) - æ•°æ®åŠ è½½é€‚é…å™¨
- [UR4Rec/data/multimodal_dataset.py](UR4Rec/data/multimodal_dataset.py) - PyTorch Dataset
- [example_data_loading.py](example_data_loading.py) - å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
- [UR4Rec/scripts/preprocess_multimodal_dataset.py](UR4Rec/scripts/preprocess_multimodal_dataset.py) - æ•°æ®é¢„å¤„ç†è„šæœ¬
- [QWEN_FLASH_USAGE.md](QWEN_FLASH_USAGE.md) - LLM ç”ŸæˆæŒ‡å—
- [ADAPTIVE_TRAINING_GUIDE.md](ADAPTIVE_TRAINING_GUIDE.md) - è‡ªé€‚åº”è®­ç»ƒæŒ‡å—

---

*åˆ›å»ºæ—¶é—´: 2025-12-09*
