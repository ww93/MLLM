# UR4Rec V2 å®Œæ•´å·¥ä½œæµç¨‹

æœ¬æ–‡æ¡£æè¿° UR4Rec V2 çš„å®Œæ•´æ•°æ®å¤„ç†å’Œè®­ç»ƒæµç¨‹ã€‚

---

## ğŸ“‹ æ€»ä½“æµç¨‹å›¾

```
Step 1: æ•°æ®é¢„å¤„ç†
    â”œâ”€â”€ ä¸‹è½½åŸå§‹æ•°æ®
    â”œâ”€â”€ æ„å»ºç”¨æˆ·åºåˆ—
    â”œâ”€â”€ åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
    â””â”€â”€ ç”Ÿæˆç‰©å“å…ƒæ•°æ®
         â†“
Step 2: å›¾ç‰‡æ•°æ®å‡†å¤‡ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ ä¸‹è½½ç‰©å“å›¾ç‰‡
    â””â”€â”€ æå– CLIP ç‰¹å¾
         â†“
Step 3: LLM æ•°æ®ç”Ÿæˆ
    â”œâ”€â”€ ç”Ÿæˆç”¨æˆ·åå¥½æ–‡æœ¬
    â””â”€â”€ ç”Ÿæˆç‰©å“æè¿°æ–‡æœ¬
         â†“
Step 4: æ¨¡å‹è®­ç»ƒ
    â”œâ”€â”€ Stage 1: é¢„è®­ç»ƒ SASRec
    â”œâ”€â”€ Stage 2: é¢„è®­ç»ƒæ£€ç´¢å™¨
    â”œâ”€â”€ Stage 3: è”åˆå¾®è°ƒ
    â””â”€â”€ Stage 4: ç«¯åˆ°ç«¯ä¼˜åŒ–
         â†“
Step 5: æ¨¡å‹è¯„ä¼°
    â”œâ”€â”€ æµ‹è¯•é›†è¯„ä¼°
    â””â”€â”€ ç”Ÿæˆæ¨èç»“æœ
```

---

## ğŸš€ è¯¦ç»†æ­¥éª¤

### Step 1: æ•°æ®é¢„å¤„ç†

#### 1.1 MovieLens æ•°æ®é›†

```bash
# MovieLens-100K
python scripts/preprocess_movielens.py \
    --dataset ml-100k \
    --output_dir data/ml-100k \
    --num_candidates 100

# MovieLens-1M
python scripts/preprocess_movielens.py \
    --dataset ml-1m \
    --output_dir data/ml-1m \
    --num_candidates 100
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/ml-100k/
â”œâ”€â”€ train_sequences.npy      # è®­ç»ƒåºåˆ— {user_id: [item_ids]}
â”œâ”€â”€ val_sequences.npy        # éªŒè¯åºåˆ—
â”œâ”€â”€ test_sequences.npy       # æµ‹è¯•åºåˆ—
â”œâ”€â”€ item_metadata.json       # ç‰©å“å…ƒæ•°æ® {item_id: {title, genres}}
â”œâ”€â”€ item_map.json           # ç‰©å“IDæ˜ å°„ {original_id: new_id}
â”œâ”€â”€ user_map.json           # ç”¨æˆ·IDæ˜ å°„
â””â”€â”€ stats.json              # æ•°æ®ç»Ÿè®¡
```

#### 1.2 Amazon Beauty æ•°æ®é›†

```bash
python scripts/preprocess_beauty.py \
    --input_file data/raw/beauty.json \
    --output_dir data/beauty \
    --num_candidates 100
```

**è¾“å‡ºæ–‡ä»¶ç»“æ„åŒä¸Š**

---

### Step 2: å›¾ç‰‡æ•°æ®å‡†å¤‡ï¼ˆå¯é€‰ï¼Œç”¨äºå¤šæ¨¡æ€ï¼‰

#### 2.1 ä¸‹è½½å›¾ç‰‡

**MovieLensï¼ˆéœ€è¦ TMDB APIï¼‰**ï¼š

```bash
# è·å– TMDB API å¯†é’¥: https://www.themoviedb.org/settings/api

python scripts/download_images.py \
    --dataset movielens \
    --item_metadata data/ml-100k/item_metadata.json \
    --output_dir data/ml-100k/images \
    --tmdb_api_key YOUR_API_KEY

# æˆ–ä½¿ç”¨å ä½å›¾ç‰‡ï¼ˆæ— éœ€ APIï¼‰
python scripts/download_images.py \
    --dataset movielens \
    --item_metadata data/ml-100k/item_metadata.json \
    --output_dir data/ml-100k/images
```

**Amazon Beautyï¼ˆä»å…ƒæ•°æ®ä¸­çš„ URL ä¸‹è½½ï¼‰**ï¼š

```bash
python scripts/download_images.py \
    --dataset amazon \
    --item_metadata data/beauty/item_metadata.json \
    --output_dir data/beauty/images
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/ml-100k/images/
â”œâ”€â”€ 1.jpg                  # ç‰©å“ 1 çš„å›¾ç‰‡
â”œâ”€â”€ 2.jpg
â”œâ”€â”€ ...
â””â”€â”€ download_log.json      # ä¸‹è½½æ—¥å¿—
```

#### 2.2 æå–å›¾ç‰‡ç‰¹å¾ï¼ˆä½¿ç”¨ CLIPï¼‰

```bash
# æå– CLIP ç‰¹å¾
python scripts/preprocess_images.py \
    --image_dir data/ml-100k/images \
    --output_path data/ml-100k/image_features.pt \
    --mode clip \
    --batch_size 32

# æˆ–åˆ›å»ºè°ƒæ•´å¤§å°åçš„å›¾ç‰‡ç¼“å­˜
python scripts/preprocess_images.py \
    --image_dir data/ml-100k/images \
    --output_path data/ml-100k/images_224 \
    --mode resize \
    --target_size 224 224
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/ml-100k/
â”œâ”€â”€ image_features.pt         # CLIP ç‰¹å¾ {embeddings, ids, features_dict}
â””â”€â”€ images_224/               # æˆ–è°ƒæ•´å¤§å°åçš„å›¾ç‰‡
    â”œâ”€â”€ 1.jpg
    â”œâ”€â”€ 2.jpg
    â””â”€â”€ ...
```

---

### Step 3: LLM æ•°æ®ç”Ÿæˆ

#### 3.1 ä½¿ç”¨ Mock ç”Ÿæˆå™¨ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰

```bash
python scripts/generate_llm_data.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --output_dir data/ml-100k/llm_generated \
    --llm_backend mock
```

#### 3.2 ä½¿ç”¨ OpenAI GPT

```bash
export OPENAI_API_KEY="your-api-key"

python scripts/generate_llm_data.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --output_dir data/ml-100k/llm_generated \
    --llm_backend openai \
    --model_name gpt-3.5-turbo \
    --api_key $OPENAI_API_KEY
```

#### 3.3 ä½¿ç”¨ Anthropic Claude

```bash
export ANTHROPIC_API_KEY="your-api-key"

python scripts/generate_llm_data.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --output_dir data/ml-100k/llm_generated \
    --llm_backend anthropic \
    --model_name claude-3-haiku-20240307 \
    --api_key $ANTHROPIC_API_KEY
```

#### 3.4 é™åˆ¶ç”Ÿæˆæ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰

```bash
python scripts/generate_llm_data.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --output_dir data/ml-100k/llm_generated \
    --llm_backend mock \
    --max_users 100 \
    --max_items 500
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/ml-100k/llm_generated/
â”œâ”€â”€ user_preferences.json     # {"user_1": "è¯¥ç”¨æˆ·å–œæ¬¢åŠ¨ä½œå’Œç§‘å¹»ç”µå½±..."}
â””â”€â”€ item_descriptions.json    # {"item_1": "ä¸€éƒ¨ç»å…¸çš„ç§‘å¹»åŠ¨ä½œç‰‡..."}
```

---

### Step 4: æ¨¡å‹è®­ç»ƒ

#### 4.1 æ–‡æœ¬æ¨¡æ€è®­ç»ƒï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰

```bash
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k \
    --epochs_per_stage 10 \
    --device cuda
```

#### 4.2 å¤šæ¨¡æ€è®­ç»ƒï¼ˆæ–‡æœ¬+å›¾åƒï¼‰

```bash
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k-multimodal \
    --use_multimodal \
    --epochs_per_stage 10 \
    --device cuda
```

#### 4.3 è‡ªå®šä¹‰è®­ç»ƒé˜¶æ®µ

```bash
# åªé¢„è®­ç»ƒ SASRec
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k-sasrec \
    --stages pretrain_sasrec \
    --epochs_per_stage 20

# å®Œæ•´å››é˜¶æ®µè®­ç»ƒ
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k-full \
    --stages pretrain_sasrec pretrain_retriever joint_finetune end_to_end \
    --epochs_per_stage 15 \
    --patience 5
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
outputs/ml-100k/
â”œâ”€â”€ pretrain_sasrec_best.pt      # é˜¶æ®µ1æœ€ä½³æ¨¡å‹
â”œâ”€â”€ pretrain_retriever_best.pt   # é˜¶æ®µ2æœ€ä½³æ¨¡å‹
â”œâ”€â”€ joint_finetune_best.pt       # é˜¶æ®µ3æœ€ä½³æ¨¡å‹
â”œâ”€â”€ end_to_end_best.pt           # é˜¶æ®µ4æœ€ä½³æ¨¡å‹
â”œâ”€â”€ final_model.pt               # æœ€ç»ˆæ¨¡å‹
â”œâ”€â”€ results.json                 # è®­ç»ƒç»“æœå’ŒæŒ‡æ ‡
â””â”€â”€ checkpoints/                 # è®­ç»ƒæ£€æŸ¥ç‚¹
```

---

### Step 5: æ¨¡å‹è¯„ä¼°

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼Œç»“æœä¿å­˜åœ¨ `results.json` ä¸­ã€‚

**è¯„ä¼°æŒ‡æ ‡**ï¼š
- `hit@5`, `hit@10`, `hit@20` - å‘½ä¸­ç‡
- `ndcg@5`, `ndcg@10`, `ndcg@20` - å½’ä¸€åŒ–æŠ˜æ‰£ç´¯ç§¯å¢ç›Š
- `mrr` - å¹³å‡å€’æ•°æ’å

---

## ğŸ”„ å®Œæ•´æµç¨‹ç¤ºä¾‹

### MovieLens-100K å®Œæ•´è®­ç»ƒæµç¨‹

```bash
# 1. æ•°æ®é¢„å¤„ç†
python scripts/preprocess_movielens.py \
    --dataset ml-100k \
    --output_dir data/ml-100k \
    --num_candidates 100

# 2. ï¼ˆå¯é€‰ï¼‰ä¸‹è½½å›¾ç‰‡
python scripts/download_images.py \
    --dataset movielens \
    --item_metadata data/ml-100k/item_metadata.json \
    --output_dir data/ml-100k/images \
    --tmdb_api_key YOUR_KEY  # æˆ–çœç•¥ä½¿ç”¨å ä½å›¾ç‰‡

# 3. ï¼ˆå¯é€‰ï¼‰æå–å›¾ç‰‡ç‰¹å¾
python scripts/preprocess_images.py \
    --image_dir data/ml-100k/images \
    --output_path data/ml-100k/image_features.pt \
    --mode clip

# 4. ç”Ÿæˆ LLM æ•°æ®
python scripts/generate_llm_data.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --output_dir data/ml-100k/llm_generated \
    --llm_backend mock

# 5. è®­ç»ƒæ¨¡å‹ï¼ˆæ–‡æœ¬æ¨¡æ€ï¼‰
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k \
    --epochs_per_stage 10

# 6. ï¼ˆå¯é€‰ï¼‰è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹
python scripts/train_v2.py \
    --config configs/movielens_100k.yaml \
    --data_dir data/ml-100k \
    --llm_data_dir data/ml-100k/llm_generated \
    --output_dir outputs/ml-100k-multimodal \
    --use_multimodal \
    --epochs_per_stage 10
```

---

## âš™ï¸ æ ¸å¿ƒæ¨¡å—è¯´æ˜

### æ•°æ®å¤„ç†æ¨¡å—

| è„šæœ¬ | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|-----|------|------|------|
| `preprocess_movielens.py` | MovieLens æ•°æ®é¢„å¤„ç† | åŸå§‹è¯„åˆ†æ•°æ® | åºåˆ— + å…ƒæ•°æ® |
| `preprocess_beauty.py` | Amazon æ•°æ®é¢„å¤„ç† | JSON æ•°æ® | åºåˆ— + å…ƒæ•°æ® |
| `download_images.py` | ä¸‹è½½ç‰©å“å›¾ç‰‡ | å…ƒæ•°æ® | å›¾ç‰‡æ–‡ä»¶ |
| `preprocess_images.py` | æå–å›¾ç‰‡ç‰¹å¾ | å›¾ç‰‡æ–‡ä»¶ | CLIP ç‰¹å¾ |
| `generate_llm_data.py` | LLM æ•°æ®ç”Ÿæˆ | åºåˆ— + å…ƒæ•°æ® | æ–‡æœ¬æè¿° |

### æ¨¡å‹æ¨¡å—

| æ–‡ä»¶ | åŠŸèƒ½ | è¯´æ˜ |
|-----|------|------|
| `models/sasrec.py` | SASRec åºåˆ—æ¨¡å‹ | åŸºäº Transformer çš„åºåˆ—æ¨è |
| `models/text_preference_retriever.py` | æ–‡æœ¬æ£€ç´¢å™¨ | ä½¿ç”¨ Sentence-BERT ç¼–ç æ–‡æœ¬ |
| `models/multimodal_retriever.py` | å¤šæ¨¡æ€æ£€ç´¢å™¨ | æ–‡æœ¬+å›¾åƒè·¨æ¨¡æ€æ£€ç´¢ |
| `models/ur4rec_v2.py` | UR4Rec æ•´åˆæ¨¡å‹ | èåˆ SASRec å’Œæ£€ç´¢å™¨ |
| `models/llm_generator.py` | LLM ç”Ÿæˆå™¨ | ç¦»çº¿ç”Ÿæˆåå¥½æè¿° |

### è®­ç»ƒæ¨¡å—

| æ–‡ä»¶ | åŠŸèƒ½ | è¯´æ˜ |
|-----|------|------|
| `models/multimodal_loss.py` | å¤šæ¨¡æ€æŸå¤±å‡½æ•° | æ£€ç´¢/ä¸€è‡´æ€§/å¯¹æ¯”/å¤šæ ·æ€§æŸå¤± |
| `models/joint_trainer.py` | è”åˆè®­ç»ƒå™¨ | å¤šé˜¶æ®µè®­ç»ƒç®¡ç† |
| `scripts/train_v2.py` | ä¸»è®­ç»ƒè„šæœ¬ | å®Œæ•´è®­ç»ƒæµç¨‹ |

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ•°æ®é¢„å¤„ç†å¤±è´¥

**é—®é¢˜**: `FileNotFoundError: [Errno 2] No such file or directory`

**è§£å†³**:
```bash
# æ£€æŸ¥åŸå§‹æ•°æ®æ˜¯å¦å­˜åœ¨
ls data/raw/

# MovieLens ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œç¡®ä¿æœ‰ç½‘ç»œè¿æ¥
# Amazon éœ€è¦æ‰‹åŠ¨ä¸‹è½½æ•°æ®æ–‡ä»¶
```

### Q2: å›¾ç‰‡ä¸‹è½½å¤±è´¥

**é—®é¢˜**: TMDB API è¿”å› 401 Unauthorized

**è§£å†³**:
```bash
# æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®
echo $TMDB_API_KEY

# æˆ–ä½¿ç”¨å ä½å›¾ç‰‡ï¼ˆæ— éœ€ APIï¼‰
python scripts/download_images.py \
    --dataset movielens \
    --item_metadata data/ml-100k/item_metadata.json \
    --output_dir data/ml-100k/images
    # ä¸æä¾› --tmdb_api_key
```

### Q3: CLIP ç‰¹å¾æå–å†…å­˜ä¸è¶³

**é—®é¢˜**: `CUDA out of memory`

**è§£å†³**:
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python scripts/preprocess_images.py \
    --image_dir data/ml-100k/images \
    --output_path data/ml-100k/image_features.pt \
    --mode clip \
    --batch_size 8  # ä» 32 é™ä½åˆ° 8

# æˆ–ä½¿ç”¨ CPU
python scripts/preprocess_images.py \
    --image_dir data/ml-100k/images \
    --output_path data/ml-100k/image_features.pt \
    --mode clip \
    --device cpu
```

### Q4: LLM æ•°æ®ç”Ÿæˆå¤ªæ…¢

**é—®é¢˜**: OpenAI API è°ƒç”¨å¾ˆæ…¢

**è§£å†³**:
```bash
# æ–¹æ¡ˆ1: ä½¿ç”¨ Mock ç”Ÿæˆå™¨
--llm_backend mock

# æ–¹æ¡ˆ2: é™åˆ¶ç”Ÿæˆæ•°é‡
--max_users 500 --max_items 1000

# æ–¹æ¡ˆ3: ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
--model_name gpt-3.5-turbo  # ä»£æ›¿ gpt-4
```

### Q5: è®­ç»ƒæ˜¾å­˜ä¸è¶³

**é—®é¢˜**: `RuntimeError: CUDA out of memory`

**è§£å†³**: åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´å‚æ•°
```yaml
training:
  train_batch_size: 16  # ä» 32 é™ä½
  eval_batch_size: 32   # ä» 64 é™ä½

model:
  sasrec_hidden_dim: 128  # ä» 256 é™ä½
  retriever_output_dim: 128  # ä» 256 é™ä½
```

---

## ğŸ“Š æ•°æ®æµè¯¦è§£

### è®­ç»ƒæ—¶çš„æ•°æ®æµ

```
1. åŠ è½½åºåˆ—æ•°æ®
   train_sequences.npy â†’ {user_id: [item_1, item_2, ..., item_n]}

2. é‡‡æ ·è®­ç»ƒæ ·æœ¬
   ç”¨æˆ·åºåˆ— â†’ è¾“å…¥åºåˆ—(å‰n-1) + ç›®æ ‡ç‰©å“(ç¬¬nä¸ª) + è´Ÿæ ·æœ¬(éšæœº)

3. LLM æ–‡æœ¬æ•°æ®
   user_preferences.json â†’ æŸ¥æ‰¾ç”¨æˆ·åå¥½æ–‡æœ¬
   item_descriptions.json â†’ æŸ¥æ‰¾ç‰©å“æè¿°æ–‡æœ¬

4. æ¨¡å‹å‰å‘ä¼ æ’­
   SASRec: è¾“å…¥åºåˆ— â†’ åºåˆ—è¡¨ç¤º â†’ å€™é€‰ç‰©å“åˆ†æ•°
   æ£€ç´¢å™¨: åå¥½æ–‡æœ¬ â†’ åå¥½å‘é‡ â†’ ç‰©å“åŒ¹é…åˆ†æ•°
   èåˆ: SASRecåˆ†æ•° + æ£€ç´¢å™¨åˆ†æ•° â†’ æœ€ç»ˆåˆ†æ•°

5. æŸå¤±è®¡ç®—
   BPRæŸå¤±: -log(sigmoid(æ­£æ ·æœ¬åˆ†æ•° - è´Ÿæ ·æœ¬åˆ†æ•°))
   æ£€ç´¢æŸå¤±: BCE(æ£€ç´¢åˆ†æ•°, æ ‡ç­¾)

6. åå‘ä¼ æ’­
   æ ¹æ®è®­ç»ƒé˜¶æ®µæ›´æ–°å¯¹åº”å‚æ•°
```

### æ¨ç†æ—¶çš„æ•°æ®æµ

```
1. è¾“å…¥
   - ç”¨æˆ·ID
   - ç”¨æˆ·å†å²åºåˆ—
   - å€™é€‰ç‰©å“åˆ—è¡¨

2. SASRec åˆ†æ•°
   å†å²åºåˆ— â†’ Transformer â†’ åºåˆ—è¡¨ç¤º â†’ å€™é€‰ç‰©å“åˆ†æ•°

3. æ£€ç´¢å™¨åˆ†æ•°
   ç”¨æˆ·ID â†’ æŸ¥æ‰¾åå¥½æ–‡æœ¬ â†’ æ–‡æœ¬ç¼–ç  â†’ åå¥½å‘é‡
   å€™é€‰ç‰©å“ â†’ ç‰©å“åµŒå…¥ â†’ ç‰©å“å‘é‡
   ä½™å¼¦ç›¸ä¼¼åº¦(åå¥½å‘é‡, ç‰©å“å‘é‡) â†’ æ£€ç´¢åˆ†æ•°

4. èåˆ
   åŠ æƒèåˆ: Î± * SASRecåˆ†æ•° + Î² * æ£€ç´¢åˆ†æ•° â†’ æœ€ç»ˆåˆ†æ•°

5. æ’åº
   æ ¹æ®æœ€ç»ˆåˆ†æ•°å¯¹å€™é€‰ç‰©å“æ’åº â†’ Top-K æ¨èåˆ—è¡¨
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å¿«é€Ÿæµ‹è¯•æµç¨‹

```bash
# ä½¿ç”¨æœ€å°æ•°æ®é›†å¿«é€ŸéªŒè¯
python scripts/preprocess_movielens.py --dataset ml-100k --output_dir data/ml-100k
python scripts/generate_llm_data.py --llm_backend mock --max_users 100 --max_items 500 ...
python scripts/train_v2.py --epochs_per_stage 2 ...
```

### 2. å®Œæ•´è®­ç»ƒæµç¨‹

```bash
# ä½¿ç”¨å®Œæ•´æ•°æ® + çœŸå® LLM
python scripts/preprocess_movielens.py --dataset ml-1m --output_dir data/ml-1m
python scripts/generate_llm_data.py --llm_backend openai --api_key $OPENAI_API_KEY ...
python scripts/train_v2.py --epochs_per_stage 20 --patience 10 ...
```

### 3. å¤šæ¨¡æ€è®­ç»ƒå»ºè®®

```bash
# 1. å…ˆè®­ç»ƒçº¯æ–‡æœ¬æ¨¡å‹ï¼ˆéªŒè¯åŸºç¡€æ¶æ„ï¼‰
python scripts/train_v2.py --output_dir outputs/text_only

# 2. ä¸‹è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
python scripts/download_images.py ...
python scripts/preprocess_images.py ...

# 3. è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹
python scripts/train_v2.py --use_multimodal --output_dir outputs/multimodal
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [README_CN.md](README_CN.md) - é¡¹ç›®æ€»è§ˆ
- [QUICKSTART_CN.md](QUICKSTART_CN.md) - å¿«é€Ÿå¼€å§‹æŒ‡å—
- [TRAINING_GUIDE.md](TRAINING_GUIDE.md) - è¯¦ç»†è®­ç»ƒæ•™ç¨‹
- [REFACTORING_PROGRESS.md](REFACTORING_PROGRESS.md) - é‡æ„è¿›åº¦å’Œæ¶æ„è¯´æ˜
- [RETRIEVER_ANALYSIS.md](RETRIEVER_ANALYSIS.md) - æ£€ç´¢å™¨è®¾è®¡åˆ†æ

---

**æœ€åæ›´æ–°**: 2025-11-27
