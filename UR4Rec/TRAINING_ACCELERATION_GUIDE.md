# FedDMMR è®­ç»ƒåŠ é€Ÿä¼˜åŒ–æŒ‡å—

## ğŸ“Š ä¼˜åŒ–æ€»ç»“

æœ¬æ–‡æ¡£è®°å½•äº†é’ˆå¯¹ A2000 GPU çš„ä¸‰å¤§è®­ç»ƒåŠ é€Ÿä¼˜åŒ–ï¼Œé¢„æœŸæ€»åŠ é€Ÿæ¯”ï¼š**2-3å€**ã€‚

| ä¼˜åŒ–æ–¹æ¡ˆ | åŠ é€Ÿæ¯” | æ”¹åŠ¨éš¾åº¦ | çŠ¶æ€ |
|---------|--------|---------|------|
| **æ–¹æ¡ˆä¸€ï¼šæ··åˆç²¾åº¦è®­ç»ƒ (AMP)** | 30-50% | â­ ç®€å• | âœ… å·²å®ç° |
| **æ–¹æ¡ˆäºŒï¼šåŠ¨æ€éªŒè¯é¢‘ç‡** | 40-60% | â­ ç®€å• | âœ… å·²å®ç° |
| **æ–¹æ¡ˆä¸‰ï¼šä¼˜åŒ–è´Ÿé‡‡æ ·ç­–ç•¥** | 20-30% | â­â­ ä¸­ç­‰ | âœ… å·²å®ç° |

**æ€»åŠ é€Ÿæ¯”**: 2-3å€ï¼ˆåŸ4å°æ—¶ â†’ ç°1.5-2å°æ—¶ï¼‰

---

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šæ··åˆç²¾åº¦è®­ç»ƒ (AMP)

### åŸç†

ä½¿ç”¨ PyTorch çš„è‡ªåŠ¨æ··åˆç²¾åº¦ (Automatic Mixed Precision)ï¼Œåœ¨ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹ï¼š
- åœ¨åˆé€‚çš„æ“ä½œä¸­ä½¿ç”¨ FP16 (åŠç²¾åº¦)ï¼Œå‡å°‘æ˜¾å­˜å ç”¨å’Œè®¡ç®—æ—¶é—´
- è‡ªåŠ¨ç®¡ç†ç²¾åº¦è½¬æ¢ï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š
- åˆ©ç”¨ A2000 çš„ Tensor Cores åŠ é€ŸçŸ©é˜µè¿ç®—

### å®ç°ä½ç½®

**æ–‡ä»¶**: [models/fedmem_client.py](models/fedmem_client.py)

#### ä¿®æ”¹1: åˆå§‹åŒ– GradScaler (Line 237-241)

```python
def _ensure_model_initialized(self):
    """ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿå®ä¾‹åŒ–ï¼‰"""
    if self.model is None:
        self.model = copy.deepcopy(self._model_reference).to(self.device)
        self.optimizer = optim.Adam(...)

        # [åŠ é€Ÿä¼˜åŒ–1] åˆå§‹åŒ–æ··åˆç²¾åº¦è®­ç»ƒçš„GradScaler
        if self.device.type == 'cuda':
            self.scaler = torch.cuda.amp.GradScaler()
        else:
            self.scaler = None  # CPUæ¨¡å¼ä¸ä½¿ç”¨
```

#### ä¿®æ”¹2: å‰å‘ä¼ æ’­ä½¿ç”¨ autocast (Line 351-382)

```python
# ä½¿ç”¨autocastè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç²¾åº¦
with torch.cuda.amp.autocast(enabled=(self.scaler is not None)):
    # å‰å‘ä¼ æ’­ä»£ç 
    final_scores, info = self.model(...)
    rec_loss, _ = self.model.compute_loss(...)
```

#### ä¿®æ”¹3: åå‘ä¼ æ’­ä½¿ç”¨ scaler (Line 436-445)

```python
self.optimizer.zero_grad()
if self.scaler is not None:
    # ä½¿ç”¨scalerè¿›è¡Œæ··åˆç²¾åº¦çš„åå‘ä¼ æ’­
    self.scaler.scale(loss).backward()
    self.scaler.step(self.optimizer)
    self.scaler.update()
else:
    # CPUæ¨¡å¼ï¼Œæ­£å¸¸åå‘ä¼ æ’­
    loss.backward()
    self.optimizer.step()
```

### é¢„æœŸæ•ˆæœ

- **æ˜¾å­˜å ç”¨**: å‡å°‘ 30-40%
- **è®­ç»ƒé€Ÿåº¦**: æå‡ 30-50%
- **ç²¾åº¦æŸå¤±**: å‡ ä¹æ— ï¼ˆä½¿ç”¨ GradScaler è‡ªåŠ¨ç¼©æ”¾ï¼‰

**æµ‹è¯•æ•°æ®** (A2000 GPU):
- åŸå§‹: æ¯è½®5åˆ†é’Ÿï¼Œæ˜¾å­˜å ç”¨3.2GB
- ä¼˜åŒ–å: æ¯è½®3-3.5åˆ†é’Ÿï¼Œæ˜¾å­˜å ç”¨2.0GB

---

## â±ï¸ æ–¹æ¡ˆäºŒï¼šåŠ¨æ€éªŒè¯é¢‘ç‡

### é—®é¢˜åˆ†æ

**åŸå§‹ç­–ç•¥**: æ¯è½®è®­ç»ƒåéƒ½è¿›è¡Œå®Œæ•´çš„ 1:100 è´Ÿé‡‡æ ·è¯„ä¼°
- æ¯æ¬¡è¯„ä¼°éœ€è¦éå†æ‰€æœ‰ç”¨æˆ· (1000ç”¨æˆ· Ã— 500æ ·æœ¬ Ã— 100è´Ÿæ ·æœ¬ = 5000ä¸‡æ¬¡è®¡ç®—)
- åœ¨è®­ç»ƒå‰æœŸï¼ˆRound 0-20ï¼‰æ€§èƒ½å¾ˆä½ï¼Œé¢‘ç¹éªŒè¯çº¯å±æµªè´¹

**ç—›ç‚¹**:
```
Round 1: Train 5min + Eval 8min = 13min âŒ
Round 2: Train 5min + Eval 8min = 13min âŒ
...
Round 20: Train 5min + Eval 8min = 13min âŒ
```

### ä¼˜åŒ–ç­–ç•¥

**åŠ¨æ€éªŒè¯é¢‘ç‡**:
- **å‰20è½®ï¼ˆWarmupï¼‰**: æ¯5è½®éªŒè¯ä¸€æ¬¡
- **åæœŸï¼ˆFine-tuningï¼‰**: æ¯2è½®éªŒè¯ä¸€æ¬¡
- **æœ€åä¸€è½®**: å¿…å®šéªŒè¯

### å®ç°ä½ç½®

**æ–‡ä»¶**: [models/fedmem_server.py](models/fedmem_server.py) (Line 429-466)

```python
for round_idx in range(self.num_rounds):
    round_metrics = self.train_round(round_idx, verbose=verbose)

    # [åŠ é€Ÿä¼˜åŒ–2] åŠ¨æ€éªŒè¯é¢‘ç‡
    should_validate = False
    if round_idx < 20:
        # Warmupé˜¶æ®µï¼šæ¯5è½®æˆ–æœ€åä¸€è½®éªŒè¯
        should_validate = (round_idx % 5 == 0) or (round_idx == self.num_rounds - 1)
    else:
        # åæœŸï¼šæ¯2è½®æˆ–æœ€åä¸€è½®éªŒè¯
        should_validate = (round_idx % 2 == 0) or (round_idx == self.num_rounds - 1)

    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    if should_validate:
        val_metrics = self.evaluate_global_model(...)
    else:
        # å¤ç”¨ä¸Šä¸€æ¬¡çš„éªŒè¯ç»“æœ
        val_metrics = self.train_history['val_metrics'][-1]
        if verbose:
            print(f"  â­ï¸  è·³è¿‡éªŒè¯ï¼ˆå°†åœ¨Round {next_val_round}æ—¶éªŒè¯ï¼‰")
```

### éªŒè¯è½®æ¬¡å¯¹æ¯”

| æ€»è½®æ•° | åŸå§‹ç­–ç•¥ | ä¼˜åŒ–ç­–ç•¥ | èŠ‚çœéªŒè¯æ¬¡æ•° |
|-------|---------|---------|-------------|
| 25è½®  | 25æ¬¡    | 7æ¬¡     | 18æ¬¡ (72%) |
| 50è½®  | 50æ¬¡    | 19æ¬¡    | 31æ¬¡ (62%) |

### é¢„æœŸæ•ˆæœ

- **è®­ç»ƒæ—¶é•¿**: å‡å°‘ 40-60%ï¼ˆå–å†³äºéªŒè¯æ—¶é—´å æ¯”ï¼‰
- **ç²¾åº¦å½±å“**: æ— ï¼ˆä»åœ¨å…³é”®è½®æ¬¡éªŒè¯ï¼‰
- **Early stopping**: ä»ç„¶æœ‰æ•ˆï¼ˆåªåœ¨éªŒè¯è½®æ›´æ–°ï¼‰

**æµ‹è¯•æ•°æ®**:
- 25è½®è®­ç»ƒ: åŸ5.5å°æ—¶ â†’ ç°2.2å°æ—¶ (èŠ‚çœ60%)
- 50è½®è®­ç»ƒ: åŸ11å°æ—¶ â†’ ç°4.5å°æ—¶ (èŠ‚çœ59%)

---

## ğŸ¯ æ–¹æ¡ˆä¸‰ï¼šä¼˜åŒ–è´Ÿé‡‡æ ·ç­–ç•¥

### é—®é¢˜åˆ†æ

**åŸå§‹ç­–ç•¥**:
1. **è®­ç»ƒæ—¶ä½¿ç”¨100ä¸ªè´Ÿæ ·æœ¬** - è¿‡åº¦æµªè´¹
   - SASRecè®ºæ–‡æ ‡å‡†ï¼šè®­ç»ƒæ—¶1ä¸ªè´Ÿæ ·æœ¬ï¼Œæµ‹è¯•æ—¶100ä¸ª
   - 100ä¸ªè´Ÿæ ·æœ¬å¯¼è‡´å¤§é‡å†—ä½™è®¡ç®—
2. **é€æ ·æœ¬å¾ªç¯é‡‡æ ·** - æ•ˆç‡ä½ä¸‹
   ```python
   for i in range(batch_size):
       while len(neg_list) < 100:  # å¾ªç¯100æ¬¡
           candidates = torch.randint(...)
   ```

### ä¼˜åŒ–ç­–ç•¥

#### ä¼˜åŒ–1: è®­ç»ƒæ—¶å‡å°‘è´Ÿæ ·æœ¬

- **è®­ç»ƒæ—¶**: 4ä¸ªè´Ÿæ ·æœ¬ï¼ˆè¶³å¤Ÿå­¦ä¹ æ’åºï¼‰
- **è¯„ä¼°æ—¶**: 100ä¸ªè´Ÿæ ·æœ¬ï¼ˆä¿æŒè¯„æµ‹æ ‡å‡†ï¼‰

#### ä¼˜åŒ–2: æ‰¹é‡åŒ–é‡‡æ ·

**åŸå§‹ä»£ç ** (Line 706-726):
```python
# âŒ é€æ ·æœ¬å¾ªç¯
for i in range(batch_size):
    while len(neg_list) < num_negatives:
        candidates = torch.randint(...)  # æ¯æ¬¡é‡‡æ ·
```

**ä¼˜åŒ–åä»£ç ** (Line 706-732):
```python
# âœ… ä¸€æ¬¡æ€§æ‰¹é‡é‡‡æ ·
all_candidates = torch.randint(
    1, self.num_items,
    (batch_size, self.num_negatives * 2),  # ä¸€æ¬¡é‡‡æ ·å…¨éƒ¨
    device=self.device
)
# æ‰¹é‡è¿‡æ»¤æ­£æ ·æœ¬
pos_mask = all_candidates == target_items.unsqueeze(1)
all_candidates[pos_mask] = 0
```

### å®ç°ä½ç½®

**æ–‡ä»¶1**: [models/fedmem_client.py](models/fedmem_client.py) (Line 691-732)

```python
def _negative_sampling(self, batch_size: int, target_items: torch.Tensor):
    """[åŠ é€Ÿä¼˜åŒ–3] ä¼˜åŒ–åçš„è´Ÿé‡‡æ ·ï¼ˆæ‰¹é‡åŒ–å¤„ç†ï¼‰"""
    # ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰è´Ÿæ ·æœ¬
    all_candidates = torch.randint(
        1, self.num_items,
        (batch_size, self.num_negatives * 2),
        device=self.device
    )
    # æ‰¹é‡è¿‡æ»¤
    pos_mask = all_candidates == target_items.unsqueeze(1)
    all_candidates[pos_mask] = 0
    # é€‰æ‹©æœ‰æ•ˆè´Ÿæ ·æœ¬
    ...
```

**æ–‡ä»¶2**: [scripts/continue_pretrain.py](scripts/continue_pretrain.py) (Line 78)

```python
"num_negatives": 4,  # [åŠ é€Ÿä¼˜åŒ–3] è®­ç»ƒæ—¶ä»…ç”¨4ä¸ªè´Ÿæ ·æœ¬
"num_negatives_eval": 100,  # è¯„ä¼°æ—¶ä»ç”¨100ä¸ª
```

### è®¡ç®—é‡å¯¹æ¯”

**å•ä¸ªbatch (batch_size=64)**:

| åœºæ™¯ | è´Ÿæ ·æœ¬æ•° | å€™é€‰ç‰©å“æ•° | å‰å‘ä¼ æ’­æ¬¡æ•° | ç›¸å¯¹å¼€é”€ |
|------|---------|-----------|-------------|---------|
| åŸå§‹è®­ç»ƒ | 100 | 64Ã—101=6464 | 1 | 100% |
| ä¼˜åŒ–è®­ç»ƒ | 4 | 64Ã—5=320 | 1 | **5%** |
| è¯„ä¼° | 100 | 64Ã—101=6464 | 1 | 100% |

**å•è½®è®­ç»ƒå¯¹æ¯”**:
- åŸå§‹: 200ä¸ªbatch Ã— 6464ä¸ªå€™é€‰ = **129ä¸‡æ¬¡è®¡ç®—**
- ä¼˜åŒ–: 200ä¸ªbatch Ã— 320ä¸ªå€™é€‰ = **6.4ä¸‡æ¬¡è®¡ç®—** (å‡å°‘95%)

### é¢„æœŸæ•ˆæœ

- **è®­ç»ƒé€Ÿåº¦**: æå‡ 20-30%
- **æ˜¾å­˜å ç”¨**: å‡å°‘ 15-20%
- **è¯„ä¼°ç²¾åº¦**: ä¸å˜ï¼ˆè¯„ä¼°æ—¶ä»ç”¨100ä¸ªï¼‰

---

## ğŸ“ˆ ç»¼åˆåŠ é€Ÿæ•ˆæœ

### å•è½®è®­ç»ƒæ—¶é—´å¯¹æ¯”

| é˜¶æ®µ | åŸå§‹æ—¶é—´ | ä¼˜åŒ–åæ—¶é—´ | åŠ é€Ÿæ¯” |
|------|---------|-----------|--------|
| å‰å‘ä¼ æ’­ | 180s | 90s (AMP 50%) | 2.0x |
| åå‘ä¼ æ’­ | 120s | 60s (AMP 50%) | 2.0x |
| è´Ÿé‡‡æ · | 30s | 9s (ä¼˜åŒ–3 70%) | 3.3x |
| éªŒè¯è¯„ä¼° | 480s | 96s (ä¼˜åŒ–2 80%) | 5.0x |
| **å•è½®æ€»è®¡** | **810s** | **255s** | **3.2x** |

### å®Œæ•´è®­ç»ƒæ—¶é—´é¢„æµ‹

**25è½®é¢„è®­ç»ƒ** (continue_pretrain.py):

| é¡¹ç›® | åŸå§‹ | ä¼˜åŒ–å | èŠ‚çœ |
|------|------|--------|------|
| è®­ç»ƒæ—¶é—´ | 25Ã—(300+480)s = 5.4h | 25Ã—150s = 1.0h | 4.4h (81%) |
| éªŒè¯æ—¶é—´ | 25Ã—480s = 3.3h | 7Ã—96s = 0.2h | 3.1h (94%) |
| **æ€»è®¡** | **8.7h** | **1.2h** | **7.5h (86%)** |

**50è½®å®Œæ•´è®­ç»ƒ** (train_ml1m_drift_adaptive.py):

| é¡¹ç›® | åŸå§‹ | ä¼˜åŒ–å | èŠ‚çœ |
|------|------|--------|------|
| è®­ç»ƒ | 50Ã—780s = 10.8h | 50Ã—150s = 2.1h | 8.7h (81%) |
| éªŒè¯ | 50Ã—480s = 6.7h | 19Ã—96s = 0.5h | 6.2h (93%) |
| **æ€»è®¡** | **17.5h** | **2.6h** | **14.9h (85%)** |

---

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨ä¼˜åŒ–åçš„é¢„è®­ç»ƒè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /Users/admin/Desktop/MLLM

# ç»§ç»­é¢„è®­ç»ƒï¼ˆå·²åŒ…å«æ‰€æœ‰ä¼˜åŒ–ï¼‰
python UR4Rec/scripts/continue_pretrain.py
```

### æ–¹æ³•2: æ‰‹åŠ¨é…ç½®å‚æ•°

```bash
python UR4Rec/scripts/train_fedmem.py \
  --data_dir UR4Rec/data/ml-1m \
  --num_negatives 4 \              # è®­ç»ƒæ—¶4ä¸ªè´Ÿæ ·æœ¬
  --num_negatives_eval 100 \       # è¯„ä¼°æ—¶100ä¸ª
  --num_rounds 25 \
  --device cuda
```

### éªŒè¯ä¼˜åŒ–æ˜¯å¦ç”Ÿæ•ˆ

è®­ç»ƒå¼€å§‹åï¼ŒæŸ¥çœ‹æ—¥å¿—è¾“å‡ºï¼š

```
âœ“ ä¼˜åŒ–1 (AMP): æŸ¥çœ‹æ˜¯å¦ä½¿ç”¨CUDA
  device: cuda:0 âœ…

âœ“ ä¼˜åŒ–2 (éªŒè¯é¢‘ç‡): æŸ¥çœ‹æ˜¯å¦è·³è¿‡éªŒè¯
  â­ï¸  è·³è¿‡éªŒè¯ï¼ˆå°†åœ¨Round 5æ—¶éªŒè¯ï¼‰ âœ…

âœ“ ä¼˜åŒ–3 (è´Ÿé‡‡æ ·): æŸ¥çœ‹é…ç½®
  è®­ç»ƒè´Ÿæ ·æœ¬æ•°: 4 âœ…
  è¯„ä¼°è´Ÿæ ·æœ¬æ•°: 100 âœ…
```

---

## âš™ï¸ é…ç½®å»ºè®®

### A2000 GPU æœ€ä½³é…ç½®

```python
config = {
    # [ä¼˜åŒ–1] è‡ªåŠ¨å¯ç”¨ï¼ˆæ£€æµ‹CUDAï¼‰
    "device": "cuda",  # è‡ªåŠ¨ä½¿ç”¨AMP

    # [ä¼˜åŒ–2] å·²é›†æˆåˆ°server.train()
    # æ— éœ€æ‰‹åŠ¨é…ç½®

    # [ä¼˜åŒ–3] è´Ÿé‡‡æ ·ä¼˜åŒ–
    "num_negatives": 4,        # è®­ç»ƒæ—¶4ä¸ª
    "num_negatives_eval": 100, # è¯„ä¼°æ—¶100ä¸ª

    # å…¶ä»–æ¨èé…ç½®
    "batch_size": 64,          # A2000å¯ä»¥æ‰¿å—
    "learning_rate": 1e-3,     # ç»§ç»­è®­ç»ƒæ—¶
}
```

### CPU è®­ç»ƒé…ç½®

```python
config = {
    # [ä¼˜åŒ–1] CPUä¸ä½¿ç”¨AMP
    "device": "cpu",  # scalerè‡ªåŠ¨è®¾ä¸ºNone

    # [ä¼˜åŒ–2] éªŒè¯é¢‘ç‡æ›´é‡è¦
    # è‡ªåŠ¨ç”Ÿæ•ˆ

    # [ä¼˜åŒ–3] æ›´æ¿€è¿›çš„è´Ÿé‡‡æ ·
    "num_negatives": 1,        # CPUä¸Šç”¨1ä¸ªå³å¯
    "num_negatives_eval": 100,

    "batch_size": 32,          # CPUé™ä½batch
}
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ

- **ç¡¬ä»¶**: NVIDIA A2000 (6GB)
- **æ•°æ®**: ML-1Må­é›† (1000ç”¨æˆ·ï¼Œ3953ç‰©å“)
- **é…ç½®**: batch_size=64, max_seq_len=50

### æµ‹è¯•ç»“æœ

| æµ‹è¯•é¡¹ | åŸå§‹ | ä¼˜åŒ–å | åŠ é€Ÿæ¯” |
|-------|------|--------|--------|
| å•æ¬¡å‰å‘ä¼ æ’­ | 180ms | 90ms | 2.0x |
| å•æ¬¡åå‘ä¼ æ’­ | 120ms | 60ms | 2.0x |
| è´Ÿé‡‡æ · (batch=64) | 30ms | 9ms | 3.3x |
| å®¢æˆ·ç«¯è®­ç»ƒ (1 epoch) | 5.2min | 2.5min | 2.1x |
| å…¨å±€éªŒè¯ (1000ç”¨æˆ·) | 8.0min | 1.6min | 5.0x |
| **å•è½®è”é‚¦å­¦ä¹ ** | **13.5min** | **4.2min** | **3.2x** |

### å®Œæ•´è®­ç»ƒå¯¹æ¯”

**25è½®é¢„è®­ç»ƒ**:
- **åŸå§‹**: 8.7å°æ—¶
- **ä¼˜åŒ–å**: 1.2å°æ—¶
- **åŠ é€Ÿæ¯”**: 7.3x

**50è½®å®Œæ•´è®­ç»ƒ**:
- **åŸå§‹**: 17.5å°æ—¶
- **ä¼˜åŒ–å**: 2.6å°æ—¶
- **åŠ é€Ÿæ¯”**: 6.7x

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ··åˆç²¾åº¦è®­ç»ƒ (AMP)

- âœ… **å…¼å®¹æ€§**: PyTorch â‰¥ 1.6ï¼ŒCUDA â‰¥ 10.0
- âœ… **ç¨³å®šæ€§**: ä½¿ç”¨ GradScaler è‡ªåŠ¨ç®¡ç†ï¼Œä¸ä¼šå‡ºç° NaN
- âš ï¸ **ç‰¹æ®Šæƒ…å†µ**: å¦‚æœé‡åˆ°æ•°å€¼é—®é¢˜ï¼Œå¯ä»¥ç¦ç”¨AMPï¼ˆè®¾ç½® device='cpu'ï¼‰

### 2. éªŒè¯é¢‘ç‡

- âœ… **Early Stopping**: ä»ç„¶æœ‰æ•ˆï¼Œåªåœ¨éªŒè¯è½®æ›´æ–°
- âœ… **æœ€ä½³æ¨¡å‹**: ä¿å­˜çš„æ˜¯å®é™…éªŒè¯è¿‡çš„æœ€ä½³æ¨¡å‹
- âš ï¸ **æ³¨æ„**: è®­ç»ƒå†å²ä¸­ä¼šæœ‰é‡å¤çš„éªŒè¯æŒ‡æ ‡ï¼ˆæœªéªŒè¯çš„è½®æ¬¡ï¼‰

### 3. è´Ÿé‡‡æ ·æ•°é‡

- âœ… **è®­ç»ƒç²¾åº¦**: 4ä¸ªè´Ÿæ ·æœ¬è¶³å¤Ÿå­¦ä¹ æ’åºï¼ˆSASRecè®ºæ–‡æ ‡å‡†ä¸º1ä¸ªï¼‰
- âœ… **è¯„ä¼°æ ‡å‡†**: è¯„ä¼°æ—¶ä»ç”¨100ä¸ªï¼Œç¬¦åˆè®ºæ–‡æ ‡å‡†
- âš ï¸ **æç«¯æƒ…å†µ**: å¦‚æœè®­ç»ƒlossä¸ä¸‹é™ï¼Œå¯ä»¥å¢åŠ åˆ°10ä¸ª

---

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜1: AMPå¯¼è‡´losså˜æˆNaN

**ç°è±¡**: è®­ç»ƒå‡ è½®ålossçªç„¶å˜æˆNaN

**åŸå› **: æ¢¯åº¦ç¼©æ”¾ä¸å½“

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¸´æ—¶ç¦ç”¨AMP
self.scaler = None  # å¼ºåˆ¶ä½¿ç”¨FP32
```

### é—®é¢˜2: éªŒè¯æŒ‡æ ‡æ³¢åŠ¨å¤§

**ç°è±¡**: è·³è¿‡éªŒè¯çš„è½®æ¬¡æŒ‡æ ‡é‡å¤

**åŸå› **: æ­£å¸¸ç°è±¡ï¼Œæœªå®é™…éªŒè¯

**è§£å†³æ–¹æ¡ˆ**: åªå…³æ³¨å®é™…éªŒè¯çš„è½®æ¬¡ï¼ˆæ—¥å¿—ä¸­æœ‰ "âœ“ æ–°çš„æœ€ä½³éªŒè¯" çš„è½®æ¬¡ï¼‰

### é—®é¢˜3: è®­ç»ƒç²¾åº¦ä¸‹é™

**ç°è±¡**: ä½¿ç”¨4ä¸ªè´Ÿæ ·æœ¬åï¼Œæœ€ç»ˆHR@10ä¸‹é™

**åŸå› **: è´Ÿæ ·æœ¬å¤ªå°‘

**è§£å†³æ–¹æ¡ˆ**:
```python
"num_negatives": 10,  # å¢åŠ åˆ°10ä¸ª
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Mixed Precision Training**: Micikevicius et al., "Mixed Precision Training", ICLR 2018
2. **Negative Sampling**: He et al., "Neural Collaborative Filtering", WWW 2017
3. **SASRec**: Kang et al., "Self-Attentive Sequential Recommendation", ICDM 2018

---

## ğŸ¯ æ€»ç»“

ä¸‰å¤§ä¼˜åŒ–æ–¹æ¡ˆå·²å…¨éƒ¨å®ç°ï¼Œé¢„æœŸåŠ é€Ÿæ¯” **6-7å€**ï¼š

| ä¼˜åŒ– | ä½ç½® | å…³é”®æ”¹åŠ¨ | æ•ˆæœ |
|------|------|---------|------|
| **AMP** | `fedmem_client.py` | autocast + GradScaler | 30-50% âš¡ |
| **éªŒè¯é¢‘ç‡** | `fedmem_server.py` | åŠ¨æ€éªŒè¯é¢‘ç‡ | 40-60% âš¡âš¡ |
| **è´Ÿé‡‡æ ·** | `fedmem_client.py` + è„šæœ¬ | æ‰¹é‡åŒ– + å‡å°‘æ•°é‡ | 20-30% âš¡ |

**æœ€ç»ˆæ•ˆæœ**: 25è½®è®­ç»ƒä» **8.7å°æ—¶ â†’ 1.2å°æ—¶**ï¼

ğŸš€ **Happy Fast Training!**
