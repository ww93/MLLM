# UR4Rec with Hierarchical MoE + CLIP Configuration for MovieLens-100K
#
# Architecture:
# - Level 1 (Within-modality): Each modality has 3 sub-experts
#   - User Preference MoE: 3 experts for genre/mood/style
#   - Item Description MoE: 3 experts for content/theme/quality
#   - CLIP Image MoE: 3 experts for visual aspects
# - Level 2 (Cross-modality): Learn to fuse 3 modality outputs

# Dataset settings
num_items: 1682  # Will be overridden by actual data
max_seq_len: 50

# SASRec parameters
sasrec_hidden_dim: 512
sasrec_num_blocks: 3
sasrec_num_heads: 8
sasrec_dropout: 0.25

# Text encoder parameters
text_model_name: "all-MiniLM-L6-v2"
text_embedding_dim: 384
retriever_output_dim: 512

# CLIP parameters
use_clip_images: true
clip_model: "ViT-B/32"  # Options: "ViT-B/32", "ViT-B/16", "ViT-L/14"
clip_features_path: "UR4Rec/data/clip_features.pt"  # Precomputed CLIP features

# Hierarchical MoE parameters
use_hierarchical_moe: true  # Enable hierarchical MoE architecture
moe_num_heads: 8  # Attention heads in each expert
moe_dropout: 0.1
moe_num_proxies: 8  # Proxy tokens for self-attention
num_sub_experts: 3  # Number of sub-experts per modality (3 for each)

# Memory mechanism parameters
max_memory_size: 20
update_trigger: "INTERACTION_COUNT"
interaction_threshold: 5
drift_threshold: 0.3
decay_factor: 0.95

# Fusion parameters
fusion_method: "weighted"
sasrec_weight: 0.4
retriever_weight: 0.6

# Training parameters
sasrec_lr: 0.0005
retriever_lr: 0.001
use_uncertainty_weighting: false
use_adaptive_alternating: false

# Training stages - 让每个modality的experts都能专门化
stages:
  - pretrain_sasrec      # 阶段1: 预训练SASRec
  - pretrain_retriever   # 阶段2: 预训练Hierarchical MoE Retriever
  - joint_finetune       # 阶段3: 联合微调
  - end_to_end          # 阶段4: 端到端训练

epochs_per_stage: 50
patience: 25

# Other settings
batch_size: 16
num_workers: 4
seed: 42
num_negatives: 20

# Hierarchical MoE specific settings
sub_expert_specialization:
  user_pref:
    - "genre_preference"     # Sub-expert 0: Genre preferences
    - "mood_preference"      # Sub-expert 1: Mood/emotion preferences
    - "style_preference"     # Sub-expert 2: Style/theme preferences
  item_desc:
    - "content_understanding"  # Sub-expert 0: Content semantics
    - "thematic_analysis"      # Sub-expert 1: Themes and topics
    - "quality_assessment"     # Sub-expert 2: Quality indicators
  image_feat:
    - "visual_composition"     # Sub-expert 0: Visual layout/composition
    - "color_texture"          # Sub-expert 1: Color and texture
    - "object_recognition"     # Sub-expert 2: Objects and scenes
