# é˜¿é‡Œäº‘ç™¾ç‚¼ï¼ˆDashScopeï¼‰APIä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

UR4Recå®Œå…¨æ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼çš„OpenAIå…¼å®¹APIï¼ŒåŒ…æ‹¬ï¼š
- âœ… æ ‡å‡†å¯¹è¯æ¨¡å¼
- âœ… **æ·±åº¦æ€è€ƒæ¨¡å¼**ï¼ˆ`enable_thinking`ï¼‰
- âœ… æµå¼å“åº”
- âœ… å¤šç§é€šä¹‰åƒé—®æ¨¡å‹ï¼ˆQwenç³»åˆ—ï¼‰

---

## å¿«é€Ÿå¼€å§‹

### 1. è·å–APIå¯†é’¥

1. è®¿é—® [é˜¿é‡Œäº‘ç™¾ç‚¼](https://dashscope.aliyuncs.com/)
2. æ³¨å†Œ/ç™»å½•è´¦å·
3. è·å–API Keyï¼ˆæ ¼å¼ï¼š`sk-xxx`ï¼‰

### 2. è®¾ç½®ç¯å¢ƒå˜é‡

```bash
export DASHSCOPE_API_KEY="your-api-key-here"
```

æˆ–åœ¨ä»£ç ä¸­ç›´æ¥è®¾ç½®ï¼š
```python
import os
os.environ["DASHSCOPE_API_KEY"] = "your-api-key"
```

---

## åŸºæœ¬ä½¿ç”¨

### æ–¹å¼1: ä½¿ç”¨UR4Recå°è£…

```python
from models import OpenAILLM
import os

# åˆ›å»ºå®¢æˆ·ç«¯
llm = OpenAILLM(
    model="qwen-plus",  # æˆ– qwen-turbo, qwen-max, qwen-flash
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ç”Ÿæˆæ–‡æœ¬
response = llm.generate("ä½ æ˜¯è°ï¼Ÿ")
print(response)
```

### æ–¹å¼2: ç›´æ¥ä½¿ç”¨OpenAIå®¢æˆ·ç«¯

```python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

response = client.chat.completions.create(
    model="qwen-plus",
    messages=[{"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿ"}]
)

print(response.choices[0].message.content)
```

---

## å¯ç”¨æ¨¡å‹

| æ¨¡å‹åç§° | è¯´æ˜ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ |
|---------|------|---------|------|
| **qwen-turbo** | å¿«é€Ÿå“åº”ï¼Œç»æµå®æƒ  | ç®€å•å¯¹è¯ã€æ‰¹é‡å¤„ç† | ğŸ’° |
| **qwen-plus** | æ€§èƒ½å‡è¡¡ï¼Œæ¨èä½¿ç”¨ | é€šç”¨æ¨èç³»ç»Ÿä»»åŠ¡ | ğŸ’°ğŸ’° |
| **qwen-max** | æœ€å¼ºæ€§èƒ½ï¼Œæœ€é«˜è´¨é‡ | å¤æ‚æ¨ç†ã€å…³é”®ä»»åŠ¡ | ğŸ’°ğŸ’°ğŸ’° |
| **qwen-flash** | æ”¯æŒæ·±åº¦æ€è€ƒæ¨¡å¼ | éœ€è¦æ¨ç†è¿‡ç¨‹çš„ä»»åŠ¡ | ğŸ’°ğŸ’° |

---

## æ·±åº¦æ€è€ƒæ¨¡å¼ ğŸ†•

é˜¿é‡Œäº‘ç™¾ç‚¼çš„ç‰¹è‰²åŠŸèƒ½ï¼Œæ¨¡å‹ä¼šå±•ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚

### ç¤ºä¾‹1: å¯ç”¨æ€è€ƒæ¨¡å¼

```python
from models import OpenAILLM
import os

llm = OpenAILLM(
    model="qwen-flash",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# å¯ç”¨æ€è€ƒæ¨¡å¼
response = llm.generate(
    "åˆ†æç”¨æˆ·å–œæ¬¢çš„ç”µå½±ç±»å‹æœ‰å“ªäº›å…±åŒç‰¹å¾ï¼Ÿ",
    extra_body={"enable_thinking": True}  # ğŸ†• å…³é”®å‚æ•°
)

print(response)
```

### ç¤ºä¾‹2: æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆæµå¼ï¼‰

```python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

messages = [{"role": "user", "content": "è®¾è®¡ä¸€ä¸ªæ¨èç®—æ³•"}]

completion = client.chat.completions.create(
    model="qwen-flash",
    messages=messages,
    extra_body={"enable_thinking": True},  # å¯ç”¨æ€è€ƒ
    stream=True  # æµå¼å“åº”
)

is_answering = False

print("=" * 20 + " æ€è€ƒè¿‡ç¨‹ " + "=" * 20)

for chunk in completion:
    delta = chunk.choices[0].delta

    # æ‰“å°æ€è€ƒè¿‡ç¨‹
    if hasattr(delta, "reasoning_content") and delta.reasoning_content:
        if not is_answering:
            print(delta.reasoning_content, end="", flush=True)

    # æ‰“å°æœ€ç»ˆç­”æ¡ˆ
    if hasattr(delta, "content") and delta.content:
        if not is_answering:
            print("\n" + "=" * 20 + " å®Œæ•´å›å¤ " + "=" * 20)
            is_answering = True
        print(delta.content, end="", flush=True)

print()
```

---

## æµå¼å“åº”

### ç¤ºä¾‹: æµå¼ç”Ÿæˆ

```python
from models import OpenAILLM
import os

llm = OpenAILLM(
    model="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ä½¿ç”¨æµå¼å“åº”
response = llm.generate(
    "è§£é‡ŠååŒè¿‡æ»¤ç®—æ³•",
    stream=True  # å¯ç”¨æµå¼
)

print(response)  # ä¼šè‡ªåŠ¨å¤„ç†æµå¼æ•°æ®å¹¶è¿”å›å®Œæ•´æ–‡æœ¬
```

---

## åœ¨UR4Recä¸­ä½¿ç”¨

### 1. LLMç”Ÿæˆå™¨

```python
from models.llm_generator import LLMPreferenceGenerator
import os

# åˆ›å»ºç”Ÿæˆå™¨
generator = LLMPreferenceGenerator(
    llm_backend="openai",
    model_name="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ç”Ÿæˆç”¨æˆ·åå¥½
item_metadata = {
    101: {"title": "æµæµªåœ°çƒ", "genres": "ç§‘å¹»|åŠ¨ä½œ"},
    205: {"title": "ç–¯ç‹‚çš„çŸ³å¤´", "genres": "å–œå‰§|çŠ¯ç½ª"}
}

user_pref = generator.generate_user_preference(
    user_id=1,
    user_history=[101, 205],
    item_metadata=item_metadata
)

print(f"ç”¨æˆ·åå¥½: {user_pref}")
```

---

## é…ç½®æ–‡ä»¶

### config.yaml

```yaml
# LLMé…ç½®
llm_backend: openai
llm_model: qwen-plus
llm_api_key: ${DASHSCOPE_API_KEY}  # ä»ç¯å¢ƒå˜é‡è¯»å–
llm_base_url: https://dashscope.aliyuncs.com/compatible-mode/v1

# å¯é€‰ï¼šå¯ç”¨æ·±åº¦æ€è€ƒ
llm_extra_body:
  enable_thinking: true

# å…¶ä»–é…ç½®...
embedding_dim: 256
```

### Pythonä»£ç 

```python
import yaml
import os

# åŠ è½½é…ç½®
with open('config.yaml') as f:
    config = yaml.safe_load(f)

# åˆ›å»ºLLMå®¢æˆ·ç«¯
from models import OpenAILLM

llm = OpenAILLM(
    model=config['llm_model'],
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url=config['llm_base_url']
)
```

---

## å®Œæ•´ç¤ºä¾‹è„šæœ¬

ä¿å­˜ä¸º `test_dashscope.py`:

```python
from openai import OpenAI
import os

def test_dashscope():
    """æµ‹è¯•é˜¿é‡Œäº‘ç™¾ç‚¼è¿æ¥"""
    client = OpenAI(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    try:
        response = client.chat.completions.create(
            model="qwen-turbo",
            messages=[{"role": "user", "content": "ä½ å¥½"}],
            max_tokens=50
        )

        print("âœ“ è¿æ¥æˆåŠŸï¼")
        print(f"å›å¤: {response.choices[0].message.content}")
        return True

    except Exception as e:
        print(f"âœ— è¿æ¥å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_dashscope()
```

è¿è¡Œæµ‹è¯•:
```bash
export DASHSCOPE_API_KEY=your-key
python test_dashscope.py
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨ç¼“å­˜

```python
from models.llm_generator import LLMPreferenceGenerator

# è‡ªåŠ¨ç¼“å­˜LLMå“åº”
generator = LLMPreferenceGenerator(
    llm_backend="openai",
    model_name="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    cache_dir="data/dashscope_cache"  # ç¼“å­˜ç›®å½•
)

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šè¯·æ±‚API
result1 = generator.generate_user_preference(...)

# ç¬¬äºŒæ¬¡è°ƒç”¨ä¼šä»ç¼“å­˜è¯»å–
result2 = generator.generate_user_preference(...)  # ç¬é—´è¿”å›
```

### 2. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡ç”Ÿæˆç”¨æˆ·åå¥½
users_data = [
    {"user_id": 1, "user_history": [101, 102]},
    {"user_id": 2, "user_history": [201, 202]},
    # ...
]

generator.batch_generate_user_preferences(
    users_data=users_data,
    item_metadata=item_metadata,
    save_path="data/user_preferences.json"
)
```

### 3. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

| ä»»åŠ¡ç±»å‹ | æ¨èæ¨¡å‹ | åŸå›  |
|---------|---------|------|
| ç®€å•æ–‡æœ¬ç”Ÿæˆ | qwen-turbo | å¿«é€Ÿä¸”ç»æµ |
| ç”¨æˆ·åå¥½åˆ†æ | qwen-plus | è´¨é‡ä¸é€Ÿåº¦å¹³è¡¡ |
| å¤æ‚æ¨ç† | qwen-max | æœ€é«˜è´¨é‡ |
| éœ€è¦æ¨ç†è¿‡ç¨‹ | qwen-flash + thinking | å¯è§£é‡Šæ€§å¼º |

---

## æˆæœ¬ä¼°ç®—

åŸºäºé˜¿é‡Œäº‘ç™¾ç‚¼å®šä»·ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | æ¯1000æ¬¡è°ƒç”¨ |
|------|---------|---------|-------------|
| qwen-turbo | Â¥0.0008/1K tokens | Â¥0.002/1K tokens | ~Â¥5-10 |
| qwen-plus | Â¥0.004/1K tokens | Â¥0.012/1K tokens | ~Â¥20-40 |
| qwen-max | Â¥0.04/1K tokens | Â¥0.12/1K tokens | ~Â¥200-400 |

**èŠ‚çœæˆæœ¬æŠ€å·§**:
- ä½¿ç”¨ç¼“å­˜æœºåˆ¶
- æ‰¹é‡å¤„ç†è¯·æ±‚
- æ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚æ¨¡å‹
- æ§åˆ¶max_tokenså‚æ•°

---

## é”™è¯¯å¤„ç†

```python
from models import OpenAILLM
import os

llm = OpenAILLM(
    model="qwen-plus",
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

try:
    response = llm.generate("ä½ å¥½")
    print(response)

except Exception as e:
    if "401" in str(e):
        print("âŒ APIå¯†é’¥æ— æ•ˆ")
    elif "429" in str(e):
        print("âŒ è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
    elif "500" in str(e):
        print("âŒ æœåŠ¡å™¨é”™è¯¯")
    else:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è·å–APIå¯†é’¥ï¼Ÿ

è®¿é—® https://dashscope.aliyuncs.com/ æ³¨å†Œå¹¶åˆ›å»ºAPI Keyã€‚

### Q2: æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿ

æ‰€æœ‰é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹ï¼šqwen-turbo, qwen-plus, qwen-max, qwen-flashç­‰ã€‚

### Q3: æ€è€ƒæ¨¡å¼æœ‰ä»€ä¹ˆç”¨ï¼Ÿ

å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œæé«˜å¯è§£é‡Šæ€§ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡ã€‚

### Q4: æµå¼å“åº”çš„ä¼˜åŠ¿ï¼Ÿ

å®æ—¶åé¦ˆï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œç‰¹åˆ«é€‚åˆç”Ÿæˆé•¿æ–‡æœ¬ã€‚

### Q5: å¦‚ä½•åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹ï¼Ÿ

åªéœ€ä¿®æ”¹`model`å‚æ•°ï¼Œæ— éœ€æ”¹åŠ¨å…¶ä»–ä»£ç ã€‚

---

## å®Œæ•´è¿è¡Œç¤ºä¾‹

```bash
# 1. è®¾ç½®APIå¯†é’¥
export DASHSCOPE_API_KEY=your-key

# 2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
cd /Users/admin/Desktop/MLLM
source venv/bin/activate

# 3. è¿è¡Œç¤ºä¾‹
cd UR4Rec/examples
python dashscope_example.py

# 4. æŸ¥çœ‹è¾“å‡º
# ä¼šçœ‹åˆ°6ä¸ªä¸åŒçš„ä½¿ç”¨ç¤ºä¾‹
```

---

## å‚è€ƒé“¾æ¥

- [é˜¿é‡Œäº‘ç™¾ç‚¼å®˜ç½‘](https://dashscope.aliyuncs.com/)
- [é€šä¹‰åƒé—®APIæ–‡æ¡£](https://help.aliyun.com/zh/dashscope/)
- [OpenAIå…¼å®¹æ¨¡å¼æ–‡æ¡£](https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope/)

---

## æ€»ç»“

âœ… **UR4Recå·²å®Œå…¨æ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼API**

æ”¯æŒçš„åŠŸèƒ½ï¼š
- âœ“ æ ‡å‡†å¯¹è¯
- âœ“ æ·±åº¦æ€è€ƒæ¨¡å¼ï¼ˆ`enable_thinking`ï¼‰
- âœ“ æµå¼å“åº”ï¼ˆ`stream`ï¼‰
- âœ“ æ‰€æœ‰é€šä¹‰åƒé—®æ¨¡å‹
- âœ“ è‡ªåŠ¨ç¼“å­˜
- âœ“ æ‰¹é‡å¤„ç†

**æ¨èé…ç½®**:
- å¼€å‘/æµ‹è¯•: qwen-turbo
- ç”Ÿäº§ç¯å¢ƒ: qwen-plus
- é«˜è´¨é‡éœ€æ±‚: qwen-max
- å¯è§£é‡Šæ€§: qwen-flash + thinking mode
