"""
FedMemè®­ç»ƒè„šæœ¬ï¼šå¸¦æœ¬åœ°åŠ¨æ€è®°å¿†å’ŒåŸå‹èšåˆçš„è”é‚¦æ¨èç³»ç»Ÿï¼ˆæ”¯æŒå¤šæ¨¡æ€æ•°æ®ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # åŸºæœ¬ç”¨æ³•ï¼ˆä»…IDç‰¹å¾ï¼‰
    python scripts/train_fedmem.py --data_dir data/ml-1m --save_dir checkpoints/fedmem

    # å®Œæ•´å¤šæ¨¡æ€ç”¨æ³•
    python scripts/train_fedmem.py \
        --data_dir data/ml-1m \
        --visual_file item_images.npy \
        --text_file item_llm_texts.npy \
        --save_dir checkpoints/fedmem

æ ¸å¿ƒç‰¹æ€§ï¼š
1. **Two-tieræœ¬åœ°åŠ¨æ€è®°å¿†** (ST: æœ€è¿‘å…´è¶£ + LT: ç¨³å®šå¤šæ ·æ€§)
2. **Novelty-based LTå†™å…¥** (æ•°æ®é©±åŠ¨é˜ˆå€¼ï¼Œ~10%å†™å…¥ç‡)
3. è®°å¿†åŸå‹èšåˆï¼ˆPrototype Aggregationï¼Œä»LTæå–ï¼‰
4. å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆContrastive Lossï¼‰
5. å¤šæ¨¡æ€ç‰¹å¾åŠ è½½ï¼ˆè§†è§‰ + æ–‡æœ¬ï¼‰
6. **[NEW] è½»é‡çº§Stage 2å¯¹é½** (æŠ•å½±å±‚ <200K params)
"""
import os
import sys
import json
import argparse

# Debug print switch (set FEDMEM_DEBUG=1 to enable)
DEBUG = bool(int(os.environ.get('FEDMEM_DEBUG', '0')))

def dprint(*args, **kwargs):
    if DEBUG:
        print(*args, **kwargs)

import torch
import numpy as np
import random
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from models.ur4rec_v2_moe import UR4RecV2MoE
from models.fedmem_simple import FedMemSimple  # [NEW] ç®€åŒ–æ¶æ„
from models.fedmem_client import FedMemClient
from models.fedmem_server import FedMemServer



def str2bool(v):
    """Robust bool parser for argparse."""
    if isinstance(v, bool):
        return v
    if v is None:
        return False
    s = str(v).strip().lower()
    if s in ("1", "true", "t", "yes", "y", "on"):
        return True
    if s in ("0", "false", "f", "no", "n", "off"):
        return False
    raise argparse.ArgumentTypeError(f"Boolean value expected, got: {v}")


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


# [NEW] å¤šæ¨¡æ€ç‰¹å¾åŠ è½½å‡½æ•°
def load_multimodal_features(
    data_dir: str,
    visual_file: Optional[str],
    text_file: Optional[str],
    num_items: int,
    device: str = 'cpu'
) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], int, int]:
    """
    åŠ è½½é¢„æå–çš„å¤šæ¨¡æ€ç‰¹å¾

    Args:
        data_dir: æ•°æ®ç›®å½•
        visual_file: è§†è§‰ç‰¹å¾æ–‡ä»¶å (e.g., 'item_images.npy' or 'item_images.pt')
        text_file: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å (e.g., 'item_llm_texts.npy' or 'item_llm_texts.pt')
        num_items: ç‰©å“æ€»æ•°
        device: è®¡ç®—è®¾å¤‡

    Returns:
        item_visual_feats: [num_items, img_dim] æˆ– None
        item_text_feats: [num_items, text_dim] æˆ– None
        img_dim: è§†è§‰ç‰¹å¾ç»´åº¦
        text_dim: æ–‡æœ¬ç‰¹å¾ç»´åº¦
    """
    item_visual_feats = None
    item_text_feats = None
    img_dim = 512  # é»˜è®¤ç»´åº¦
    text_dim = 768  # é»˜è®¤ç»´åº¦

    print(f"\n{'='*60}")
    print("åŠ è½½å¤šæ¨¡æ€ç‰¹å¾")
    print(f"{'='*60}")

    # ========== åŠ è½½è§†è§‰ç‰¹å¾ ==========
    if visual_file:
        visual_path = os.path.join(data_dir, visual_file)

        if os.path.exists(visual_path):
            try:
                # æ”¯æŒ.npyå’Œ.ptæ ¼å¼
                if visual_path.endswith('.npy'):
                    visual_np = np.load(visual_path)
                    item_visual_feats = torch.from_numpy(visual_np).float().to(device)
                elif visual_path.endswith('.pt') or visual_path.endswith('.pth'):
                    item_visual_feats = torch.load(visual_path, map_location=device, weights_only=False)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è§†è§‰ç‰¹å¾æ–‡ä»¶æ ¼å¼: {visual_path}")

                # éªŒè¯å½¢çŠ¶
                if item_visual_feats.shape[0] != num_items:
                    print(f"âš ï¸ è­¦å‘Š: è§†è§‰ç‰¹å¾æ•°é‡ ({item_visual_feats.shape[0]}) ä¸ç‰©å“æ•°é‡ ({num_items}) ä¸åŒ¹é…")
                    print(f"   å°†åˆ›å»ºé›¶å¡«å……ç‰¹å¾ä»¥åŒ¹é…ç‰©å“æ•°é‡")

                    # åˆ›å»ºé›¶å¡«å……ç‰¹å¾
                    img_dim = item_visual_feats.shape[1]
                    padded_feats = torch.zeros(num_items, img_dim, device=device)
                    min_items = min(num_items, item_visual_feats.shape[0])
                    padded_feats[:min_items] = item_visual_feats[:min_items]
                    item_visual_feats = padded_feats
                else:
                    img_dim = item_visual_feats.shape[1]

                print(f"âœ“ æˆåŠŸåŠ è½½è§†è§‰ç‰¹å¾: {visual_path}")
                print(f"  å½¢çŠ¶: {item_visual_feats.shape}")
                print(f"  æ•°æ®ç±»å‹: {item_visual_feats.dtype}")
                print(f"  ç»Ÿè®¡: min={item_visual_feats.min():.4f}, max={item_visual_feats.max():.4f}, mean={item_visual_feats.mean():.4f}")

            except Exception as e:
                print(f"âœ— åŠ è½½è§†è§‰ç‰¹å¾å¤±è´¥: {e}")
                dprint(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„è§†è§‰ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")
                item_visual_feats = None
        else:
            print(f"âš ï¸ è­¦å‘Š: è§†è§‰ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {visual_path}")
            dprint(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„è§†è§‰ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")

    # å¦‚æœæ²¡æœ‰åŠ è½½æˆåŠŸï¼Œä½¿ç”¨éšæœºç‰¹å¾
    if visual_file and item_visual_feats is None:
        print(f"\n[DEBUG] åˆ›å»ºéšæœºè§†è§‰ç‰¹å¾: [{num_items}, {img_dim}]")
        item_visual_feats = torch.randn(num_items, img_dim, device=device) * 0.01
        dprint(f"âš ï¸ è­¦å‘Š: ä½¿ç”¨éšæœºè§†è§‰ç‰¹å¾ï¼è¿™ä»…ç”¨äºè°ƒè¯•ï¼Œä¸é€‚åˆæ­£å¼è®­ç»ƒï¼")

    # ========== åŠ è½½æ–‡æœ¬ç‰¹å¾ ==========
    if text_file:
        text_path = os.path.join(data_dir, text_file)

        if os.path.exists(text_path):
            try:
                # æ”¯æŒ.npyå’Œ.ptæ ¼å¼
                if text_path.endswith('.npy'):
                    text_np = np.load(text_path)
                    item_text_feats = torch.from_numpy(text_np).float().to(device)
                elif text_path.endswith('.pt') or text_path.endswith('.pth'):
                    item_text_feats = torch.load(text_path, map_location=device, weights_only=False)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æœ¬ç‰¹å¾æ–‡ä»¶æ ¼å¼: {text_path}")

                # éªŒè¯å½¢çŠ¶
                if item_text_feats.shape[0] != num_items:
                    print(f"âš ï¸ è­¦å‘Š: æ–‡æœ¬ç‰¹å¾æ•°é‡ ({item_text_feats.shape[0]}) ä¸ç‰©å“æ•°é‡ ({num_items}) ä¸åŒ¹é…")
                    print(f"   å°†åˆ›å»ºé›¶å¡«å……ç‰¹å¾ä»¥åŒ¹é…ç‰©å“æ•°é‡")

                    # åˆ›å»ºé›¶å¡«å……ç‰¹å¾
                    text_dim = item_text_feats.shape[1]
                    padded_feats = torch.zeros(num_items, text_dim, device=device)
                    min_items = min(num_items, item_text_feats.shape[0])
                    padded_feats[:min_items] = item_text_feats[:min_items]
                    item_text_feats = padded_feats
                else:
                    text_dim = item_text_feats.shape[1]

                print(f"\nâœ“ æˆåŠŸåŠ è½½æ–‡æœ¬ç‰¹å¾: {text_path}")
                print(f"  å½¢çŠ¶: {item_text_feats.shape}")
                print(f"  æ•°æ®ç±»å‹: {item_text_feats.dtype}")
                print(f"  ç»Ÿè®¡: min={item_text_feats.min():.4f}, max={item_text_feats.max():.4f}, mean={item_text_feats.mean():.4f}")

            except Exception as e:
                print(f"âœ— åŠ è½½æ–‡æœ¬ç‰¹å¾å¤±è´¥: {e}")
                dprint(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ–‡æœ¬ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")
                item_text_feats = None
        else:
            print(f"\nâš ï¸ è­¦å‘Š: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {text_path}")
            dprint(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ–‡æœ¬ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")

    # å¦‚æœæ²¡æœ‰åŠ è½½æˆåŠŸï¼Œä½¿ç”¨éšæœºç‰¹å¾
    if text_file and item_text_feats is None:
        print(f"\n[DEBUG] åˆ›å»ºéšæœºæ–‡æœ¬ç‰¹å¾: [{num_items}, {text_dim}]")
        item_text_feats = torch.randn(num_items, text_dim, device=device) * 0.01
        dprint(f"âš ï¸ è­¦å‘Š: ä½¿ç”¨éšæœºæ–‡æœ¬ç‰¹å¾ï¼è¿™ä»…ç”¨äºè°ƒè¯•ï¼Œä¸é€‚åˆæ­£å¼è®­ç»ƒï¼")

    # ========== æ€»ç»“ ==========
    print(f"\n{'='*60}")
    print("å¤šæ¨¡æ€ç‰¹å¾åŠ è½½æ€»ç»“")
    print(f"{'='*60}")
    print(f"è§†è§‰ç‰¹å¾: {'âœ“ å·²åŠ è½½' if item_visual_feats is not None else 'âœ— æœªåŠ è½½'}")
    if item_visual_feats is not None:
        print(f"  ç»´åº¦: {img_dim}")
    print(f"æ–‡æœ¬ç‰¹å¾: {'âœ“ å·²åŠ è½½' if item_text_feats is not None else 'âœ— æœªåŠ è½½'}")
    if item_text_feats is not None:
        print(f"  ç»´åº¦: {text_dim}")
    print(f"{'='*60}\n")

    return item_visual_feats, item_text_feats, img_dim, text_dim


# [UPDATED] æ›´æ–°åçš„åŠ è½½ç”¨æˆ·åºåˆ—å‡½æ•°
def load_user_sequences(
    data_path: str,
    data_dir: str,
    visual_file: Optional[str] = None,
    text_file: Optional[str] = None,
    device: str = 'cpu'
) -> Tuple[Dict[int, List[int]], int, Optional[torch.Tensor], Optional[torch.Tensor], int, int]:
    """
    åŠ è½½ç”¨æˆ·äº¤äº’åºåˆ—å’Œå¤šæ¨¡æ€ç‰¹å¾

    Args:
        data_path: äº¤äº’æ•°æ®æ–‡ä»¶è·¯å¾„
        data_dir: æ•°æ®ç›®å½•ï¼ˆç”¨äºåŠ è½½å¤šæ¨¡æ€ç‰¹å¾ï¼‰
        visual_file: è§†è§‰ç‰¹å¾æ–‡ä»¶å
        text_file: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å
        device: è®¡ç®—è®¾å¤‡

    Returns:
        user_sequences: {user_id: [item_id1, item_id2, ...]}
        num_items: ç‰©å“æ€»æ•°
        item_visual_feats: [num_items, img_dim] æˆ– None
        item_text_feats: [num_items, text_dim] æˆ– None
        img_dim: è§†è§‰ç‰¹å¾ç»´åº¦
        text_dim: æ–‡æœ¬ç‰¹å¾ç»´åº¦
    """
    user_sequences = {}
    max_item_id = 0

    print(f"\n{'='*60}")
    print("åŠ è½½ç”¨æˆ·äº¤äº’åºåˆ—")
    print(f"{'='*60}")

    # æ£€æµ‹æ•°æ®æ ¼å¼å¹¶åŠ è½½
    with open(data_path, 'r') as f:
        first_line = f.readline().strip()
        f.seek(0)  # é‡ç½®åˆ°æ–‡ä»¶å¼€å¤´

        parts = first_line.split()

        # åˆ¤æ–­æ ¼å¼ï¼š
        # æ ¼å¼1: user_id item_1 item_2 item_3 ... (ä¸€è¡Œå¤šä¸ªitems)
        # æ ¼å¼2: user_id item_id rating timestamp (æ¯è¡Œä¸€æ¡äº¤äº’)

        if len(parts) > 4:
            # æ ¼å¼1: æ¯è¡Œæ˜¯ä¸€ä¸ªç”¨æˆ·çš„å®Œæ•´åºåˆ—
            print("æ£€æµ‹åˆ°æ ¼å¼: æ¯è¡Œä¸€ä¸ªç”¨æˆ·åºåˆ—")
            for line in f:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue

                user_id = int(parts[0])
                items = [int(x) for x in parts[1:]]
                user_sequences[user_id] = items

                if items:
                    max_item_id = max(max_item_id, max(items))
        else:
            # æ ¼å¼2: æ¯è¡Œæ˜¯ä¸€æ¡äº¤äº’è®°å½•ï¼Œéœ€è¦èšåˆ
            print("æ£€æµ‹åˆ°æ ¼å¼: æ¯è¡Œä¸€æ¡äº¤äº’è®°å½•")
            user_interactions = {}

            for line in f:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue

                user_id = int(parts[0])
                item_id = int(parts[1])

                # å¦‚æœæœ‰timestampï¼ˆç¬¬4ä¸ªå­—æ®µï¼‰ï¼Œç”¨äºæ’åº
                timestamp = int(parts[3]) if len(parts) >= 4 else 0

                if user_id not in user_interactions:
                    user_interactions[user_id] = []

                user_interactions[user_id].append((timestamp, item_id))
                max_item_id = max(max_item_id, item_id)

            # æŒ‰æ—¶é—´æ’åºå¹¶æå–itemåºåˆ—
            for user_id, interactions in user_interactions.items():
                interactions.sort(key=lambda x: x[0])  # æŒ‰timestampæ’åº
                user_sequences[user_id] = [item_id for _, item_id in interactions]

    num_items = max_item_id + 1

    # æ‰“å°è¿‡æ»¤å‰çš„ç»Ÿè®¡
    print(f"âœ“ åŸå§‹ç”¨æˆ·æ•°: {len(user_sequences)}")
    print(f"âœ“ ç‰©å“æ€»æ•°: {num_items}")

    if len(user_sequences) == 0:
        raise ValueError(
            f"âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•ç”¨æˆ·æ•°æ®ï¼\n"
            f"   è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼: {data_path}\n"
            f"   é¢„æœŸæ ¼å¼: user_id item_1 item_2 item_3 ...\n"
            f"   æ¯è¡Œä¸€ä¸ªç”¨æˆ·ï¼Œç©ºæ ¼åˆ†éš”"
        )

    # è¿‡æ»¤æ‰åºåˆ—å¤ªçŸ­çš„ç”¨æˆ·ï¼ˆè‡³å°‘éœ€è¦5ä¸ªitemï¼štrain, val, testï¼‰
    original_user_count = len(user_sequences)
    user_sequences = {
        uid: seq for uid, seq in user_sequences.items()
        if len(seq) >= 5
    }

    if len(user_sequences) == 0:
        raise ValueError(
            f"âŒ è¿‡æ»¤åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·ï¼\n"
            f"   åŸå§‹ç”¨æˆ·æ•°: {original_user_count}\n"
            f"   è¿‡æ»¤æ¡ä»¶: åºåˆ—é•¿åº¦ >= 5\n"
            f"   å»ºè®®: æ£€æŸ¥æ•°æ®æ–‡ä»¶ {data_path} çš„æ ¼å¼æ˜¯å¦æ­£ç¡®"
        )

    print(f"âœ“ è¿‡æ»¤åç”¨æˆ·æ•°: {len(user_sequences)} (è¿‡æ»¤æ‰ {original_user_count - len(user_sequences)} ä¸ª)")

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    seq_lengths = [len(seq) for seq in user_sequences.values()]
    print(f"  åºåˆ—é•¿åº¦ç»Ÿè®¡:")
    print(f"    æœ€å°: {min(seq_lengths)}")
    print(f"    æœ€å¤§: {max(seq_lengths)}")
    print(f"    å¹³å‡: {sum(seq_lengths)/len(seq_lengths):.1f}")
    print(f"    æ€»äº¤äº’æ•°: {sum(seq_lengths):,}")
    print(f"{'='*60}\n")

    # [NEW] åŠ è½½å¤šæ¨¡æ€ç‰¹å¾
    item_visual_feats, item_text_feats, img_dim, text_dim = load_multimodal_features(
        data_dir=data_dir,
        visual_file=visual_file,
        text_file=text_file,
        num_items=num_items,
        device=device
    )

    return user_sequences, num_items, item_visual_feats, item_text_feats, img_dim, text_dim


# [UPDATED] æ›´æ–°åçš„åˆ›å»ºå®¢æˆ·ç«¯å‡½æ•°
def create_fedmem_clients(
    user_sequences: Dict[int, List[int]],
    global_model: UR4RecV2MoE,
    item_visual_feats: Optional[torch.Tensor],
    item_text_feats: Optional[torch.Tensor],
    args: argparse.Namespace
) -> List[FedMemClient]:
    """
    åˆ›å»ºFedMemå®¢æˆ·ç«¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ç‰¹å¾ï¼‰

    Args:
        user_sequences: ç”¨æˆ·äº¤äº’åºåˆ—
        global_model: å…¨å±€æ¨¡å‹
        item_visual_feats: ç‰©å“è§†è§‰ç‰¹å¾ [num_items, img_dim]
        item_text_feats: ç‰©å“æ–‡æœ¬ç‰¹å¾ [num_items, text_dim]
        args: è®­ç»ƒå‚æ•°

    Returns:
        clients: FedMemClientåˆ—è¡¨
    """
    clients = []

    print(f"\n{'='*60}")
    print("åˆ›å»º FedMem å®¢æˆ·ç«¯")
    print(f"{'='*60}")

    for user_id, sequence in user_sequences.items():
        client = FedMemClient(
            client_id=user_id,
            model=global_model,
            user_sequence=sequence,
            device=args.device,
            # [NEW] å¤šæ¨¡æ€ç‰¹å¾
            item_visual_feats=item_visual_feats,
            item_text_feats=item_text_feats,
            # è®­ç»ƒå‚æ•°
            learning_rate=args.learning_rate,
            weight_decay=args.weight_decay,
            local_epochs=args.local_epochs,
            batch_size=args.batch_size,
            max_seq_len=args.max_seq_len,
            # è´Ÿé‡‡æ ·
            num_negatives=args.num_negatives,
            num_items=args.num_items,
            # FedMemè®°å¿†å‚æ•°
            memory_capacity=args.memory_capacity,
            surprise_threshold=args.surprise_threshold,
            contrastive_lambda=args.contrastive_lambda,
            num_memory_prototypes=args.num_memory_prototypes,
            # è´Ÿé‡‡æ ·è¯„ä¼°å‚æ•°
            use_negative_sampling=args.use_negative_sampling,
            num_negatives_eval=args.num_negatives_eval
        )
        clients.append(client)

    print(f"âœ“ åˆ›å»ºäº† {len(clients)} ä¸ª FedMem å®¢æˆ·ç«¯")
    print(f"  æ¯ä¸ªå®¢æˆ·ç«¯:")
    print(f"    - è§†è§‰ç‰¹å¾: {'å¯ç”¨' if item_visual_feats is not None else 'ç¦ç”¨'}")
    print(f"    - æ–‡æœ¬ç‰¹å¾: {'å¯ç”¨' if item_text_feats is not None else 'ç¦ç”¨'}")
    print(f"    - è®°å¿†æ¶æ„: Two-tier (ST: 50, LT: {args.memory_capacity})")
    print(f"    - LTå†™å…¥ç­–ç•¥: Novelty-based (threshold=0.583)")
    print(f"    - å…¼å®¹å‚æ•° surprise_threshold: {args.surprise_threshold}")
    print(f"{'='*60}\n")

    return clients


def main():
    parser = argparse.ArgumentParser(description="FedMemè®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰")

    # æ•°æ®å‚æ•°
    parser.add_argument("--data_dir", type=str, default="UR4Rec/data/ml-1m",
                        help="æ•°æ®ç›®å½•")
    parser.add_argument("--data_file", type=str, default="subset_ratings.dat",
                        help="äº¤äº’æ•°æ®æ–‡ä»¶å")

    # [NEW] å¤šæ¨¡æ€ç‰¹å¾æ–‡ä»¶å‚æ•°
    parser.add_argument("--visual_file", type=str, default="clip_features.pt",
                        help="è§†è§‰ç‰¹å¾æ–‡ä»¶å (e.g., 'item_images.npy' or 'item_images.pt')")
    parser.add_argument("--text_file", type=str, default="text_features.pt",
                        help="æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å (e.g., 'item_llm_texts.npy' or 'item_llm_texts.pt')")

    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model_type", type=str, default="moe",
                        choices=["moe", "simple"],
                        help="æ¨¡å‹æ¶æ„ç±»å‹: 'moe' (MoEæ¶æ„) æˆ– 'simple' (ç®€åŒ–æ¶æ„)")

    # [NEW] ä¸‰é˜¶æ®µè®­ç»ƒå‚æ•°
    parser.add_argument("--stage", type=str, default="full",
                        choices=["pretrain_sasrec", "align_projectors", "finetune_moe", "full"],
                        help="è®­ç»ƒé˜¶æ®µ:\n"
                             "  pretrain_sasrec: ç¬¬ä¸€é˜¶æ®µï¼Œçº¯ID SASRecé¢„è®­ç»ƒ\n"
                             "  align_projectors: ç¬¬äºŒé˜¶æ®µï¼Œå¤šæ¨¡æ€æŠ•å½±å±‚å¯¹é½\n"
                             "  finetune_moe: ç¬¬ä¸‰é˜¶æ®µï¼ŒMoEé›†æˆå¾®è°ƒ\n"
                             "  full: å®Œæ•´è®­ç»ƒï¼ˆé»˜è®¤ï¼‰")
    parser.add_argument("--stage1_checkpoint", type=str, default=None,
                        help="ç¬¬ä¸€é˜¶æ®µcheckpointè·¯å¾„ï¼ˆç”¨äºstage2å’Œstage3ï¼‰")
    parser.add_argument("--stage2_checkpoint", type=str, default=None,
                        help="ç¬¬äºŒé˜¶æ®µcheckpointè·¯å¾„ï¼ˆç”¨äºstage3ï¼‰")

    parser.add_argument("--num_items", type=int, default=1682,
                        help="ç‰©å“æ€»æ•°ï¼ˆè‡ªåŠ¨æ£€æµ‹å¦‚æœæœªæŒ‡å®šï¼‰")
    parser.add_argument("--sasrec_hidden_dim", type=int, default=256,
                        help="SASRecéšè—å±‚ç»´åº¦")
    parser.add_argument("--sasrec_num_blocks", type=int, default=2,
                        help="SASRec Transformerå—æ•°é‡")
    parser.add_argument("--sasrec_num_heads", type=int, default=4,
                        help="SASRecæ³¨æ„åŠ›å¤´æ•°é‡")
    parser.add_argument("--retriever_output_dim", type=int, default=256,
                        help="Retrieverè¾“å‡ºç»´åº¦")
    parser.add_argument("--moe_num_heads", type=int, default=8,
                        help="MoEæ³¨æ„åŠ›å¤´æ•°é‡")
    parser.add_argument("--max_seq_len", type=int, default=50,
                        help="æœ€å¤§åºåˆ—é•¿åº¦")

    # [NEW] ç®€åŒ–æ¶æ„ä¸“ç”¨å‚æ•°
    parser.add_argument("--id_emb_dim", type=int, default=128,
                        help="[ç®€åŒ–æ¶æ„] IDåµŒå…¥ç»´åº¦")
    parser.add_argument("--visual_proj_dim", type=int, default=64,
                        help="[ç®€åŒ–æ¶æ„] è§†è§‰ç‰¹å¾æŠ•å½±ç»´åº¦")
    parser.add_argument("--text_proj_dim", type=int, default=64,
                        help="[ç®€åŒ–æ¶æ„] æ–‡æœ¬ç‰¹å¾æŠ•å½±ç»´åº¦")

    # FedMemå‚æ•° (Two-tier Memory: ST + LT)
    parser.add_argument("--memory_capacity", type=int, default=200,
                        help="LT (long-term) è®°å¿†å®¹é‡ï¼Œæ¨è200 (ML-1M), STå›ºå®š50")
    parser.add_argument("--surprise_threshold", type=float, default=0.5,
                        help="å…¼å®¹å‚æ•°ï¼Œæ–°ç‰ˆæœ¬ä¸»è¦ä½¿ç”¨novelty-basedå†™å…¥ (é»˜è®¤0.583)")
    parser.add_argument("--contrastive_lambda", type=float, default=0.05,
                        help="å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡")
    parser.add_argument("--num_memory_prototypes", type=int, default=5,
                        help="è®°å¿†åŸå‹æ•°é‡ï¼ˆä»LTæå–ï¼‰")
    parser.add_argument("--enable_prototype_aggregation", action="store_true",
                        help="å¯ç”¨åŸå‹èšåˆ")

    # è”é‚¦å­¦ä¹ å‚æ•°
    parser.add_argument("--num_rounds", type=int, default=50,
                        help="è”é‚¦å­¦ä¹ è½®æ•°")
    parser.add_argument("--client_fraction", type=float, default=0.1,
                        help="æ¯è½®å‚ä¸çš„å®¢æˆ·ç«¯æ¯”ä¾‹")
    parser.add_argument("--local_epochs", type=int, default=1,
                        help="å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒè½®æ•°")
    parser.add_argument("--aggregation_method", type=str, default="fedavg",
                        choices=["fedavg", "fedprox"],
                        help="èšåˆæ–¹æ³•")
    parser.add_argument("--patience", type=int, default=10,
                        help="æ—©åœpatience")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--learning_rate", type=float, default=1e-3,
                        help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-5,
                        help="æƒé‡è¡°å‡")
    parser.add_argument("--batch_size", type=int, default=32,
                        help="æ‰¹å¤§å°")
    parser.add_argument("--num_negatives", type=int, default=4,
                        help="è´Ÿæ ·æœ¬æ•°é‡")

    # è´Ÿé‡‡æ ·è¯„ä¼°å‚æ•°
    parser.add_argument("--use_negative_sampling", type=str2bool, default=True,
                        help="ä½¿ç”¨1:100è´Ÿé‡‡æ ·è¯„ä¼°ï¼ˆå¯¹é½NCF/SASRecè®ºæ–‡ï¼‰")
    parser.add_argument("--num_negatives_eval", type=int, default=100,
                        help="è¯„ä¼°æ—¶çš„è´Ÿæ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤100ï¼‰")

    # ã€æ®‹å·®å¢å¼ºã€‘Residual Enhancement å‚æ•°
    parser.add_argument("--gating_init", type=float, default=0.1,
                        help="é—¨æ§æƒé‡åˆå§‹å€¼ï¼ˆæ¨è0.0-0.1ï¼‰ï¼Œæ§åˆ¶è¾…åŠ©ä¿¡æ¯æ³¨å…¥å¼ºåº¦")

    # ã€ç­–ç•¥1ã€‘Router Bias Initialization å‚æ•° [å·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹]
    parser.add_argument("--init_bias_for_sasrec", action="store_true",
                        help="[å·²åºŸå¼ƒ] å¯ç”¨Router Bias Initializationï¼ˆç­–ç•¥1ï¼‰")
    parser.add_argument("--sasrec_bias_value", type=float, default=5.0,
                        help="[å·²åºŸå¼ƒ] SASRec expertçš„biasåˆå§‹å€¼")

    # ã€ç­–ç•¥2ã€‘Partial Aggregation å‚æ•°
    parser.add_argument("--partial_aggregation_warmup_rounds", type=int, default=20,
                        help="Warmupè½®æ•°ï¼Œå‰Nè½®åªèšåˆSASRecå‚æ•°ï¼ˆç­–ç•¥2ï¼‰ï¼Œ0è¡¨ç¤ºç¦ç”¨")

    # å…¶ä»–å‚æ•°
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu",
                        help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--seed", type=int, default=42,
                        help="éšæœºç§å­")
    parser.add_argument("--save_dir", type=str, default="checkpoints/fedmem",
                        help="æ¨¡å‹ä¿å­˜ç›®å½•")
    parser.add_argument("--verbose", action="store_true",
                        help="æ‰“å°è¯¦ç»†è®­ç»ƒä¿¡æ¯")

    # [NEW] é¢„è®­ç»ƒæƒé‡åŠ è½½
    parser.add_argument("--pretrained_path", type=str, default=None,
                        help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºè¿ç§»å­¦ä¹ ï¼‰ã€‚åŠ è½½SASRecéª¨å¹²æƒé‡ï¼Œè·³è¿‡Warmupé˜¶æ®µ")

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # ä¿å­˜é…ç½®
    with open(os.path.join(args.save_dir, 'config.json'), 'w') as f:
        json.dump(vars(args), f, indent=2)

    print(f"\n{'='*60}")
    print("FedMemè®­ç»ƒé…ç½®")
    print(f"{'='*60}")
    for key, value in vars(args).items():
        print(f"{key}: {value}")
    print(f"{'='*60}\n")

    # ============================================
    # 1. [UPDATED] åŠ è½½æ•°æ®ï¼ˆåŒ…å«å¤šæ¨¡æ€ç‰¹å¾ï¼‰
    # ============================================
    print("\n[1/4] åŠ è½½æ•°æ®...")
    data_path = os.path.join(args.data_dir, args.data_file)

    if not os.path.exists(data_path):
        print(f"é”™è¯¯ï¼šæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {data_path}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨æˆ–ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„")
        return

    # [ä¸‰é˜¶æ®µè®­ç»ƒ] ç¬¬ä¸€é˜¶æ®µï¼šçº¯IDè®­ç»ƒï¼Œç¦ç”¨å¤šæ¨¡æ€
    if args.stage == "pretrain_sasrec":
        print(f"  [Stage 1] çº¯ID SASRecé¢„è®­ç»ƒ - ç¦ç”¨å¤šæ¨¡æ€ç‰¹å¾åŠ è½½")
        visual_file_to_load = None
        text_file_to_load = None

        # [Stage 1å…³é”®ä¿®å¤] Stage 1ç›®æ ‡æ˜¯å¤ç°FedSASRecæ€§èƒ½ï¼›partial warmupè‹¥åªèšåˆ'sasrec'ä¼šé—æ¼item/pos embeddingï¼Œå¯¼è‡´globalæ¨¡å‹æ— æ³•å¯¹é½ã€‚
        if args.partial_aggregation_warmup_rounds != 0:
            print(f"  [Stage 1] è‡ªåŠ¨å…³é—­partial warmup: {args.partial_aggregation_warmup_rounds} -> 0")
            args.partial_aggregation_warmup_rounds = 0
    else:
        visual_file_to_load = args.visual_file
        text_file_to_load = args.text_file

    # [NEW] åŠ è½½äº¤äº’åºåˆ— + å¤šæ¨¡æ€ç‰¹å¾
    user_sequences, num_items, item_visual_feats, item_text_feats, img_dim, text_dim = load_user_sequences(
        data_path=data_path,
        data_dir=args.data_dir,
        visual_file=visual_file_to_load,
        text_file=text_file_to_load,
        device=args.device
    )
    args.num_items = num_items  # æ›´æ–°num_items

    # ============================================
    # 2. [UPDATED] åˆ›å»ºå…¨å±€æ¨¡å‹ï¼ˆæ ¹æ®model_typeé€‰æ‹©æ¶æ„ï¼‰
    # ============================================
    # [NEW] ä½¿ç”¨ä»æ•°æ®åŠ è½½å¾—åˆ°çš„å®é™…ç»´åº¦
    # å¦‚æœæ²¡æœ‰åŠ è½½å¤šæ¨¡æ€ç‰¹å¾ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦
    actual_text_dim = text_dim if item_text_feats is not None else 384
    actual_img_dim = img_dim if item_visual_feats is not None else 512

    # æ ¹æ®model_typeé€‰æ‹©æ¨¡å‹æ¶æ„
    if args.model_type == "moe":
        print("\n[2/4] åˆ›å»ºå…¨å±€ UR4RecV2MoE æ¨¡å‹ï¼ˆMoEæ¶æ„ï¼‰...")
        print(f"  æ¨¡å‹é…ç½®:")
        print(f"    - æ¶æ„: MoE (Mixture of Experts)")
        print(f"    - ç‰©å“æ•°: {args.num_items}")
        print(f"    - æ–‡æœ¬ç‰¹å¾ç»´åº¦: {actual_text_dim}")
        print(f"    - å›¾åƒç‰¹å¾ç»´åº¦: {actual_img_dim}")
        print(f"    - SASRecéšè—ç»´åº¦: {args.sasrec_hidden_dim}")
        print(f"    - MoEéšè—ç»´åº¦: {args.sasrec_hidden_dim}")

        global_model = UR4RecV2MoE(
            num_items=args.num_items,
            # SASRecå‚æ•°
            sasrec_hidden_dim=args.sasrec_hidden_dim,
            sasrec_num_blocks=args.sasrec_num_blocks,
            sasrec_num_heads=args.sasrec_num_heads,
            sasrec_dropout=0.1,
            max_seq_len=args.max_seq_len,
            # å¤šæ¨¡æ€ç‰¹å¾ç»´åº¦
            visual_dim=actual_img_dim,  # CLIPç‰¹å¾ç»´åº¦
            text_dim=actual_text_dim,   # Sentence-BERTç‰¹å¾ç»´åº¦
            # MoEå‚æ•°
            moe_hidden_dim=args.sasrec_hidden_dim,  # ä¸SASRecä¿æŒä¸€è‡´
            moe_num_heads=args.moe_num_heads,
            moe_dropout=0.1,
            router_hidden_dim=128,
            # æ®‹å·®å¢å¼ºå‚æ•°
            gating_init=args.gating_init,
            # è´Ÿè½½å‡è¡¡
            load_balance_lambda=0.01,
            # ã€ç­–ç•¥1ã€‘Router Bias Initialization [å·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹]
            init_bias_for_sasrec=args.init_bias_for_sasrec,
            sasrec_bias_value=args.sasrec_bias_value,
            # è®¾å¤‡
            device=args.device
        )

    elif args.model_type == "simple":
        print("\n[2/4] åˆ›å»ºå…¨å±€ FedMemSimple æ¨¡å‹ï¼ˆç®€åŒ–æ¶æ„ï¼‰...")

        # è®¡ç®—æ€»çš„è¾“å…¥ç»´åº¦
        total_input_dim = args.id_emb_dim + args.visual_proj_dim + args.text_proj_dim

        print(f"  æ¨¡å‹é…ç½®:")
        print(f"    - æ¶æ„: Simple (ç›´æ¥æ‹¼æ¥)")
        print(f"    - ç‰©å“æ•°: {args.num_items}")
        print(f"    - IDåµŒå…¥ç»´åº¦: {args.id_emb_dim}")
        print(f"    - è§†è§‰æŠ•å½±ç»´åº¦: {actual_img_dim} â†’ {args.visual_proj_dim}")
        print(f"    - æ–‡æœ¬æŠ•å½±ç»´åº¦: {actual_text_dim} â†’ {args.text_proj_dim}")
        print(f"    - æ‹¼æ¥åæ€»ç»´åº¦: {total_input_dim}")
        print(f"    - SASRecè¾“å…¥ç»´åº¦: {total_input_dim}")

        global_model = FedMemSimple(
            num_items=args.num_items,
            # ID embeddingç»´åº¦
            id_emb_dim=args.id_emb_dim,
            # å¤šæ¨¡æ€ç‰¹å¾ç»´åº¦
            visual_dim=actual_img_dim,      # CLIPç‰¹å¾
            text_dim=actual_text_dim,       # Sentence-BERTç‰¹å¾
            # æŠ•å½±ç»´åº¦
            visual_proj_dim=args.visual_proj_dim,
            text_proj_dim=args.text_proj_dim,
            # SASRecå‚æ•°
            sasrec_num_blocks=args.sasrec_num_blocks,
            sasrec_num_heads=args.sasrec_num_heads,
            sasrec_dropout=0.1,
            max_seq_len=args.max_seq_len,
            # è®¾å¤‡
            device=args.device
        )

    else:
        raise ValueError(f"æœªçŸ¥çš„model_type: {args.model_type}. æ”¯æŒ: 'moe', 'simple'")

    print(f"\nâœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
    print(f"  æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in global_model.parameters()):,}")
    trainable_params = sum(p.numel() for p in global_model.parameters() if p.requires_grad)
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    # ============================================
    # 2.5. [NEW] åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¯é€‰ï¼‰
    # ============================================
    if args.pretrained_path is not None:
        print(f"\n[2.5/4] åŠ è½½é¢„è®­ç»ƒæƒé‡...")
        print(f"  è·¯å¾„: {args.pretrained_path}")

        if os.path.exists(args.pretrained_path):
            try:
                # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPyTorch 2.6+éœ€è¦weights_only=Falseæ¥åŠ è½½åŒ…å«numpyå¯¹è±¡çš„checkpointï¼‰
                pretrained_state = torch.load(args.pretrained_path, map_location=args.device, weights_only=False)

                # åªåŠ è½½SASRecéª¨å¹²æƒé‡ï¼ˆå…¼å®¹æ€§åŠ è½½ï¼‰
                current_state = global_model.state_dict()
                loaded_keys = []
                skipped_keys = []

                for key, value in pretrained_state.items():
                    # ä¼˜å…ˆåŠ è½½SASRecç›¸å…³å‚æ•°
                    if 'sasrec' in key.lower() or 'item_emb' in key.lower():
                        if key in current_state and current_state[key].shape == value.shape:
                            current_state[key] = value
                            loaded_keys.append(key)
                        else:
                            skipped_keys.append(key)
                    # å¯é€‰ï¼šåŠ è½½Routerå’ŒLayerNormï¼ˆå¦‚æœå½¢çŠ¶åŒ¹é…ï¼‰
                    elif 'router' in key.lower() or 'layernorm' in key.lower():
                        if key in current_state and current_state[key].shape == value.shape:
                            current_state[key] = value
                            loaded_keys.append(key)
                        else:
                            skipped_keys.append(key)
                    else:
                        skipped_keys.append(key)

                # åº”ç”¨åŠ è½½çš„æƒé‡
                global_model.load_state_dict(current_state)

                print(f"  âœ“ æˆåŠŸåŠ è½½ {len(loaded_keys)} ä¸ªå‚æ•°")
                print(f"    ä¸»è¦æ¨¡å—: SASRecéª¨å¹²ã€ItemåµŒå…¥ã€Router")
                if len(skipped_keys) > 0:
                    print(f"  âš ï¸  è·³è¿‡ {len(skipped_keys)} ä¸ªå‚æ•°ï¼ˆå½¢çŠ¶ä¸åŒ¹é…æˆ–ééª¨å¹²å‚æ•°ï¼‰")

                # é‡è¦æç¤º
                print(f"\n  ğŸ“Œ é¢„è®­ç»ƒæƒé‡å·²åŠ è½½ï¼Œå»ºè®®:")
                print(f"    - ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆå¦‚1e-4, å½“å‰{args.learning_rate}ï¼‰")
                print(f"    - å‡å°‘è®­ç»ƒè½®æ•°ï¼ˆå½“å‰{args.num_rounds}è½®ï¼‰")
                print(f"    - ç›´æ¥è·³è¿‡Warmupï¼ˆè®¾ç½®partial_aggregation_warmup_rounds=0ï¼‰")

            except Exception as e:
                print(f"  âœ— åŠ è½½é¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ç»§ç»­è®­ç»ƒ")
        else:
            print(f"  âœ— é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {args.pretrained_path}")
            print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ç»§ç»­è®­ç»ƒ")

    # ============================================
    # 3. [ä¸‰é˜¶æ®µè®­ç»ƒ] CheckpointåŠ è½½ä¸æ¨¡å‹æ›´æ–° (åœ¨åˆ›å»ºå®¢æˆ·ç«¯ä¹‹å‰)
    # ============================================
    print(f"\n[3/4] ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ - CheckpointåŠ è½½...")

    if args.stage == "pretrain_sasrec":
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šçº¯ID SASRecé¢„è®­ç»ƒ =====
        print(f"  [Stage 1: Backbone Pre-training]")
        print(f"  ç›®æ ‡: è®­ç»ƒé«˜è´¨é‡çš„çº¯ID SASRec (é¢„æœŸ HR@10 â‰ˆ 0.60-0.70)")
        print(f"  è®­ç»ƒå¯¹è±¡: SASRec (Embedding + Transformer)")
        print(f"  æ•°æ®: ä»…Item IDåºåˆ—")
        print(f"  å†»ç»“: æ— ")
        print(f"  âœ“ æ‰€æœ‰å‚æ•°å¯è®­ç»ƒ")

    elif args.stage == "align_projectors":
        # ===== ç¬¬äºŒé˜¶æ®µï¼šå¤šæ¨¡æ€æŠ•å½±å±‚å¯¹é½ =====
        print(f"  [Stage 2: Modality Alignment]")
        print(f"  ç›®æ ‡: è®©å¤šæ¨¡æ€ç‰¹å¾å¯¹é½åˆ°IDç©ºé—´")
        print(f"  è®­ç»ƒå¯¹è±¡: Visual/Semantic Projectors")
        print(f"  å†»ç»“: SASRec + Item Embedding")

        # [å…³é”®ä¿®å¤] Stage 2ç¦ç”¨warmup
        # åŸå› ï¼šwarmupåªèšåˆSASRecï¼Œä½†Stage 2å†»ç»“äº†SASRecï¼Œè®­ç»ƒçš„æ˜¯æŠ•å½±å±‚
        if args.partial_aggregation_warmup_rounds > 0:
            print(f"  âš ï¸  è­¦å‘Š: Stage 2åº”è¯¥ç¦ç”¨warmupï¼ˆå½“å‰è®¾ç½®={args.partial_aggregation_warmup_rounds}ï¼‰")
            print(f"  åŸå› : warmupåªèšåˆSASRecï¼Œä½†Stage 2è®­ç»ƒçš„æ˜¯æŠ•å½±å±‚")
            print(f"  è‡ªåŠ¨ç¦ç”¨warmup...")
            args.partial_aggregation_warmup_rounds = 0

        # åŠ è½½Stage 1 checkpoint
        if args.stage1_checkpoint and os.path.exists(args.stage1_checkpoint):
            print(f"  åŠ è½½Stage 1 checkpoint: {args.stage1_checkpoint}")
            try:
                checkpoint = torch.load(args.stage1_checkpoint, map_location=args.device, weights_only=False)
                state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint

                # [æ–¹æ¡ˆ2ä¿®å¤] Stage 2æ—¶ä¸åŠ è½½expertå’ŒLayerNormå‚æ•°ï¼Œå› ä¸ºç»´åº¦å·²æ”¹å˜
                # Stage 1çš„expertæ˜¯128ç»´ï¼Œæ–¹æ¡ˆ2çš„expertæ˜¯512/384ç»´
                # Stage 1çš„LayerNormä¹Ÿæ˜¯128ç»´ï¼Œéœ€è¦è·³è¿‡é¿å…è¦†ç›–æ–°çš„512/384ç»´LayerNorm
                filtered_state_dict = {}
                skipped_keys = []
                for key, value in state_dict.items():
                    # è·³è¿‡visual_expertã€semantic_expertã€cross_modal_fusionå’Œç›¸å…³LayerNormçš„å‚æ•°
                    if any(pattern in key for pattern in [
                        'visual_expert', 'semantic_expert', 'cross_modal_fusion',
                        'vis_layernorm', 'sem_layernorm'
                    ]):
                        skipped_keys.append(key)
                        continue
                    filtered_state_dict[key] = value

                if skipped_keys:
                    dprint(f"  [æ–¹æ¡ˆ2] è·³è¿‡åŠ è½½expertå’ŒLayerNormå‚æ•°ï¼ˆç»´åº¦å·²æ”¹å˜ï¼‰: {len(skipped_keys)}ä¸ª")
                    for key in skipped_keys[:3]:
                        print(f"     - {key}")
                    if len(skipped_keys) > 3:
                        print(f"     - ... è¿˜æœ‰{len(skipped_keys)-3}ä¸ª")

                # [STAGE 2/3 FIX] strict=Falseå…è®¸éƒ¨åˆ†åŠ è½½ï¼Œå¿½ç•¥missing keysï¼ˆå¦‚gating_weightï¼‰
                missing_keys, unexpected_keys = global_model.load_state_dict(filtered_state_dict, strict=False)

                print(f"  âœ“ æˆåŠŸåŠ è½½Stage 1æƒé‡åˆ°global_model")
                if missing_keys:
                    dprint(f"  â„¹ï¸  æ–°å¢å‚æ•°ï¼ˆStage 1 checkpointä¸­ä¸å­˜åœ¨ï¼‰: {len(missing_keys)}ä¸ª")
                    for key in missing_keys[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"     - {key} (å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–)")
                    if len(missing_keys) > 3:
                        print(f"     - ... è¿˜æœ‰{len(missing_keys)-3}ä¸ª")

                # [è°ƒè¯•] éªŒè¯æƒé‡ç¡®å®è¢«åŠ è½½ - æ£€æŸ¥å…³é”®å‚æ•°
                param_stats = []
                for name, param in global_model.named_parameters():
                    if 'item_emb' in name.lower() or 'sasrec' in name.lower():
                        param_stats.append((name, param.mean().item(), param.std().item(), param.abs().max().item()))
                        if len(param_stats) >= 3:  # åªæ‰“å°å‰3ä¸ªå…³é”®å‚æ•°
                            break

                dprint(f"  [è°ƒè¯•] å…³é”®å‚æ•°ç»Ÿè®¡ï¼ˆéªŒè¯æ˜¯å¦çœŸçš„åŠ è½½äº†è®­ç»ƒå¥½çš„æƒé‡ï¼‰:")
                for name, mean, std, max_val in param_stats:
                    print(f"    {name}: mean={mean:.4f}, std={std:.4f}, max={max_val:.4f}")
                dprint(f"  [è°ƒè¯•] å¦‚æœæ˜¯è®­ç»ƒå¥½çš„æƒé‡ï¼Œmeanå’Œmaxåº”è¯¥æœ‰æ˜æ˜¾çš„éé›¶å€¼")

                # [æ–¹æ¡ˆ2è°ƒè¯•] éªŒè¯expertå’ŒLayerNormçš„ç»´åº¦
                dprint(f"\n  [æ–¹æ¡ˆ2è°ƒè¯•] éªŒè¯æ¨¡å‹ç»´åº¦è®¾ç½®:")
                print(f"    preserve_multimodal_dim: {global_model.preserve_multimodal_dim}")
                print(f"    visual_expert.output_dim: {global_model.visual_expert.output_dim}")
                print(f"    semantic_expert.output_dim: {global_model.semantic_expert.output_dim}")
                print(f"    vis_layernorm.normalized_shape: {global_model.vis_layernorm.normalized_shape}")
                print(f"    sem_layernorm.normalized_shape: {global_model.sem_layernorm.normalized_shape}")

            except Exception as e:
                print(f"  âœ— åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"  âš ï¸  è­¦å‘Š: æœªæä¾›Stage 1 checkpointï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

        print(f"  âœ“ CheckpointåŠ è½½å®Œæˆï¼Œå†»ç»“ç­–ç•¥å°†åœ¨åˆ›å»ºå®¢æˆ·ç«¯ååº”ç”¨")

    elif args.stage == "finetune_moe":
        # ===== ç¬¬ä¸‰é˜¶æ®µï¼šMoEé›†æˆå¾®è°ƒ =====
        print(f"  [Stage 3: MoE Fine-tuning]")
        print(f"  ç›®æ ‡: å­¦ä¹ Router (ä»€ä¹ˆæ—¶å€™ç”¨è°)")
        print(f"  å¾®è°ƒ (å°LR): SASRec Transformer, Visual/Semantic Projectors")
        print(f"  å…¨é€Ÿè®­ç»ƒ: MoE Router")
        print(f"  å†»ç»“: Item Embedding (é”šç‚¹)")

        # [å…³é”®ä¿®å¤] Stage 3ç¦ç”¨warmup
        # åŸå› ï¼šwarmupåªèšåˆSASRecï¼Œä½†Stage 3éœ€è¦èšåˆTransformerã€æŠ•å½±å±‚ã€Router
        if args.partial_aggregation_warmup_rounds > 0:
            print(f"  âš ï¸  è­¦å‘Š: Stage 3åº”è¯¥ç¦ç”¨warmupï¼ˆå½“å‰è®¾ç½®={args.partial_aggregation_warmup_rounds}ï¼‰")
            print(f"  åŸå› : warmupåªèšåˆSASRecï¼Œä½†Stage 3éœ€è¦èšåˆå¤šä¸ªç»„ä»¶")
            print(f"  è‡ªåŠ¨ç¦ç”¨warmup...")
            args.partial_aggregation_warmup_rounds = 0

        # åŠ è½½Stage 1 checkpoint (backbone)
        if args.stage1_checkpoint and os.path.exists(args.stage1_checkpoint):
            print(f"  åŠ è½½Stage 1 checkpoint: {args.stage1_checkpoint}")
            try:
                checkpoint = torch.load(args.stage1_checkpoint, map_location=args.device, weights_only=False)
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint

                # [å…³é”®ä¿®å¤] åŠ è½½SASRec + Item Embedding
                # åŸå› ï¼šStage 3å†»ç»“item_embï¼Œå¿…é¡»åŠ è½½è®­ç»ƒå¥½çš„embedding
                # å¦åˆ™ä¼šå‡ºç°"è®­ç»ƒå¥½çš„SASRec + éšæœºçš„embedding"çš„ä¸åŒ¹é…
                current_state = global_model.state_dict()
                loaded = 0
                for key, value in state_dict.items():
                    # åŠ è½½ SASRec å’Œ item_emb
                    if ('sasrec' in key.lower() or 'item_emb' in key.lower()) and key in current_state:
                        current_state[key] = value
                        loaded += 1
                global_model.load_state_dict(current_state)
                print(f"  âœ“ æˆåŠŸåŠ è½½Stage 1æƒé‡åˆ°global_model ({loaded}ä¸ªå‚æ•°)")
                print(f"     åŒ…æ‹¬: SASRecéª¨å¹² + Item Embedding")
            except Exception as e:
                print(f"  âœ— åŠ è½½Stage 1å¤±è´¥: {e}")

        # åŠ è½½Stage 2 checkpoint (projectors)
        if args.stage2_checkpoint and os.path.exists(args.stage2_checkpoint):
            print(f"  åŠ è½½Stage 2 checkpoint: {args.stage2_checkpoint}")
            try:
                checkpoint = torch.load(args.stage2_checkpoint, map_location=args.device, weights_only=False)
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint

                # [å…³é”®ä¿®å¤] Stage 3åªåŠ è½½æŠ•å½±å±‚å’Œgatingï¼Œè·³è¿‡éšæœºçš„MoEç»„ä»¶
                # åŸå› ï¼šStage 2è®­ç»ƒæ—¶MoEç»„ä»¶ï¼ˆrouter/expert/fusionï¼‰æ˜¯å†»ç»“çš„ï¼ˆéšæœºçŠ¶æ€ï¼‰
                #       Stage 3ä¸åº”è¯¥åŠ è½½è¿™äº›éšæœºå‚æ•°ï¼Œåº”è¯¥ç”¨è‡ªå·±çš„åˆå§‹åŒ–
                current_state = global_model.state_dict()
                loaded = 0
                skipped_shape = []
                skipped_random_moe = []
                for key, value in state_dict.items():
                    # [Stage 3å…³é”®] åªåŠ è½½Stage 2è®­ç»ƒè¿‡çš„ç»„ä»¶
                    # âœ“ åŠ è½½: visual_proj, text_proj, align_gating, gating_weight
                    # âœ— è·³è¿‡: router, expert, cross_modal_fusion (è¿™äº›åœ¨Stage 2æ˜¯å†»ç»“/éšæœºçš„)
                    should_load = (
                        ('proj' in key.lower() and 'expert' not in key.lower()) or  # æŠ•å½±å±‚ï¼ˆéExpertå†…éƒ¨çš„projï¼‰
                        'align_gating' in key.lower() or    # Stage 2è®­ç»ƒçš„å¯¹é½é—¨æ§
                        'gating_weight' in key.lower()      # æ®‹å·®èåˆæƒé‡ï¼ˆæ ¸å¿ƒï¼ï¼‰
                    )

                    # è®°å½•è·³è¿‡çš„MoEç»„ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    is_moe_component = (
                        'router' in key.lower() or
                        'expert' in key.lower() or
                        'cross_modal_fusion' in key.lower() or
                        ('layernorm' in key.lower() and any(x in key.lower() for x in ['vis_', 'sem_', 'seq_']))
                    )
                    if is_moe_component:
                        skipped_random_moe.append(key)

                    if should_load and key in current_state:
                        # å½¢çŠ¶æ£€æŸ¥ï¼šåªåŠ è½½å½¢çŠ¶åŒ¹é…çš„å‚æ•°
                        if current_state[key].shape == value.shape:
                            current_state[key] = value
                            loaded += 1
                        else:
                            skipped_shape.append(f"{key} (ckpt:{value.shape} vs model:{current_state[key].shape})")

                # æ‰“å°è·³è¿‡çš„MoEç»„ä»¶ï¼ˆé‡è¦è°ƒè¯•ä¿¡æ¯ï¼‰
                if skipped_random_moe:
                    print(f"  â„¹ï¸  è·³è¿‡Stage 2ä¸­éšæœºçš„MoEç»„ä»¶ ({len(skipped_random_moe)}ä¸ª):")
                    print(f"     åŸå› : è¿™äº›ç»„ä»¶åœ¨Stage 2æ˜¯å†»ç»“çš„ï¼ˆæœªè®­ç»ƒï¼‰ï¼Œä¸åº”è¯¥åŠ è½½")
                    print(f"     è·³è¿‡: router ({sum(1 for k in skipped_random_moe if 'router' in k)}), "
                          f"expert ({sum(1 for k in skipped_random_moe if 'expert' in k)}), "
                          f"fusion ({sum(1 for k in skipped_random_moe if 'fusion' in k)}), "
                          f"layernorm ({sum(1 for k in skipped_random_moe if 'layernorm' in k)})")

                if skipped_shape:
                    print(f"  â„¹ï¸  è·³è¿‡å½¢çŠ¶ä¸åŒ¹é…çš„å‚æ•° ({len(skipped_shape)}ä¸ª):")
                    for item in skipped_shape[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"     - {item}")
                    if len(skipped_shape) > 5:
                        print(f"     - ... è¿˜æœ‰{len(skipped_shape)-5}ä¸ª")

                global_model.load_state_dict(current_state)
                print(f"  âœ“ æˆåŠŸåŠ è½½Stage 2æƒé‡åˆ°global_model ({loaded}ä¸ªå‚æ•°)")
                print(f"     åŠ è½½: visual_proj, text_proj, align_gating, gating_weight")
                print(f"     ä¿æŒStage 3è‡ªå·±çš„åˆå§‹åŒ–: router, experts, fusion")
                # [å…³é”®éªŒè¯] æ‰“å°gating_weightå®é™…å€¼
                if hasattr(global_model, 'gating_weight'):
                    print(f"  âœ“ éªŒè¯: gating_weight = {global_model.gating_weight.item():.6f}")
            except Exception as e:
                print(f"  âœ— åŠ è½½Stage 2å¤±è´¥: {e}")

        print(f"  âœ“ CheckpointåŠ è½½å®Œæˆï¼Œå†»ç»“ç­–ç•¥å°†åœ¨åˆ›å»ºå®¢æˆ·ç«¯ååº”ç”¨")

    elif args.stage == "full":
        # ===== å®Œæ•´è®­ç»ƒï¼ˆåŸæœ‰é€»è¾‘ï¼‰ =====
        if args.pretrained_path is not None and os.path.exists(args.pretrained_path):
            print(f"  [Full Training] ä½¿ç”¨å°å­¦ä¹ ç‡å¾®è°ƒï¼ˆä¸å†»ç»“embeddingï¼‰")
            print(f"  åŸå› : éœ€è¦embeddingä¸å¤šæ¨¡æ€ç‰¹å¾å¯¹é½")
            print(f"  âœ“ æ‰€æœ‰å‚æ•°ä¿æŒå¯è®­ç»ƒï¼Œä½¿ç”¨å­¦ä¹ ç‡{args.learning_rate}")
        else:
            print(f"  [Full Training] ä»é›¶å¼€å§‹è®­ç»ƒ")
            print(f"  âœ“ æ‰€æœ‰å‚æ•°å¯è®­ç»ƒ")

    # ============================================
    # 3.5. [UPDATED] åˆ›å»ºFedMemå®¢æˆ·ç«¯ (åœ¨checkpointåŠ è½½å’Œæ¨¡å‹æ›´æ–°ä¹‹å)
    # ============================================
    print("\n[3.5/4] åˆ›å»º FedMem å®¢æˆ·ç«¯...")

    # [NEW] ä¼ é€’å¤šæ¨¡æ€ç‰¹å¾åˆ°å®¢æˆ·ç«¯
    clients = create_fedmem_clients(
        user_sequences=user_sequences,
        global_model=global_model,
        item_visual_feats=item_visual_feats,  # [NEW]
        item_text_feats=item_text_feats,      # [NEW]
        args=args
    )

    # ============================================
    # 3.6. [ä¸‰é˜¶æ®µè®­ç»ƒ] å‚æ•°å†»ç»“ç­–ç•¥ (å®¢æˆ·ç«¯å·²åˆ›å»º)
    # ============================================
    if args.stage == "align_projectors":
        print(f"\n[3.6/4] åº”ç”¨Stage 2å†»ç»“ç­–ç•¥ï¼ˆè½»é‡çº§å¯¹é½ï¼‰...")
        print(f"  âœ“ ç›®æ ‡: è®­ç»ƒæŠ•å½±å±‚ï¼Œå°†å¤šæ¨¡æ€ç‰¹å¾å¯¹é½åˆ°IDç©ºé—´")
        print(f"  âœ“ å‚æ•°é‡: <200K (vs åŸæ–¹æ¡ˆ ~4M)")
        print(f"  å†»ç»“: SASRec + Item Embedding + Experts + CrossModalFusion + Router")
        print(f"  è®­ç»ƒ: visual_proj (512â†’128) + text_proj (384â†’128) + align_gating MLP")

        # åº”ç”¨å†»ç»“ç­–ç•¥åˆ°æ‰€æœ‰å®¢æˆ·ç«¯
        for client in clients:
            client._ensure_model_initialized()
            frozen_params = []
            trainable_params_names = []

            for name, param in client.model.named_parameters():
                k = name.lower()
                # [Stage 2æ ¸å¿ƒ] åªè®­ç»ƒæŠ•å½±å±‚å’Œå¯¹é½é—¨æ§
                if 'visual_proj' in k or 'text_proj' in k or 'align_gating' in k:
                    param.requires_grad = True
                    trainable_params_names.append(name)
                else:
                    # å†»ç»“å…¶ä»–æ‰€æœ‰å‚æ•°ï¼šSASRec, Experts, CrossModalFusion, Router, LayerNorms, Gating Weight
                    param.requires_grad = False
                    frozen_params.append(name)

            # é‡å»ºä¼˜åŒ–å™¨ï¼ˆåªåŒ…å«å¯è®­ç»ƒå‚æ•°ï¼‰
            trainable_params = [p for p in client.model.parameters() if p.requires_grad]
            client.optimizer = torch.optim.Adam(
                trainable_params,
                lr=client.learning_rate,
                weight_decay=client.weight_decay
            )

            # ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°æ•°é‡
            if client.client_id == list(user_sequences.keys())[0]:  # åªæ‰“å°ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯
                num_trainable = sum(p.numel() for p in trainable_params)
                print(f"  ç¤ºä¾‹å®¢æˆ·ç«¯ {client.client_id}:")
                print(f"    - å†»ç»“å‚æ•°: {len(frozen_params)}ä¸ª")
                print(f"    - å¯è®­ç»ƒå‚æ•°: {len(trainable_params_names)}ä¸ª (~{num_trainable:,} params)")
                print(f"    - å¯è®­ç»ƒå±‚: {', '.join(trainable_params_names)}")

        print(f"  âœ“ æ‰€æœ‰ {len(clients)} ä¸ªå®¢æˆ·ç«¯å·²åº”ç”¨Stage 2è½»é‡çº§å†»ç»“ç­–ç•¥")

    elif args.stage == "finetune_moe":
        print(f"\n[3.6/4] Stage 3: ä¸‰é˜¶æ®µæ¸è¿›å¼è§£å†»ç­–ç•¥")
        print(f"  [æ–¹æ¡ˆ1] æ¸è¿›å¼è§£å†»å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€åº”ç”¨ï¼š")
        print(f"    Stage 3a (Round 0-9):  å†»ç»“ SASRec+æŠ•å½±å±‚+Experts+Fusion, è®­ç»ƒ Router")
        print(f"    Stage 3b (Round 10-29): å†»ç»“ SASRec+æŠ•å½±å±‚, è®­ç»ƒ Router+Experts+Fusion")
        print(f"    Stage 3c (Round 30-49): å†»ç»“ item_emb, è®­ç»ƒ æ‰€æœ‰å…¶ä»–å‚æ•° (LR=1e-5)")
        print(f"  âœ“ ç›®æ ‡: æ¸è¿›è§£å†»ï¼Œé¿å…ç ´åStage 2å­¦åˆ°çš„SASRec-æŠ•å½±å±‚é…åˆ")

        # [å…³é”®éªŒè¯] æ£€æŸ¥gating_weightæ˜¯å¦æ­£ç¡®åŠ è½½
        sample_client = clients[0]
        sample_client._ensure_model_initialized()
        if hasattr(sample_client.model, 'gating_weight'):
            print(f"  âœ“ éªŒè¯: å®¢æˆ·ç«¯ {sample_client.client_id} gating_weight = {sample_client.model.gating_weight.item():.6f}")

        print(f"  âœ“ æ¸è¿›å¼å†»ç»“ç­–ç•¥å°†åœ¨æ¯è½®è®­ç»ƒæ—¶åŠ¨æ€åº”ç”¨")

        # æ³¨ï¼šåŸæœ‰çš„é™æ€å†»ç»“ç­–ç•¥å·²ç§»é™¤ï¼Œæ”¹ä¸ºåœ¨FedMemServer.train_roundä¸­åŠ¨æ€åº”ç”¨

    # ============================================
    # 4. åˆ›å»ºFedMemæœåŠ¡å™¨å¹¶å¼€å§‹è®­ç»ƒ
    # ============================================
    print("\n[4/4] åˆ›å»º FedMem æœåŠ¡å™¨å¹¶å¼€å§‹è®­ç»ƒ...")

    server = FedMemServer(
        global_model=global_model,
        clients=clients,
        device=args.device,
        # è”é‚¦å­¦ä¹ å‚æ•°
        aggregation_method=args.aggregation_method,
        client_fraction=args.client_fraction,
        num_rounds=args.num_rounds,
        local_epochs=args.local_epochs,
        patience=args.patience,
        # FedMemå‚æ•°
        enable_prototype_aggregation=args.enable_prototype_aggregation,
        num_memory_prototypes=args.num_memory_prototypes,
        # ã€ç­–ç•¥2ã€‘Partial Aggregation
        partial_aggregation_warmup_rounds=args.partial_aggregation_warmup_rounds,
        # [æ–¹æ¡ˆ1] æ¸è¿›å¼è§£å†»
        stage=args.stage
    )

    # å¼€å§‹è®­ç»ƒï¼ˆä¼ é€’user_sequencesç”¨äºè´Ÿé‡‡æ ·è¯„ä¼°ï¼‰
    train_history = server.train(user_sequences=user_sequences, verbose=args.verbose or True)

    # ============================================
    # 5. ä¿å­˜æ¨¡å‹å’Œç»“æœ
    # ============================================
    print("\nä¿å­˜æ¨¡å‹å’Œè®­ç»ƒå†å²...")

    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(args.save_dir, 'fedmem_model.pt')
    server.save_model(model_path)

    # ä¿å­˜è®­ç»ƒå†å²
    history_path = os.path.join(args.save_dir, 'train_history.json')
    with open(history_path, 'w') as f:
        # å°†tensorè½¬æ¢ä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        history_serializable = {}
        for key, value in train_history.items():
            if isinstance(value, list):
                history_serializable[key] = [
                    {k: float(v) if isinstance(v, (int, float)) else v
                     for k, v in item.items()}
                    if isinstance(item, dict) else item
                    for item in value
                ]
            elif isinstance(value, dict):
                history_serializable[key] = {
                    k: float(v) if isinstance(v, (int, float)) else v
                    for k, v in value.items()
                }
            else:
                history_serializable[key] = value

        json.dump(history_serializable, f, indent=2)

    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    print(f"âœ“ è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")

    # ============================================
    # 6. æ‰“å°æœ€ç»ˆç»“æœ
    # ============================================
    print(f"\n{'='*60}")
    print("æœ€ç»ˆç»“æœ")
    print(f"{'='*60}")

    test_metrics = train_history['test_metrics']
    print("\næµ‹è¯•é›†æŒ‡æ ‡:")
    for key, value in test_metrics.items():
        print(f"  {key}: {value:.4f}")

    best_metrics = server.get_best_metrics()
    dprint(f"\næœ€ä½³éªŒè¯è½®æ¬¡: {best_metrics.get('round', -1) + 1}")
    dprint("æœ€ä½³éªŒè¯æŒ‡æ ‡:")
    for key, value in best_metrics.items():
        if key != 'round':
            print(f"  {key}: {value:.4f}")

    # [NEW] æ‰“å°å¤šæ¨¡æ€ä½¿ç”¨æƒ…å†µ
    print(f"\n{'='*60}")
    print("å¤šæ¨¡æ€ä½¿ç”¨æƒ…å†µ")
    print(f"{'='*60}")
    print(f"è§†è§‰ç‰¹å¾: {'âœ“ ä½¿ç”¨' if item_visual_feats is not None else 'âœ— æœªä½¿ç”¨'}")
    print(f"æ–‡æœ¬ç‰¹å¾: {'âœ“ ä½¿ç”¨' if item_text_feats is not None else 'âœ— æœªä½¿ç”¨'}")
    if item_visual_feats is None and item_text_feats is None:
        print("\nâš ï¸ æ³¨æ„: æœªåŠ è½½ä»»ä½•å¤šæ¨¡æ€ç‰¹å¾ï¼")
        print("   å»ºè®®ä½¿ç”¨ --visual_file å’Œ --text_file å‚æ•°åŠ è½½å¤šæ¨¡æ€æ•°æ®")
        print("   ä»¥è·å¾—æ›´å¥½çš„æ¨èæ•ˆæœã€‚")

    print(f"\n{'='*60}")
    print("è®­ç»ƒå®Œæˆï¼")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()