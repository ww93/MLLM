"""
FedMemè®­ç»ƒè„šæœ¬ï¼šå¸¦æœ¬åœ°åŠ¨æ€è®°å¿†å’ŒåŸå‹èšåˆçš„è”é‚¦æ¨èç³»ç»Ÿï¼ˆæ”¯æŒå¤šæ¨¡æ€æ•°æ®ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # åŸºæœ¬ç”¨æ³•ï¼ˆä»…IDç‰¹å¾ï¼‰
    python scripts/train_fedmem.py --data_dir data/ml-1m --save_dir checkpoints/fedmem

    # å®Œæ•´å¤šæ¨¡æ€ç”¨æ³•
    python scripts/train_fedmem.py \
        --data_dir data/ml-1m \
        --visual_file item_images.npy \
        --text_file item_llm_texts.npy \
        --save_dir checkpoints/fedmem

æ ¸å¿ƒç‰¹æ€§ï¼š
1. æœ¬åœ°åŠ¨æ€è®°å¿†ï¼ˆLocalDynamicMemoryï¼‰
2. Surprise-basedè®°å¿†æ›´æ–°
3. è®°å¿†åŸå‹èšåˆï¼ˆPrototype Aggregationï¼‰
4. å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆContrastive Lossï¼‰
5. **[NEW] å¤šæ¨¡æ€ç‰¹å¾åŠ è½½ï¼ˆè§†è§‰ + æ–‡æœ¬ï¼‰**
"""
import os
import sys
import json
import argparse
import torch
import numpy as np
import random
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from models.ur4rec_v2_moe import UR4RecV2MoE
from models.fedmem_client import FedMemClient
from models.fedmem_server import FedMemServer


def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


# [NEW] å¤šæ¨¡æ€ç‰¹å¾åŠ è½½å‡½æ•°
def load_multimodal_features(
    data_dir: str,
    visual_file: Optional[str],
    text_file: Optional[str],
    num_items: int,
    device: str = 'cpu'
) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], int, int]:
    """
    åŠ è½½é¢„æå–çš„å¤šæ¨¡æ€ç‰¹å¾

    Args:
        data_dir: æ•°æ®ç›®å½•
        visual_file: è§†è§‰ç‰¹å¾æ–‡ä»¶å (e.g., 'item_images.npy' or 'item_images.pt')
        text_file: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å (e.g., 'item_llm_texts.npy' or 'item_llm_texts.pt')
        num_items: ç‰©å“æ€»æ•°
        device: è®¡ç®—è®¾å¤‡

    Returns:
        item_visual_feats: [num_items, img_dim] æˆ– None
        item_text_feats: [num_items, text_dim] æˆ– None
        img_dim: è§†è§‰ç‰¹å¾ç»´åº¦
        text_dim: æ–‡æœ¬ç‰¹å¾ç»´åº¦
    """
    item_visual_feats = None
    item_text_feats = None
    img_dim = 512  # é»˜è®¤ç»´åº¦
    text_dim = 768  # é»˜è®¤ç»´åº¦

    print(f"\n{'='*60}")
    print("åŠ è½½å¤šæ¨¡æ€ç‰¹å¾")
    print(f"{'='*60}")

    # ========== åŠ è½½è§†è§‰ç‰¹å¾ ==========
    if visual_file:
        visual_path = os.path.join(data_dir, visual_file)

        if os.path.exists(visual_path):
            try:
                # æ”¯æŒ.npyå’Œ.ptæ ¼å¼
                if visual_path.endswith('.npy'):
                    visual_np = np.load(visual_path)
                    item_visual_feats = torch.from_numpy(visual_np).float().to(device)
                elif visual_path.endswith('.pt') or visual_path.endswith('.pth'):
                    item_visual_feats = torch.load(visual_path, map_location=device)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è§†è§‰ç‰¹å¾æ–‡ä»¶æ ¼å¼: {visual_path}")

                # éªŒè¯å½¢çŠ¶
                if item_visual_feats.shape[0] != num_items:
                    print(f"âš ï¸ è­¦å‘Š: è§†è§‰ç‰¹å¾æ•°é‡ ({item_visual_feats.shape[0]}) ä¸ç‰©å“æ•°é‡ ({num_items}) ä¸åŒ¹é…")
                    print(f"   å°†åˆ›å»ºé›¶å¡«å……ç‰¹å¾ä»¥åŒ¹é…ç‰©å“æ•°é‡")

                    # åˆ›å»ºé›¶å¡«å……ç‰¹å¾
                    img_dim = item_visual_feats.shape[1]
                    padded_feats = torch.zeros(num_items, img_dim, device=device)
                    min_items = min(num_items, item_visual_feats.shape[0])
                    padded_feats[:min_items] = item_visual_feats[:min_items]
                    item_visual_feats = padded_feats
                else:
                    img_dim = item_visual_feats.shape[1]

                print(f"âœ“ æˆåŠŸåŠ è½½è§†è§‰ç‰¹å¾: {visual_path}")
                print(f"  å½¢çŠ¶: {item_visual_feats.shape}")
                print(f"  æ•°æ®ç±»å‹: {item_visual_feats.dtype}")
                print(f"  ç»Ÿè®¡: min={item_visual_feats.min():.4f}, max={item_visual_feats.max():.4f}, mean={item_visual_feats.mean():.4f}")

            except Exception as e:
                print(f"âœ— åŠ è½½è§†è§‰ç‰¹å¾å¤±è´¥: {e}")
                print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„è§†è§‰ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")
                item_visual_feats = None
        else:
            print(f"âš ï¸ è­¦å‘Š: è§†è§‰ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {visual_path}")
            print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„è§†è§‰ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")

    # å¦‚æœæ²¡æœ‰åŠ è½½æˆåŠŸï¼Œä½¿ç”¨éšæœºç‰¹å¾
    if visual_file and item_visual_feats is None:
        print(f"\n[DEBUG] åˆ›å»ºéšæœºè§†è§‰ç‰¹å¾: [{num_items}, {img_dim}]")
        item_visual_feats = torch.randn(num_items, img_dim, device=device) * 0.01
        print(f"âš ï¸ è­¦å‘Š: ä½¿ç”¨éšæœºè§†è§‰ç‰¹å¾ï¼è¿™ä»…ç”¨äºè°ƒè¯•ï¼Œä¸é€‚åˆæ­£å¼è®­ç»ƒï¼")

    # ========== åŠ è½½æ–‡æœ¬ç‰¹å¾ ==========
    if text_file:
        text_path = os.path.join(data_dir, text_file)

        if os.path.exists(text_path):
            try:
                # æ”¯æŒ.npyå’Œ.ptæ ¼å¼
                if text_path.endswith('.npy'):
                    text_np = np.load(text_path)
                    item_text_feats = torch.from_numpy(text_np).float().to(device)
                elif text_path.endswith('.pt') or text_path.endswith('.pth'):
                    item_text_feats = torch.load(text_path, map_location=device)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æœ¬ç‰¹å¾æ–‡ä»¶æ ¼å¼: {text_path}")

                # éªŒè¯å½¢çŠ¶
                if item_text_feats.shape[0] != num_items:
                    print(f"âš ï¸ è­¦å‘Š: æ–‡æœ¬ç‰¹å¾æ•°é‡ ({item_text_feats.shape[0]}) ä¸ç‰©å“æ•°é‡ ({num_items}) ä¸åŒ¹é…")
                    print(f"   å°†åˆ›å»ºé›¶å¡«å……ç‰¹å¾ä»¥åŒ¹é…ç‰©å“æ•°é‡")

                    # åˆ›å»ºé›¶å¡«å……ç‰¹å¾
                    text_dim = item_text_feats.shape[1]
                    padded_feats = torch.zeros(num_items, text_dim, device=device)
                    min_items = min(num_items, item_text_feats.shape[0])
                    padded_feats[:min_items] = item_text_feats[:min_items]
                    item_text_feats = padded_feats
                else:
                    text_dim = item_text_feats.shape[1]

                print(f"\nâœ“ æˆåŠŸåŠ è½½æ–‡æœ¬ç‰¹å¾: {text_path}")
                print(f"  å½¢çŠ¶: {item_text_feats.shape}")
                print(f"  æ•°æ®ç±»å‹: {item_text_feats.dtype}")
                print(f"  ç»Ÿè®¡: min={item_text_feats.min():.4f}, max={item_text_feats.max():.4f}, mean={item_text_feats.mean():.4f}")

            except Exception as e:
                print(f"âœ— åŠ è½½æ–‡æœ¬ç‰¹å¾å¤±è´¥: {e}")
                print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ–‡æœ¬ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")
                item_text_feats = None
        else:
            print(f"\nâš ï¸ è­¦å‘Š: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {text_path}")
            print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ–‡æœ¬ç‰¹å¾ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰")

    # å¦‚æœæ²¡æœ‰åŠ è½½æˆåŠŸï¼Œä½¿ç”¨éšæœºç‰¹å¾
    if text_file and item_text_feats is None:
        print(f"\n[DEBUG] åˆ›å»ºéšæœºæ–‡æœ¬ç‰¹å¾: [{num_items}, {text_dim}]")
        item_text_feats = torch.randn(num_items, text_dim, device=device) * 0.01
        print(f"âš ï¸ è­¦å‘Š: ä½¿ç”¨éšæœºæ–‡æœ¬ç‰¹å¾ï¼è¿™ä»…ç”¨äºè°ƒè¯•ï¼Œä¸é€‚åˆæ­£å¼è®­ç»ƒï¼")

    # ========== æ€»ç»“ ==========
    print(f"\n{'='*60}")
    print("å¤šæ¨¡æ€ç‰¹å¾åŠ è½½æ€»ç»“")
    print(f"{'='*60}")
    print(f"è§†è§‰ç‰¹å¾: {'âœ“ å·²åŠ è½½' if item_visual_feats is not None else 'âœ— æœªåŠ è½½'}")
    if item_visual_feats is not None:
        print(f"  ç»´åº¦: {img_dim}")
    print(f"æ–‡æœ¬ç‰¹å¾: {'âœ“ å·²åŠ è½½' if item_text_feats is not None else 'âœ— æœªåŠ è½½'}")
    if item_text_feats is not None:
        print(f"  ç»´åº¦: {text_dim}")
    print(f"{'='*60}\n")

    return item_visual_feats, item_text_feats, img_dim, text_dim


# [UPDATED] æ›´æ–°åçš„åŠ è½½ç”¨æˆ·åºåˆ—å‡½æ•°
def load_user_sequences(
    data_path: str,
    data_dir: str,
    visual_file: Optional[str] = None,
    text_file: Optional[str] = None,
    device: str = 'cpu'
) -> Tuple[Dict[int, List[int]], int, Optional[torch.Tensor], Optional[torch.Tensor], int, int]:
    """
    åŠ è½½ç”¨æˆ·äº¤äº’åºåˆ—å’Œå¤šæ¨¡æ€ç‰¹å¾

    Args:
        data_path: äº¤äº’æ•°æ®æ–‡ä»¶è·¯å¾„
        data_dir: æ•°æ®ç›®å½•ï¼ˆç”¨äºåŠ è½½å¤šæ¨¡æ€ç‰¹å¾ï¼‰
        visual_file: è§†è§‰ç‰¹å¾æ–‡ä»¶å
        text_file: æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å
        device: è®¡ç®—è®¾å¤‡

    Returns:
        user_sequences: {user_id: [item_id1, item_id2, ...]}
        num_items: ç‰©å“æ€»æ•°
        item_visual_feats: [num_items, img_dim] æˆ– None
        item_text_feats: [num_items, text_dim] æˆ– None
        img_dim: è§†è§‰ç‰¹å¾ç»´åº¦
        text_dim: æ–‡æœ¬ç‰¹å¾ç»´åº¦
    """
    user_sequences = {}
    max_item_id = 0

    print(f"\n{'='*60}")
    print("åŠ è½½ç”¨æˆ·äº¤äº’åºåˆ—")
    print(f"{'='*60}")

    # æ£€æµ‹æ•°æ®æ ¼å¼å¹¶åŠ è½½
    with open(data_path, 'r') as f:
        first_line = f.readline().strip()
        f.seek(0)  # é‡ç½®åˆ°æ–‡ä»¶å¼€å¤´

        parts = first_line.split()

        # åˆ¤æ–­æ ¼å¼ï¼š
        # æ ¼å¼1: user_id item_1 item_2 item_3 ... (ä¸€è¡Œå¤šä¸ªitems)
        # æ ¼å¼2: user_id item_id rating timestamp (æ¯è¡Œä¸€æ¡äº¤äº’)

        if len(parts) > 4:
            # æ ¼å¼1: æ¯è¡Œæ˜¯ä¸€ä¸ªç”¨æˆ·çš„å®Œæ•´åºåˆ—
            print("æ£€æµ‹åˆ°æ ¼å¼: æ¯è¡Œä¸€ä¸ªç”¨æˆ·åºåˆ—")
            for line in f:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue

                user_id = int(parts[0])
                items = [int(x) for x in parts[1:]]
                user_sequences[user_id] = items

                if items:
                    max_item_id = max(max_item_id, max(items))
        else:
            # æ ¼å¼2: æ¯è¡Œæ˜¯ä¸€æ¡äº¤äº’è®°å½•ï¼Œéœ€è¦èšåˆ
            print("æ£€æµ‹åˆ°æ ¼å¼: æ¯è¡Œä¸€æ¡äº¤äº’è®°å½•")
            user_interactions = {}

            for line in f:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue

                user_id = int(parts[0])
                item_id = int(parts[1])

                # å¦‚æœæœ‰timestampï¼ˆç¬¬4ä¸ªå­—æ®µï¼‰ï¼Œç”¨äºæ’åº
                timestamp = int(parts[3]) if len(parts) >= 4 else 0

                if user_id not in user_interactions:
                    user_interactions[user_id] = []

                user_interactions[user_id].append((timestamp, item_id))
                max_item_id = max(max_item_id, item_id)

            # æŒ‰æ—¶é—´æ’åºå¹¶æå–itemåºåˆ—
            for user_id, interactions in user_interactions.items():
                interactions.sort(key=lambda x: x[0])  # æŒ‰timestampæ’åº
                user_sequences[user_id] = [item_id for _, item_id in interactions]

    num_items = max_item_id + 1

    # æ‰“å°è¿‡æ»¤å‰çš„ç»Ÿè®¡
    print(f"âœ“ åŸå§‹ç”¨æˆ·æ•°: {len(user_sequences)}")
    print(f"âœ“ ç‰©å“æ€»æ•°: {num_items}")

    if len(user_sequences) == 0:
        raise ValueError(
            f"âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•ç”¨æˆ·æ•°æ®ï¼\n"
            f"   è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼: {data_path}\n"
            f"   é¢„æœŸæ ¼å¼: user_id item_1 item_2 item_3 ...\n"
            f"   æ¯è¡Œä¸€ä¸ªç”¨æˆ·ï¼Œç©ºæ ¼åˆ†éš”"
        )

    # è¿‡æ»¤æ‰åºåˆ—å¤ªçŸ­çš„ç”¨æˆ·ï¼ˆè‡³å°‘éœ€è¦5ä¸ªitemï¼štrain, val, testï¼‰
    original_user_count = len(user_sequences)
    user_sequences = {
        uid: seq for uid, seq in user_sequences.items()
        if len(seq) >= 5
    }

    if len(user_sequences) == 0:
        raise ValueError(
            f"âŒ è¿‡æ»¤åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·ï¼\n"
            f"   åŸå§‹ç”¨æˆ·æ•°: {original_user_count}\n"
            f"   è¿‡æ»¤æ¡ä»¶: åºåˆ—é•¿åº¦ >= 5\n"
            f"   å»ºè®®: æ£€æŸ¥æ•°æ®æ–‡ä»¶ {data_path} çš„æ ¼å¼æ˜¯å¦æ­£ç¡®"
        )

    print(f"âœ“ è¿‡æ»¤åç”¨æˆ·æ•°: {len(user_sequences)} (è¿‡æ»¤æ‰ {original_user_count - len(user_sequences)} ä¸ª)")

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    seq_lengths = [len(seq) for seq in user_sequences.values()]
    print(f"  åºåˆ—é•¿åº¦ç»Ÿè®¡:")
    print(f"    æœ€å°: {min(seq_lengths)}")
    print(f"    æœ€å¤§: {max(seq_lengths)}")
    print(f"    å¹³å‡: {sum(seq_lengths)/len(seq_lengths):.1f}")
    print(f"    æ€»äº¤äº’æ•°: {sum(seq_lengths):,}")
    print(f"{'='*60}\n")

    # [NEW] åŠ è½½å¤šæ¨¡æ€ç‰¹å¾
    item_visual_feats, item_text_feats, img_dim, text_dim = load_multimodal_features(
        data_dir=data_dir,
        visual_file=visual_file,
        text_file=text_file,
        num_items=num_items,
        device=device
    )

    return user_sequences, num_items, item_visual_feats, item_text_feats, img_dim, text_dim


# [UPDATED] æ›´æ–°åçš„åˆ›å»ºå®¢æˆ·ç«¯å‡½æ•°
def create_fedmem_clients(
    user_sequences: Dict[int, List[int]],
    global_model: UR4RecV2MoE,
    item_visual_feats: Optional[torch.Tensor],
    item_text_feats: Optional[torch.Tensor],
    args: argparse.Namespace
) -> List[FedMemClient]:
    """
    åˆ›å»ºFedMemå®¢æˆ·ç«¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ç‰¹å¾ï¼‰

    Args:
        user_sequences: ç”¨æˆ·äº¤äº’åºåˆ—
        global_model: å…¨å±€æ¨¡å‹
        item_visual_feats: ç‰©å“è§†è§‰ç‰¹å¾ [num_items, img_dim]
        item_text_feats: ç‰©å“æ–‡æœ¬ç‰¹å¾ [num_items, text_dim]
        args: è®­ç»ƒå‚æ•°

    Returns:
        clients: FedMemClientåˆ—è¡¨
    """
    clients = []

    print(f"\n{'='*60}")
    print("åˆ›å»º FedMem å®¢æˆ·ç«¯")
    print(f"{'='*60}")

    for user_id, sequence in user_sequences.items():
        client = FedMemClient(
            client_id=user_id,
            model=global_model,
            user_sequence=sequence,
            device=args.device,
            # [NEW] å¤šæ¨¡æ€ç‰¹å¾
            item_visual_feats=item_visual_feats,
            item_text_feats=item_text_feats,
            # è®­ç»ƒå‚æ•°
            learning_rate=args.learning_rate,
            weight_decay=args.weight_decay,
            local_epochs=args.local_epochs,
            batch_size=args.batch_size,
            max_seq_len=args.max_seq_len,
            # è´Ÿé‡‡æ ·
            num_negatives=args.num_negatives,
            num_items=args.num_items,
            # FedMemè®°å¿†å‚æ•°
            memory_capacity=args.memory_capacity,
            surprise_threshold=args.surprise_threshold,
            contrastive_lambda=args.contrastive_lambda,
            num_memory_prototypes=args.num_memory_prototypes,
            # è´Ÿé‡‡æ ·è¯„ä¼°å‚æ•°
            use_negative_sampling=args.use_negative_sampling,
            num_negatives_eval=args.num_negatives_eval
        )
        clients.append(client)

    print(f"âœ“ åˆ›å»ºäº† {len(clients)} ä¸ª FedMem å®¢æˆ·ç«¯")
    print(f"  æ¯ä¸ªå®¢æˆ·ç«¯:")
    print(f"    - è§†è§‰ç‰¹å¾: {'å¯ç”¨' if item_visual_feats is not None else 'ç¦ç”¨'}")
    print(f"    - æ–‡æœ¬ç‰¹å¾: {'å¯ç”¨' if item_text_feats is not None else 'ç¦ç”¨'}")
    print(f"    - è®°å¿†å®¹é‡: {args.memory_capacity}")
    print(f"    - Surpriseé˜ˆå€¼: {args.surprise_threshold}")
    print(f"{'='*60}\n")

    return clients


def main():
    parser = argparse.ArgumentParser(description="FedMemè®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰")

    # æ•°æ®å‚æ•°
    parser.add_argument("--data_dir", type=str, default="UR4Rec/data/ml-1m",
                        help="æ•°æ®ç›®å½•")
    parser.add_argument("--data_file", type=str, default="subset_ratings.dat",
                        help="äº¤äº’æ•°æ®æ–‡ä»¶å")

    # [NEW] å¤šæ¨¡æ€ç‰¹å¾æ–‡ä»¶å‚æ•°
    parser.add_argument("--visual_file", type=str, default="clip_features.pt",
                        help="è§†è§‰ç‰¹å¾æ–‡ä»¶å (e.g., 'item_images.npy' or 'item_images.pt')")
    parser.add_argument("--text_file", type=str, default="text_features.pt",
                        help="æ–‡æœ¬ç‰¹å¾æ–‡ä»¶å (e.g., 'item_llm_texts.npy' or 'item_llm_texts.pt')")

    # æ¨¡å‹å‚æ•°
    parser.add_argument("--num_items", type=int, default=1682,
                        help="ç‰©å“æ€»æ•°ï¼ˆè‡ªåŠ¨æ£€æµ‹å¦‚æœæœªæŒ‡å®šï¼‰")
    parser.add_argument("--sasrec_hidden_dim", type=int, default=256,
                        help="SASRecéšè—å±‚ç»´åº¦")
    parser.add_argument("--sasrec_num_blocks", type=int, default=2,
                        help="SASRec Transformerå—æ•°é‡")
    parser.add_argument("--sasrec_num_heads", type=int, default=4,
                        help="SASRecæ³¨æ„åŠ›å¤´æ•°é‡")
    parser.add_argument("--retriever_output_dim", type=int, default=256,
                        help="Retrieverè¾“å‡ºç»´åº¦")
    parser.add_argument("--moe_num_heads", type=int, default=8,
                        help="MoEæ³¨æ„åŠ›å¤´æ•°é‡")
    parser.add_argument("--max_seq_len", type=int, default=50,
                        help="æœ€å¤§åºåˆ—é•¿åº¦")

    # FedMemå‚æ•°
    parser.add_argument("--memory_capacity", type=int, default=50,
                        help="æœ¬åœ°è®°å¿†å®¹é‡")
    parser.add_argument("--surprise_threshold", type=float, default=0.3,
                        help="Surpriseé˜ˆå€¼")
    parser.add_argument("--contrastive_lambda", type=float, default=0.2,
                        help="å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡")
    parser.add_argument("--num_memory_prototypes", type=int, default=5,
                        help="è®°å¿†åŸå‹æ•°é‡")
    parser.add_argument("--enable_prototype_aggregation", action="store_true",
                        help="å¯ç”¨åŸå‹èšåˆ")

    # è”é‚¦å­¦ä¹ å‚æ•°
    parser.add_argument("--num_rounds", type=int, default=50,
                        help="è”é‚¦å­¦ä¹ è½®æ•°")
    parser.add_argument("--client_fraction", type=float, default=0.1,
                        help="æ¯è½®å‚ä¸çš„å®¢æˆ·ç«¯æ¯”ä¾‹")
    parser.add_argument("--local_epochs", type=int, default=1,
                        help="å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒè½®æ•°")
    parser.add_argument("--aggregation_method", type=str, default="fedavg",
                        choices=["fedavg", "fedprox"],
                        help="èšåˆæ–¹æ³•")
    parser.add_argument("--patience", type=int, default=10,
                        help="æ—©åœpatience")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--learning_rate", type=float, default=5e-3,
                        help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-5,
                        help="æƒé‡è¡°å‡")
    parser.add_argument("--batch_size", type=int, default=32,
                        help="æ‰¹å¤§å°")
    parser.add_argument("--num_negatives", type=int, default=100,
                        help="è´Ÿæ ·æœ¬æ•°é‡")

    # è´Ÿé‡‡æ ·è¯„ä¼°å‚æ•°
    parser.add_argument("--use_negative_sampling", default=True,
                        help="ä½¿ç”¨1:100è´Ÿé‡‡æ ·è¯„ä¼°ï¼ˆå¯¹é½NCF/SASRecè®ºæ–‡ï¼‰")
    parser.add_argument("--num_negatives_eval", type=int, default=100,
                        help="è¯„ä¼°æ—¶çš„è´Ÿæ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤100ï¼‰")

    # ã€æ®‹å·®å¢å¼ºã€‘Residual Enhancement å‚æ•°
    parser.add_argument("--gating_init", type=float, default=0.1,
                        help="é—¨æ§æƒé‡åˆå§‹å€¼ï¼ˆæ¨è0.0-0.1ï¼‰ï¼Œæ§åˆ¶è¾…åŠ©ä¿¡æ¯æ³¨å…¥å¼ºåº¦")

    # ã€ç­–ç•¥1ã€‘Router Bias Initialization å‚æ•° [å·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹]
    parser.add_argument("--init_bias_for_sasrec", action="store_true",
                        help="[å·²åºŸå¼ƒ] å¯ç”¨Router Bias Initializationï¼ˆç­–ç•¥1ï¼‰")
    parser.add_argument("--sasrec_bias_value", type=float, default=5.0,
                        help="[å·²åºŸå¼ƒ] SASRec expertçš„biasåˆå§‹å€¼")

    # ã€ç­–ç•¥2ã€‘Partial Aggregation å‚æ•°
    parser.add_argument("--partial_aggregation_warmup_rounds", type=int, default=20,
                        help="Warmupè½®æ•°ï¼Œå‰Nè½®åªèšåˆSASRecå‚æ•°ï¼ˆç­–ç•¥2ï¼‰ï¼Œ0è¡¨ç¤ºç¦ç”¨")

    # å…¶ä»–å‚æ•°
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu",
                        help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--seed", type=int, default=42,
                        help="éšæœºç§å­")
    parser.add_argument("--save_dir", type=str, default="checkpoints/fedmem",
                        help="æ¨¡å‹ä¿å­˜ç›®å½•")
    parser.add_argument("--verbose", action="store_true",
                        help="æ‰“å°è¯¦ç»†è®­ç»ƒä¿¡æ¯")

    # [NEW] é¢„è®­ç»ƒæƒé‡åŠ è½½
    parser.add_argument("--pretrained_path", type=str, default=None,
                        help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆç”¨äºè¿ç§»å­¦ä¹ ï¼‰ã€‚åŠ è½½SASRecéª¨å¹²æƒé‡ï¼Œè·³è¿‡Warmupé˜¶æ®µ")

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # ä¿å­˜é…ç½®
    with open(os.path.join(args.save_dir, 'config.json'), 'w') as f:
        json.dump(vars(args), f, indent=2)

    print(f"\n{'='*60}")
    print("FedMemè®­ç»ƒé…ç½®")
    print(f"{'='*60}")
    for key, value in vars(args).items():
        print(f"{key}: {value}")
    print(f"{'='*60}\n")

    # ============================================
    # 1. [UPDATED] åŠ è½½æ•°æ®ï¼ˆåŒ…å«å¤šæ¨¡æ€ç‰¹å¾ï¼‰
    # ============================================
    print("\n[1/4] åŠ è½½æ•°æ®...")
    data_path = os.path.join(args.data_dir, args.data_file)

    if not os.path.exists(data_path):
        print(f"é”™è¯¯ï¼šæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {data_path}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨æˆ–ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„")
        return

    # [NEW] åŠ è½½äº¤äº’åºåˆ— + å¤šæ¨¡æ€ç‰¹å¾
    user_sequences, num_items, item_visual_feats, item_text_feats, img_dim, text_dim = load_user_sequences(
        data_path=data_path,
        data_dir=args.data_dir,
        visual_file=args.visual_file,
        text_file=args.text_file,
        device=args.device
    )
    args.num_items = num_items  # æ›´æ–°num_items

    # ============================================
    # 2. [UPDATED] åˆ›å»ºå…¨å±€æ¨¡å‹ï¼ˆä½¿ç”¨å®é™…çš„ç‰¹å¾ç»´åº¦ï¼‰
    # ============================================
    print("\n[2/4] åˆ›å»ºå…¨å±€ UR4RecV2MoE æ¨¡å‹...")

    # [NEW] ä½¿ç”¨ä»æ•°æ®åŠ è½½å¾—åˆ°çš„å®é™…ç»´åº¦
    # å¦‚æœæ²¡æœ‰åŠ è½½å¤šæ¨¡æ€ç‰¹å¾ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦
    actual_text_dim = text_dim if item_text_feats is not None else 384
    actual_img_dim = img_dim if item_visual_feats is not None else 512

    print(f"  æ¨¡å‹é…ç½®:")
    print(f"    - ç‰©å“æ•°: {args.num_items}")
    print(f"    - æ–‡æœ¬ç‰¹å¾ç»´åº¦: {actual_text_dim}")
    print(f"    - å›¾åƒç‰¹å¾ç»´åº¦: {actual_img_dim}")
    print(f"    - SASRecéšè—ç»´åº¦: {args.sasrec_hidden_dim}")
    print(f"    - MoEéšè—ç»´åº¦: {args.sasrec_hidden_dim}")

    global_model = UR4RecV2MoE(
        num_items=args.num_items,
        # SASRecå‚æ•°
        sasrec_hidden_dim=args.sasrec_hidden_dim,
        sasrec_num_blocks=args.sasrec_num_blocks,
        sasrec_num_heads=args.sasrec_num_heads,
        sasrec_dropout=0.1,
        max_seq_len=args.max_seq_len,
        # å¤šæ¨¡æ€ç‰¹å¾ç»´åº¦
        visual_dim=actual_img_dim,  # CLIPç‰¹å¾ç»´åº¦
        text_dim=actual_text_dim,   # Sentence-BERTç‰¹å¾ç»´åº¦
        # MoEå‚æ•°
        moe_hidden_dim=args.sasrec_hidden_dim,  # ä¸SASRecä¿æŒä¸€è‡´
        moe_num_heads=args.moe_num_heads,
        moe_dropout=0.1,
        router_hidden_dim=128,
        # æ®‹å·®å¢å¼ºå‚æ•°
        gating_init=args.gating_init,
        # è´Ÿè½½å‡è¡¡
        load_balance_lambda=0.01,
        # ã€ç­–ç•¥1ã€‘Router Bias Initialization [å·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹]
        init_bias_for_sasrec=args.init_bias_for_sasrec,
        sasrec_bias_value=args.sasrec_bias_value,
        # è®¾å¤‡
        device=args.device
    )

    print(f"\nâœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
    print(f"  æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in global_model.parameters()):,}")
    trainable_params = sum(p.numel() for p in global_model.parameters() if p.requires_grad)
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    # ============================================
    # 2.5. [NEW] åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¯é€‰ï¼‰
    # ============================================
    if args.pretrained_path is not None:
        print(f"\n[2.5/4] åŠ è½½é¢„è®­ç»ƒæƒé‡...")
        print(f"  è·¯å¾„: {args.pretrained_path}")

        if os.path.exists(args.pretrained_path):
            try:
                # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPyTorch 2.6+éœ€è¦weights_only=Falseæ¥åŠ è½½åŒ…å«numpyå¯¹è±¡çš„checkpointï¼‰
                pretrained_state = torch.load(args.pretrained_path, map_location=args.device, weights_only=False)

                # åªåŠ è½½SASRecéª¨å¹²æƒé‡ï¼ˆå…¼å®¹æ€§åŠ è½½ï¼‰
                current_state = global_model.state_dict()
                loaded_keys = []
                skipped_keys = []

                for key, value in pretrained_state.items():
                    # ä¼˜å…ˆåŠ è½½SASRecç›¸å…³å‚æ•°
                    if 'sasrec' in key.lower() or 'item_emb' in key.lower():
                        if key in current_state and current_state[key].shape == value.shape:
                            current_state[key] = value
                            loaded_keys.append(key)
                        else:
                            skipped_keys.append(key)
                    # å¯é€‰ï¼šåŠ è½½Routerå’ŒLayerNormï¼ˆå¦‚æœå½¢çŠ¶åŒ¹é…ï¼‰
                    elif 'router' in key.lower() or 'layernorm' in key.lower():
                        if key in current_state and current_state[key].shape == value.shape:
                            current_state[key] = value
                            loaded_keys.append(key)
                        else:
                            skipped_keys.append(key)
                    else:
                        skipped_keys.append(key)

                # åº”ç”¨åŠ è½½çš„æƒé‡
                global_model.load_state_dict(current_state)

                print(f"  âœ“ æˆåŠŸåŠ è½½ {len(loaded_keys)} ä¸ªå‚æ•°")
                print(f"    ä¸»è¦æ¨¡å—: SASRecéª¨å¹²ã€ItemåµŒå…¥ã€Router")
                if len(skipped_keys) > 0:
                    print(f"  âš ï¸  è·³è¿‡ {len(skipped_keys)} ä¸ªå‚æ•°ï¼ˆå½¢çŠ¶ä¸åŒ¹é…æˆ–ééª¨å¹²å‚æ•°ï¼‰")

                # é‡è¦æç¤º
                print(f"\n  ğŸ“Œ é¢„è®­ç»ƒæƒé‡å·²åŠ è½½ï¼Œå»ºè®®:")
                print(f"    - ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆå¦‚1e-4, å½“å‰{args.learning_rate}ï¼‰")
                print(f"    - å‡å°‘è®­ç»ƒè½®æ•°ï¼ˆå½“å‰{args.num_rounds}è½®ï¼‰")
                print(f"    - ç›´æ¥è·³è¿‡Warmupï¼ˆè®¾ç½®partial_aggregation_warmup_rounds=0ï¼‰")

            except Exception as e:
                print(f"  âœ— åŠ è½½é¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}")
                print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ç»§ç»­è®­ç»ƒ")
        else:
            print(f"  âœ— é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {args.pretrained_path}")
            print(f"  å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ç»§ç»­è®­ç»ƒ")

    # ============================================
    # 3. [UPDATED] åˆ›å»ºFedMemå®¢æˆ·ç«¯ï¼ˆä¼ å…¥å¤šæ¨¡æ€ç‰¹å¾ï¼‰
    # ============================================
    print("\n[3/4] åˆ›å»º FedMem å®¢æˆ·ç«¯...")

    # [NEW] ä¼ é€’å¤šæ¨¡æ€ç‰¹å¾åˆ°å®¢æˆ·ç«¯
    clients = create_fedmem_clients(
        user_sequences=user_sequences,
        global_model=global_model,
        item_visual_feats=item_visual_feats,  # [NEW]
        item_text_feats=item_text_feats,      # [NEW]
        args=args
    )

    # ============================================
    # 4. åˆ›å»ºFedMemæœåŠ¡å™¨å¹¶å¼€å§‹è®­ç»ƒ
    # ============================================
    print("\n[4/4] åˆ›å»º FedMem æœåŠ¡å™¨å¹¶å¼€å§‹è®­ç»ƒ...")

    server = FedMemServer(
        global_model=global_model,
        clients=clients,
        device=args.device,
        # è”é‚¦å­¦ä¹ å‚æ•°
        aggregation_method=args.aggregation_method,
        client_fraction=args.client_fraction,
        num_rounds=args.num_rounds,
        local_epochs=args.local_epochs,
        patience=args.patience,
        # FedMemå‚æ•°
        enable_prototype_aggregation=args.enable_prototype_aggregation,
        num_memory_prototypes=args.num_memory_prototypes,
        # ã€ç­–ç•¥2ã€‘Partial Aggregation
        partial_aggregation_warmup_rounds=args.partial_aggregation_warmup_rounds
    )

    # å¼€å§‹è®­ç»ƒï¼ˆä¼ é€’user_sequencesç”¨äºè´Ÿé‡‡æ ·è¯„ä¼°ï¼‰
    train_history = server.train(user_sequences=user_sequences, verbose=args.verbose or True)

    # ============================================
    # 5. ä¿å­˜æ¨¡å‹å’Œç»“æœ
    # ============================================
    print("\nä¿å­˜æ¨¡å‹å’Œè®­ç»ƒå†å²...")

    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(args.save_dir, 'fedmem_model.pt')
    server.save_model(model_path)

    # ä¿å­˜è®­ç»ƒå†å²
    history_path = os.path.join(args.save_dir, 'train_history.json')
    with open(history_path, 'w') as f:
        # å°†tensorè½¬æ¢ä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
        history_serializable = {}
        for key, value in train_history.items():
            if isinstance(value, list):
                history_serializable[key] = [
                    {k: float(v) if isinstance(v, (int, float)) else v
                     for k, v in item.items()}
                    if isinstance(item, dict) else item
                    for item in value
                ]
            elif isinstance(value, dict):
                history_serializable[key] = {
                    k: float(v) if isinstance(v, (int, float)) else v
                    for k, v in value.items()
                }
            else:
                history_serializable[key] = value

        json.dump(history_serializable, f, indent=2)

    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    print(f"âœ“ è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")

    # ============================================
    # 6. æ‰“å°æœ€ç»ˆç»“æœ
    # ============================================
    print(f"\n{'='*60}")
    print("æœ€ç»ˆç»“æœ")
    print(f"{'='*60}")

    test_metrics = train_history['test_metrics']
    print("\næµ‹è¯•é›†æŒ‡æ ‡:")
    for key, value in test_metrics.items():
        print(f"  {key}: {value:.4f}")

    best_metrics = server.get_best_metrics()
    print(f"\næœ€ä½³éªŒè¯è½®æ¬¡: {best_metrics.get('round', -1) + 1}")
    print("æœ€ä½³éªŒè¯æŒ‡æ ‡:")
    for key, value in best_metrics.items():
        if key != 'round':
            print(f"  {key}: {value:.4f}")

    # [NEW] æ‰“å°å¤šæ¨¡æ€ä½¿ç”¨æƒ…å†µ
    print(f"\n{'='*60}")
    print("å¤šæ¨¡æ€ä½¿ç”¨æƒ…å†µ")
    print(f"{'='*60}")
    print(f"è§†è§‰ç‰¹å¾: {'âœ“ ä½¿ç”¨' if item_visual_feats is not None else 'âœ— æœªä½¿ç”¨'}")
    print(f"æ–‡æœ¬ç‰¹å¾: {'âœ“ ä½¿ç”¨' if item_text_feats is not None else 'âœ— æœªä½¿ç”¨'}")
    if item_visual_feats is None and item_text_feats is None:
        print("\nâš ï¸ æ³¨æ„: æœªåŠ è½½ä»»ä½•å¤šæ¨¡æ€ç‰¹å¾ï¼")
        print("   å»ºè®®ä½¿ç”¨ --visual_file å’Œ --text_file å‚æ•°åŠ è½½å¤šæ¨¡æ€æ•°æ®")
        print("   ä»¥è·å¾—æ›´å¥½çš„æ¨èæ•ˆæœã€‚")

    print(f"\n{'='*60}")
    print("è®­ç»ƒå®Œæˆï¼")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
