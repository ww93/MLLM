# FedDMMR: è”é‚¦æ·±åº¦å¤šæ¨¡æ€è®°å¿†æ¨èç³»ç»Ÿ

**Federated Deep Multimodal Memory Recommendation**

---

## ğŸ“‹ ç›®å½•

1. [æ¶æ„æ¦‚è¿°](#æ¶æ„æ¦‚è¿°)
2. [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
3. [æ¨¡å‹ä½¿ç”¨](#æ¨¡å‹ä½¿ç”¨)
4. [å‰å‘ä¼ æ’­æµç¨‹](#å‰å‘ä¼ æ’­æµç¨‹)
5. [è®­ç»ƒç¤ºä¾‹](#è®­ç»ƒç¤ºä¾‹)
6. [å‚æ•°è¯´æ˜](#å‚æ•°è¯´æ˜)
7. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## ğŸ—ï¸ æ¶æ„æ¦‚è¿°

FedDMMRé‡‡ç”¨**åœºæ™¯è‡ªé€‚åº”å¼‚æ„æ··åˆä¸“å®¶(Scenario-Adaptive Heterogeneous MoE)**æ¶æ„ï¼Œé€šè¿‡åŠ¨æ€è·¯ç”±æœºåˆ¶èåˆä¸‰ä¸ªå¼‚æ„ä¸“å®¶çš„æ¨èç»“æœï¼š

```
ç”¨æˆ·åºåˆ— + ç›®æ ‡ç‰©å“
        â†“
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
   â”‚ SASRec  â”‚  â† åºåˆ—ä¸“å®¶(Sequential Expert)
   â”‚ Backboneâ”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â†“
   åºåˆ—è¡¨ç¤º (seq_repr)
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                 â†“                 â†“                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ åºåˆ—ä¸“å®¶ â”‚      â”‚ è§†è§‰ä¸“å®¶  â”‚     â”‚ è¯­ä¹‰ä¸“å®¶  â”‚     â”‚ è·¯ç”±å™¨   â”‚
  â”‚Sequentialâ”‚      â”‚  Visual  â”‚     â”‚ Semantic â”‚     â”‚  Router  â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚                â”‚
       â”‚                 â”‚                 â”‚                â”‚
  seq_scores        vis_scores        sem_scores      weights[3]
       â”‚                 â”‚                 â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                      åŠ æƒèåˆ (Weighted Sum)
                              â†“
                       æœ€ç»ˆæ¨èåˆ†æ•°
```

### å…³é”®ç‰¹æ€§

âœ… **å¼‚æ„ä¸“å®¶è®¾è®¡**: ä¸‰ä¸ªä¸“å®¶ä½¿ç”¨ä¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶å’Œç‰¹å¾æ¥æº
âœ… **åŠ¨æ€è·¯ç”±**: åŸºäºç›®æ ‡ç‰©å“åµŒå…¥çš„ä»¥ç‰©å“ä¸ºä¸­å¿ƒçš„è·¯ç”±ç­–ç•¥
âœ… **å¤šæ¨¡æ€è®°å¿†**: æ”¯æŒè§†è§‰å’Œè¯­ä¹‰è®°å¿†çš„å¹¶è¡Œæ£€ç´¢
âœ… **è´Ÿè½½å‡è¡¡**: è‡ªåŠ¨å¹³è¡¡ä¸“å®¶ä½¿ç”¨ç‡ï¼Œé¿å…ä¸“å®¶é€€åŒ–
âœ… **è”é‚¦å‹å¥½**: è®¾è®¡é€‚é…è”é‚¦å­¦ä¹ åœºæ™¯çš„è®°å¿†èšåˆ

---

## ğŸ§© æ ¸å¿ƒç»„ä»¶

### 1. è½»é‡çº§æ³¨æ„åŠ› (LightweightAttention)

**ç”¨é€”**: ä¸ºVisualExpertæä¾›é«˜æ•ˆçš„è§†è§‰ç‰¹å¾æ£€ç´¢

**æœºåˆ¶**:
```python
Q = Linear(target_visual)      # [B, hidden_dim]
K = Linear(memory_visual)      # [B, TopK, hidden_dim]
scores = softmax(Q @ K^T / âˆšd) # [B, TopK]
output = scores @ V            # [B, visual_dim]
```

**ä¼˜åŠ¿**:
- å‚æ•°é‡å°ï¼Œè®¡ç®—é«˜æ•ˆ
- é€‚åˆé«˜ç»´è§†è§‰ç‰¹å¾(512ç»´CLIPç‰¹å¾)
- å•å¤´æ³¨æ„åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆ

---

### 2. è§†è§‰ä¸“å®¶ (VisualExpert)

**è¾“å…¥**:
- `target_visual`: ç›®æ ‡ç‰©å“çš„è§†è§‰ç‰¹å¾ [B, N, 512]
- `memory_visual`: è®°å¿†ä¸­çš„è§†è§‰ç‰¹å¾ [B, TopK, 512]

**å¤„ç†æµç¨‹**:
```
target_visual (CLIPç‰¹å¾)
      â†“
 è½»é‡çº§æ³¨æ„åŠ›æ£€ç´¢ â† memory_visual
      â†“
  èšåˆè§†è§‰è¡¨ç¤º
      â†“
  æŠ•å½±åˆ°éšè—ç»´åº¦
      â†“
 è§†è§‰åµŒå…¥ [B, N, hidden_dim]
```

**è¾“å‡º**: å¯Œå«è§†è§‰ä¿¡æ¯çš„ç‰©å“åµŒå…¥ï¼Œç”¨äºè®¡ç®—è§†è§‰åˆ†æ•°

---

### 3. è¯­ä¹‰ä¸“å®¶ (SemanticExpert)

**è¾“å…¥**:
- `target_id_embs`: ç›®æ ‡ç‰©å“IDåµŒå…¥ [B, N, id_dim]
- `memory_text`: è®°å¿†ä¸­çš„æ–‡æœ¬ç‰¹å¾ [B, TopK, 384]

**å¤„ç†æµç¨‹**:
```
target_id_embs
      â†“
  QueryæŠ•å½± (Q)
      â†“
 å¤šå¤´äº¤å‰æ³¨æ„åŠ› â† memory_text (K, V)
      â†“
  æ®‹å·®è¿æ¥ + LayerNorm
      â†“
 è¯­ä¹‰åµŒå…¥ [B, N, hidden_dim]
```

**å…³é”®æŠ€æœ¯**:
- ä½¿ç”¨`nn.MultiheadAttention` (4ä¸ªå¤´)
- æ”¯æŒäº¤å‰æ³¨æ„åŠ›: Queryæ¥è‡ªç‰©å“IDï¼ŒKey/Valueæ¥è‡ªè®°å¿†æ–‡æœ¬
- æ®‹å·®è¿æ¥ä¿ç•™åŸå§‹IDä¿¡æ¯

---

### 4. ä»¥ç‰©å“ä¸ºä¸­å¿ƒçš„è·¯ç”±å™¨ (ItemCentricRouter)

**è®¾è®¡ç†å¿µ**: ä¸åŒç‰©å“é€‚åˆä¸åŒçš„æ¨èç­–ç•¥

- çƒ­é—¨ç”µå½± â†’ ä¾èµ–åºåˆ—æ¨¡å¼(Sequential)
- è§†è§‰å¯¼å‘å•†å“ â†’ ä¾èµ–å¤–è§‚(Visual)
- æ–‡æœ¬ä¸°å¯Œç‰©å“ â†’ ä¾èµ–è¯­ä¹‰(Semantic)

**ç½‘ç»œç»“æ„**:
```
ç‰©å“åµŒå…¥ [B, N, id_dim]
      â†“
  Linear(hidden_dim=128) + LayerNorm + ReLU + Dropout
      â†“
  Linear(hidden_dim//2=64) + ReLU + Dropout
      â†“
  Linear(num_experts=3) + Softmax
      â†“
ä¸“å®¶æƒé‡ [B, N, 3]
```

**è¾“å‡º**: æ¯ä¸ªç‰©å“çš„ä¸‰ä¸ªä¸“å®¶æƒé‡ï¼Œå’Œä¸º1

---

### 5. ä¸»æ¨¡å‹ (UR4RecV2MoE)

**å®Œæ•´å‚æ•°åˆ—è¡¨**:

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `num_items` | int | - | ç‰©å“æ€»æ•°(å«padding) |
| `num_users` | int | - | ç”¨æˆ·æ€»æ•°(å«padding) |
| `item_emb_dim` | int | 64 | ç‰©å“IDåµŒå…¥ç»´åº¦ |
| `user_emb_dim` | int | 64 | ç”¨æˆ·IDåµŒå…¥ç»´åº¦ |
| `sasrec_hidden_dim` | int | 128 | SASRecéšè—å±‚ç»´åº¦ |
| `sasrec_num_blocks` | int | 2 | SASRec Transformerå—æ•° |
| `sasrec_num_heads` | int | 4 | SASRecæ³¨æ„åŠ›å¤´æ•° |
| `max_seq_len` | int | 50 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `visual_dim` | int | 512 | CLIPè§†è§‰ç‰¹å¾ç»´åº¦ |
| `text_dim` | int | 384 | Sentence-BERTæ–‡æœ¬ç»´åº¦ |
| `router_hidden_dim` | int | 128 | è·¯ç”±å™¨éšè—å±‚ç»´åº¦ |
| `dropout` | float | 0.1 | Dropoutæ¯”ç‡ |
| `load_balance_weight` | float | 0.01 | è´Ÿè½½å‡è¡¡æŸå¤±æƒé‡ |

---

## ğŸš€ æ¨¡å‹ä½¿ç”¨

### åŸºæœ¬åˆå§‹åŒ–

```python
from UR4Rec.models.ur4rec_v2_moe import UR4RecV2MoE

model = UR4RecV2MoE(
    num_items=1683,          # ML-100Kç‰©å“æ•°
    num_users=944,           # ML-100Kç”¨æˆ·æ•°
    item_emb_dim=128,
    user_emb_dim=128,
    sasrec_hidden_dim=256,
    sasrec_num_blocks=2,
    sasrec_num_heads=4,
    max_seq_len=50,
    visual_dim=512,          # CLIPç‰¹å¾
    text_dim=384,            # SBERTç‰¹å¾
    router_hidden_dim=128,
    dropout=0.1,
    load_balance_weight=0.01
)
```

### å‰å‘ä¼ æ’­

```python
# å‡†å¤‡è¾“å…¥
user_ids = torch.tensor([1, 2, 3])                    # [B]
input_seq = torch.tensor([[1,2,3,0], [4,5,6,7], ...]) # [B, max_seq_len]
target_items = torch.tensor([[10, 20], [15, 25], ...]) # [B, N]

# å¤šæ¨¡æ€è®°å¿†ç‰¹å¾
memory_visual = torch.randn(3, 20, 512)  # [B, TopK, 512]
memory_text = torch.randn(3, 20, 384)    # [B, TopK, 384]
target_visual = torch.randn(3, 2, 512)   # [B, N, 512]
target_text = torch.randn(3, 2, 384)     # [B, N, 384]

# å‰å‘ä¼ æ’­
final_scores, rec_loss, lb_loss = model(
    user_ids=user_ids,
    input_seq=input_seq,
    target_items=target_items,
    memory_visual=memory_visual,
    memory_text=memory_text,
    target_visual=target_visual,
    target_text=target_text
)

# è®¡ç®—æ€»æŸå¤±
total_loss = rec_loss + 0.01 * lb_loss
```

---

## ğŸ”„ å‰å‘ä¼ æ’­æµç¨‹

### é˜¶æ®µ1: åºåˆ—ç¼–ç 

```python
# SASRecå¤„ç†ç”¨æˆ·è¡Œä¸ºåºåˆ—
seq_output = self.sasrec(input_seq)       # [B, L, D]
seq_repr = seq_output[:, -1, :]           # [B, D] å–æœ€åæ—¶åˆ»
```

### é˜¶æ®µ2: ä¸‰ä¸“å®¶å¹¶è¡Œè®¡ç®—

#### ä¸“å®¶A: åºåˆ—ä¸“å®¶
```python
target_item_embs = self.item_embedding(target_items)  # [B, N, D]
seq_scores = seq_repr @ target_item_embs.T            # [B, N]
```

#### ä¸“å®¶B: è§†è§‰ä¸“å®¶
```python
if memory_visual is not None and target_visual is not None:
    vis_embs = self.visual_expert(
        target_visual=target_visual,        # [B, N, 512]
        memory_visual=memory_visual         # [B, TopK, 512]
    )  # â†’ [B, N, D]
    vis_scores = seq_repr @ vis_embs.T     # [B, N]
else:
    vis_scores = 0.0
```

#### ä¸“å®¶C: è¯­ä¹‰ä¸“å®¶
```python
if memory_text is not None:
    sem_embs = self.semantic_expert(
        target_id_embs=target_item_embs,    # [B, N, D]
        memory_text=memory_text             # [B, TopK, 384]
    )  # â†’ [B, N, D]
    sem_scores = seq_repr @ sem_embs.T     # [B, N]
else:
    sem_scores = 0.0
```

### é˜¶æ®µ3: åŠ¨æ€è·¯ç”±ä¸èåˆ

```python
# è®¡ç®—è·¯ç”±æƒé‡
router_weights = self.router(target_item_embs)  # [B, N, 3]
w_seq = router_weights[:, :, 0]  # [B, N]
w_vis = router_weights[:, :, 1]
w_sem = router_weights[:, :, 2]

# åŠ æƒèåˆ
final_scores = (
    w_seq * seq_scores +
    w_vis * vis_scores +
    w_sem * sem_scores
)  # [B, N]
```

### é˜¶æ®µ4: æŸå¤±è®¡ç®—

```python
# æ¨èæŸå¤±: BPRæŸå¤±
pos_scores = final_scores[:, 0]        # [B] æ­£æ ·æœ¬
neg_scores = final_scores[:, 1:]       # [B, N-1] è´Ÿæ ·æœ¬
rec_loss = -torch.mean(
    torch.log(torch.sigmoid(pos_scores.unsqueeze(1) - neg_scores) + 1e-10)
)

# è´Ÿè½½å‡è¡¡æŸå¤±
expert_usage = router_weights.mean(dim=[0, 1])  # [3]
uniform_target = 1.0 / 3.0
lb_loss = torch.sum((expert_usage - uniform_target) ** 2)

return final_scores, rec_loss, lb_loss
```

---

## ğŸ¯ è®­ç»ƒç¤ºä¾‹

### å®Œæ•´è®­ç»ƒå¾ªç¯

```python
import torch
from torch.utils.data import DataLoader
from UR4Rec.models.ur4rec_v2_moe import UR4RecV2MoE
from UR4Rec.models.local_dynamic_memory import LocalDynamicMemory

# 1. åˆå§‹åŒ–æ¨¡å‹
model = UR4RecV2MoE(
    num_items=1683,
    num_users=944,
    sasrec_hidden_dim=256,
    max_seq_len=50,
    visual_dim=512,
    text_dim=384,
    load_balance_weight=0.01
).to('cuda')

optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 2. åˆå§‹åŒ–æœ¬åœ°åŠ¨æ€è®°å¿†
memory = LocalDynamicMemory(
    capacity=50,
    surprise_threshold=0.5,
    visual_dim=512,
    text_dim=384
)

# 3. è®­ç»ƒå¾ªç¯
for epoch in range(50):
    for batch in train_loader:
        user_ids = batch['user_id'].to('cuda')
        input_seq = batch['item_seq'].to('cuda')
        target_item = batch['target_item'].to('cuda')

        # è´Ÿé‡‡æ ·
        neg_items = torch.randint(1, 1683, (len(target_item), 99), device='cuda')
        all_candidates = torch.cat([target_item.unsqueeze(1), neg_items], dim=1)

        # ä»è®°å¿†ä¸­æ£€ç´¢å¤šæ¨¡æ€ç‰¹å¾
        memory_visual, memory_text = memory.retrieve_multimodal_memory(
            user_ids=user_ids,
            top_k=20
        )  # [B, 20, 512], [B, 20, 384]

        # è·å–å€™é€‰ç‰©å“çš„å¤šæ¨¡æ€ç‰¹å¾
        target_visual = get_visual_features(all_candidates)  # [B, 100, 512]
        target_text = get_text_features(all_candidates)      # [B, 100, 384]

        # å‰å‘ä¼ æ’­
        scores, rec_loss, lb_loss = model(
            user_ids=user_ids,
            input_seq=input_seq,
            target_items=all_candidates,
            memory_visual=memory_visual,
            memory_text=memory_text,
            target_visual=target_visual,
            target_text=target_text
        )

        # æ€»æŸå¤±
        total_loss = rec_loss + 0.01 * lb_loss

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()

        # æ›´æ–°è®°å¿†
        surprises = compute_surprise(scores[:, 0])  # è®¡ç®—æƒŠå–œåº¦
        memory.add_batch(
            user_ids=user_ids,
            item_ids=target_item,
            surprises=surprises,
            visual_features=target_visual[:, 0, :],
            text_features=target_text[:, 0, :]
        )

    print(f"Epoch {epoch+1}: Rec Loss = {rec_loss:.4f}, LB Loss = {lb_loss:.4f}")
```

---

## âš™ï¸ å‚æ•°è¯´æ˜

### è¶…å‚æ•°è°ƒä¼˜å»ºè®®

| å‚æ•° | å°æ•°æ®é›† | å¤§æ•°æ®é›† | è¯´æ˜ |
|------|---------|---------|------|
| `sasrec_hidden_dim` | 64-128 | 256-512 | å½±å“æ¨¡å‹å®¹é‡ |
| `sasrec_num_blocks` | 1-2 | 2-4 | Transformeræ·±åº¦ |
| `item_emb_dim` | 64 | 128-256 | ç‰©å“åµŒå…¥ç»´åº¦ |
| `router_hidden_dim` | 64-128 | 128-256 | è·¯ç”±å™¨å¤æ‚åº¦ |
| `dropout` | 0.1-0.2 | 0.1 | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| `load_balance_weight` | 0.01-0.05 | 0.01 | å¹³è¡¡é‡è¦æ€§ |
| `max_seq_len` | 20-50 | 50-100 | åºåˆ—é•¿åº¦ |

### è´Ÿè½½å‡è¡¡æƒé‡é€‰æ‹©

```python
# è¿‡å°: ä¸“å®¶ä½¿ç”¨ä¸å‡è¡¡ï¼Œå¯èƒ½é€€åŒ–ä¸ºå•ä¸“å®¶
load_balance_weight = 0.001  # âŒ å¤ªå°

# åˆé€‚: æ—¢ä¿è¯æ¨èå‡†ç¡®æ€§ï¼Œåˆä¿ƒè¿›ä¸“å®¶å‡è¡¡
load_balance_weight = 0.01   # âœ… æ¨è

# è¿‡å¤§: ç‰ºç‰²æ¨èå‡†ç¡®æ€§æ¥å¼ºåˆ¶å‡è¡¡
load_balance_weight = 0.1    # âŒ å¤ªå¤§
```

---

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–

**é—®é¢˜**: å¤šæ¨¡æ€ç‰¹å¾å ç”¨å¤§é‡å†…å­˜

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä»…åœ¨éœ€è¦æ—¶æ£€ç´¢è®°å¿†
if self.training:
    # è®­ç»ƒæ—¶ä½¿ç”¨å®Œæ•´è®°å¿†
    memory_visual, memory_text = memory.retrieve(top_k=50)
else:
    # æ¨ç†æ—¶ä½¿ç”¨ç²¾ç®€è®°å¿†
    memory_visual, memory_text = memory.retrieve(top_k=20)

# ä½¿ç”¨åŠç²¾åº¦
model.half()  # FP16
memory_visual = memory_visual.half()
```

### 2. è®¡ç®—ä¼˜åŒ–

**æ‰¹é‡åŒ–ç‰©å“åµŒå…¥è·å–**:
```python
# âŒ ä½æ•ˆ: é€ä¸ªè·å–
for item_id in target_items:
    emb = model.item_embedding(item_id)

# âœ… é«˜æ•ˆ: æ‰¹é‡è·å–
all_embs = model.item_embedding(target_items)  # [B, N, D]
```

**ç¼“å­˜é™æ€ç‰¹å¾**:
```python
# é¢„è®¡ç®—æ‰€æœ‰ç‰©å“çš„è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾
all_visual_features = precompute_clip_features()   # [num_items, 512]
all_text_features = precompute_sbert_features()    # [num_items, 384]

# è®­ç»ƒæ—¶ç›´æ¥ç´¢å¼•
target_visual = all_visual_features[target_items]
target_text = all_text_features[target_items]
```

### 3. åˆ†å¸ƒå¼è®­ç»ƒ

**è”é‚¦å­¦ä¹ åœºæ™¯**:
```python
from UR4Rec.models.fedmem_client import FedMemClient
from UR4Rec.models.fedmem_server import FedMemServer

# æœåŠ¡å™¨ç«¯
server = FedMemServer(
    model_class=UR4RecV2MoE,
    model_kwargs={...},
    enable_prototype_aggregation=True,
    num_memory_prototypes=5
)

# å®¢æˆ·ç«¯è®­ç»ƒ
for client_id in selected_clients:
    client = FedMemClient(client_id, data, model, memory)
    updated_weights, prototypes = client.train(local_epochs=3)
    server.aggregate([updated_weights], [prototypes])
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### MovieLens-100K

| é…ç½® | HR@10 | NDCG@10 | è®­ç»ƒæ—¶é—´ |
|------|-------|---------|---------|
| ä»…åºåˆ—ä¸“å®¶ | 0.38 | 0.22 | 1å°æ—¶ |
| + è§†è§‰ä¸“å®¶ | 0.41 | 0.24 | 1.5å°æ—¶ |
| + è¯­ä¹‰ä¸“å®¶ | 0.42 | 0.25 | 2å°æ—¶ |
| å®Œæ•´FedDMMR | **0.43** | **0.26** | 2å°æ—¶ |

### ä¸“å®¶ä½¿ç”¨ç‡

å…¸å‹è®­ç»ƒåçš„ä¸“å®¶æƒé‡åˆ†å¸ƒ:
```
Sequential Expert: 40-50%  (åºåˆ—æ¨¡å¼ä¸»å¯¼)
Visual Expert:     25-35%  (å¤–è§‚ç›¸ä¼¼æ€§)
Semantic Expert:   20-30%  (è¯­ä¹‰å…³è”)
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: è§†è§‰/è¯­ä¹‰ä¸“å®¶çš„åˆ†æ•°å§‹ç»ˆä¸º0ï¼Ÿ

**åŸå› **: æœªæä¾›`memory_visual`æˆ–`memory_text`å‚æ•°

**è§£å†³**:
```python
# ç¡®ä¿ä¼ é€’å¤šæ¨¡æ€è®°å¿†ç‰¹å¾
scores, rec_loss, lb_loss = model(
    ...,
    memory_visual=memory.get_visual_memory(),  # â† å¿…é¡»æä¾›
    memory_text=memory.get_text_memory()       # â† å¿…é¡»æä¾›
)
```

### Q2: è´Ÿè½½å‡è¡¡æŸå¤±è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Ÿ

**è§£å†³**: é™ä½`load_balance_weight`
```python
model = UR4RecV2MoE(..., load_balance_weight=0.005)  # ä»0.01é™åˆ°0.005
```

### Q3: è·¯ç”±å™¨æ€»æ˜¯é€‰æ‹©å•ä¸€ä¸“å®¶ï¼Ÿ

**åŸå› **: æ¨¡å‹å°šæœªæ”¶æ•›æˆ–æ•°æ®ä¸æ”¯æŒå¤šæ¨¡æ€

**è§£å†³**:
1. å¢åŠ è®­ç»ƒè½®æ•°
2. æ£€æŸ¥å¤šæ¨¡æ€ç‰¹å¾è´¨é‡
3. é€‚å½“æé«˜`load_balance_weight`

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **FedAvg**: McMahan et al. "Communication-Efficient Learning of Deep Networks from Decentralized Data" (AISTATS 2017)

2. **SASRec**: Kang & McAuley. "Self-Attentive Sequential Recommendation" (ICDM 2018)

3. **Mixture-of-Experts**: Shazeer et al. "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer" (ICLR 2017)

4. **CLIP**: Radford et al. "Learning Transferable Visual Models From Natural Language Supervision" (ICML 2021)

5. **Sentence-BERT**: Reimers & Gurevych. "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks" (EMNLP 2019)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

**v2.0 - 2025-12-18**
- âœ… å®Œå…¨é‡æ„ä¸ºFedDMMRæ¶æ„
- âœ… å®ç°Scenario-Adaptive Heterogeneous MoE
- âœ… æ·»åŠ LightweightAttentionå’ŒItemCentricRouter
- âœ… æ”¯æŒå¤šæ¨¡æ€è®°å¿†è¾“å…¥
- âœ… æ·»åŠ è´Ÿè½½å‡è¡¡æŸå¤±

**v1.0 - 2025-12-15**
- åˆå§‹UR4Recå®ç°
- åŸºç¡€MoEæ£€ç´¢æ¶æ„

---

## ğŸ“§ è”ç³»æ–¹å¼

**é¡¹ç›®**: FedDMMR - Federated Deep Multimodal Memory Recommendation
**ç”¨é€”**: ACL 2026 è®ºæ–‡æŠ•ç¨¿
**ä»£ç **: `/Users/admin/Desktop/MLLM/UR4Rec/models/ur4rec_v2_moe.py`
**æ–‡æ¡£æ—¥æœŸ**: 2025å¹´12æœˆ18æ—¥

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜è¯·æŸ¥é˜…æºç æ³¨é‡Šæˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚** ğŸš€
